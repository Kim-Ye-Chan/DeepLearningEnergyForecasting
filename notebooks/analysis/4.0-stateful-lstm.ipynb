{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d701f02-43fd-4453-9392-efef8db0c8a9",
   "metadata": {},
   "source": [
    "This notebook applies a stateful LSTM model using PyTorch & Lightning, to get multi-step quantile energy consumption forecasts. \n",
    "\\\n",
    "It also performs & demonstrates the necessary data handling & preprocessing steps to get input & output sequences for the LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "565fe9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==2.0.2 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: pandas==2.2.2 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: optuna==4.4.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (4.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from pandas==2.2.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from optuna==4.4.0) (1.14.1)\n",
      "Requirement already satisfied: colorlog in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from optuna==4.4.0) (6.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from optuna==4.4.0) (22.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from optuna==4.4.0) (2.0.41)\n",
      "Requirement already satisfied: tqdm in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from optuna==4.4.0) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from optuna==4.4.0) (6.0.2)\n",
      "Requirement already satisfied: Mako in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from alembic>=1.5.0->optuna==4.4.0) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from alembic>=1.5.0->optuna==4.4.0) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.16.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna==4.4.0) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from colorlog->optuna==4.4.0) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna==4.4.0) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy==2.0.2 pandas==2.2.2 optuna==4.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5039c32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë£¨íŠ¸ ê²½ë¡œë¡œ ì´ë™: c:\\Users\\Daniel\\DeepLearningEnergyForecasting\n",
      "ğŸ“‚ í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: c:\\Users\\Daniel\\DeepLearningEnergyForecasting\n",
      "ğŸ“ src ê²½ë¡œ ì¡´ì¬ ì—¬ë¶€: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# ì •í™•í•œ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •\n",
    "project_root = os.path.abspath(\"c:/Users/Daniel/DeepLearningEnergyForecasting/\")  # notebooks í´ë” ë°”ë¡œ ìœ„ê°€ ë£¨íŠ¸\n",
    "\n",
    "# í™•ì¸\n",
    "print(\"ë£¨íŠ¸ ê²½ë¡œë¡œ ì´ë™:\", project_root)\n",
    "os.chdir(project_root)\n",
    "\n",
    "# sys.pathì— ì¶”ê°€\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# ë‹¤ì‹œ í™•ì¸\n",
    "print(\"ğŸ“‚ í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬:\", os.getcwd())\n",
    "print(\"ğŸ“ src ê²½ë¡œ ì¡´ì¬ ì—¬ë¶€:\", os.path.exists(\"src/deep_learning\"))  # ì§ì ‘ src ì¶”ê°€\n",
    "src_path = os.path.join(project_root, \"src\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6ef11cc-56ac-42e0-98bc-d8e5baa08288",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_42176\\332957137.py\", line 6, in <module>\n",
      "    import lightning as pl\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\__init__.py\", line 41, in <module>\n",
      "    from lightning.pytorch.callbacks import Callback  # noqa: E402\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\__init__.py\", line 35, in <module>\n",
      "    from lightning.pytorch.callbacks import Callback  # noqa: E402\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\callbacks\\__init__.py\", line 14, in <module>\n",
      "    from lightning.pytorch.callbacks.batch_size_finder import BatchSizeFinder\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\callbacks\\batch_size_finder.py\", line 24, in <module>\n",
      "    from lightning.pytorch.callbacks.callback import Callback\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\callbacks\\callback.py\", line 25, in <module>\n",
      "    from lightning.pytorch.utilities.types import STEP_OUTPUT\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\utilities\\types.py\", line 27, in <module>\n",
      "    from torchmetrics import Metric\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\torchmetrics\\__init__.py\", line 37, in <module>\n",
      "    from torchmetrics import functional  # noqa: E402\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\torchmetrics\\functional\\__init__.py\", line 122, in <module>\n",
      "    from torchmetrics.functional.text._deprecated import _bleu_score as bleu_score\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\torchmetrics\\functional\\text\\__init__.py\", line 17, in <module>\n",
      "    from torchmetrics.functional.text.chrf import chrf_score\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\torchmetrics\\functional\\text\\chrf.py\", line 32, in <module>\n",
      "    _EPS_SMOOTHING = tensor(1e-16)\n",
      "c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\torchmetrics\\functional\\text\\chrf.py:32: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_numpy.cpp:77.)\n",
      "  _EPS_SMOOTHING = tensor(1e-16)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import lightning as pl \n",
    "#import pytorch_lightning as pl\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "\n",
    "import optuna\n",
    "import warnings\n",
    "\n",
    "from lightning.pytorch.callbacks import Callback\n",
    "#from pytorch_lightning.callbacks import EarlyStopping\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "from src.deep_learning.preprocessing import SequenceScaler, SequenceDataset\n",
    "from src.deep_learning.quantile_loss import QuantileLoss\n",
    "from src.deep_learning.lstm import StatefulQuantileLSTM\n",
    "from src.deep_learning.testing import train_val_split, train_val_split_const_batch_size, test_sequences_to_dataframe, plot_actual_predicted, plot_sequence_preds, calculate_metrics\n",
    "from src.deep_learning.prediction import predictions_to_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86c0d62f-2163-4c92-bf7e-283f177fffce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbb5262f-36ee-4d06-9457-771df657d8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 1923"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0b59f93-6e6e-4fdb-8a8b-53a7551ba5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1923\n"
     ]
    }
   ],
   "source": [
    "# Set Torch settings\n",
    "torch.set_default_dtype(torch.float32)\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "pl.seed_everything(random_seed, workers = True)\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f04ab1c-13d2-43b0-9fef-de865238c890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot settings\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "759916b7-9291-4bdd-b0f8-14eabca92e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"C:/Users/Daniel/DeepLearningEnergyForecasting/data/analysis/processed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3595e22d-ad5e-4523-be32-1e0f06c7917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir + \"train_advanced_featured.csv\")\n",
    "df[\"ì¼ì‹œ\"] = pd.to_datetime(df[\"ì¼ì‹œ\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57ab82ca-f92d-4c00-9b57-aff3d00637fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ê±´ë¬¼ë²ˆí˜¸</th>\n",
       "      <th>ì¼ì‹œ</th>\n",
       "      <th>ê¸°ì˜¨(Â°C)</th>\n",
       "      <th>ê°•ìˆ˜ëŸ‰(mm)</th>\n",
       "      <th>í’ì†(m/s)</th>\n",
       "      <th>ìŠµë„(%)</th>\n",
       "      <th>ì¼ì¡°(hr)</th>\n",
       "      <th>ì¼ì‚¬(MJ/m2)</th>\n",
       "      <th>ì „ë ¥ì†Œë¹„ëŸ‰(kWh)</th>\n",
       "      <th>ì—°ë©´ì (m2)</th>\n",
       "      <th>...</th>\n",
       "      <th>ê±´ë¬¼ìœ í˜•_í•™êµ</th>\n",
       "      <th>ê±´ë¬¼ìœ í˜•_í˜¸í…”</th>\n",
       "      <th>consumption_lag_24h</th>\n",
       "      <th>trend</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>day_of_week_sin</th>\n",
       "      <th>day_of_week_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-06-02 00:00:00</td>\n",
       "      <td>18.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3870.42</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5794.80</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-06-02 01:00:00</td>\n",
       "      <td>18.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5733.45</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5591.85</td>\n",
       "      <td>25</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-06-02 02:00:00</td>\n",
       "      <td>17.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5689.17</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5338.17</td>\n",
       "      <td>26</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-06-02 03:00:00</td>\n",
       "      <td>16.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5579.04</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4554.42</td>\n",
       "      <td>27</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-06-02 04:00:00</td>\n",
       "      <td>16.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4113.60</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3602.25</td>\n",
       "      <td>28</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203971</th>\n",
       "      <td>100</td>\n",
       "      <td>2024-08-24 19:00:00</td>\n",
       "      <td>29.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.18</td>\n",
       "      <td>3276.00</td>\n",
       "      <td>162070.24</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2206.92</td>\n",
       "      <td>203995</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203972</th>\n",
       "      <td>100</td>\n",
       "      <td>2024-08-24 20:00:00</td>\n",
       "      <td>28.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3197.52</td>\n",
       "      <td>162070.24</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2064.12</td>\n",
       "      <td>203996</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203973</th>\n",
       "      <td>100</td>\n",
       "      <td>2024-08-24 21:00:00</td>\n",
       "      <td>28.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3006.60</td>\n",
       "      <td>162070.24</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1161.12</td>\n",
       "      <td>203997</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203974</th>\n",
       "      <td>100</td>\n",
       "      <td>2024-08-24 22:00:00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2649.72</td>\n",
       "      <td>162070.24</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2076.36</td>\n",
       "      <td>203998</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203975</th>\n",
       "      <td>100</td>\n",
       "      <td>2024-08-24 23:00:00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2929.32</td>\n",
       "      <td>162070.24</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2763.24</td>\n",
       "      <td>203999</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203976 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ê±´ë¬¼ë²ˆí˜¸                  ì¼ì‹œ  ê¸°ì˜¨(Â°C)  ê°•ìˆ˜ëŸ‰(mm)  í’ì†(m/s)  ìŠµë„(%)  ì¼ì¡°(hr)  \\\n",
       "0          1 2024-06-02 00:00:00    18.7      0.0      2.9   58.0     0.0   \n",
       "1          1 2024-06-02 01:00:00    18.2      0.0      3.5   60.0     0.0   \n",
       "2          1 2024-06-02 02:00:00    17.6      0.0      2.5   61.0     0.0   \n",
       "3          1 2024-06-02 03:00:00    16.9      0.0      2.5   64.0     0.0   \n",
       "4          1 2024-06-02 04:00:00    16.1      0.0      1.6   66.0     0.0   \n",
       "...      ...                 ...     ...      ...      ...    ...     ...   \n",
       "203971   100 2024-08-24 19:00:00    29.1      0.0      4.4   76.0     0.4   \n",
       "203972   100 2024-08-24 20:00:00    28.6      0.0      3.7   74.0     0.0   \n",
       "203973   100 2024-08-24 21:00:00    28.3      0.0      2.9   74.0     0.0   \n",
       "203974   100 2024-08-24 22:00:00    28.0      0.0      1.7   76.0     0.0   \n",
       "203975   100 2024-08-24 23:00:00    28.0      0.0      2.1   75.0     0.0   \n",
       "\n",
       "        ì¼ì‚¬(MJ/m2)  ì „ë ¥ì†Œë¹„ëŸ‰(kWh)    ì—°ë©´ì (m2)  ...  ê±´ë¬¼ìœ í˜•_í•™êµ  ê±´ë¬¼ìœ í˜•_í˜¸í…”  \\\n",
       "0            0.00     3870.42   82912.71  ...    False     True   \n",
       "1            0.00     5733.45   82912.71  ...    False     True   \n",
       "2            0.00     5689.17   82912.71  ...    False     True   \n",
       "3            0.00     5579.04   82912.71  ...    False     True   \n",
       "4            0.00     4113.60   82912.71  ...    False     True   \n",
       "...           ...         ...        ...  ...      ...      ...   \n",
       "203971       0.18     3276.00  162070.24  ...    False     True   \n",
       "203972       0.00     3197.52  162070.24  ...    False     True   \n",
       "203973       0.00     3006.60  162070.24  ...    False     True   \n",
       "203974       0.00     2649.72  162070.24  ...    False     True   \n",
       "203975       0.00     2929.32  162070.24  ...    False     True   \n",
       "\n",
       "        consumption_lag_24h   trend  hour_sin  hour_cos  day_of_week_sin  \\\n",
       "0                   5794.80      24  0.000000  1.000000        -0.781831   \n",
       "1                   5591.85      25  0.258819  0.965926        -0.781831   \n",
       "2                   5338.17      26  0.500000  0.866025        -0.781831   \n",
       "3                   4554.42      27  0.707107  0.707107        -0.781831   \n",
       "4                   3602.25      28  0.866025  0.500000        -0.781831   \n",
       "...                     ...     ...       ...       ...              ...   \n",
       "203971              2206.92  203995 -0.965926  0.258819        -0.974928   \n",
       "203972              2064.12  203996 -0.866025  0.500000        -0.974928   \n",
       "203973              1161.12  203997 -0.707107  0.707107        -0.974928   \n",
       "203974              2076.36  203998 -0.500000  0.866025        -0.974928   \n",
       "203975              2763.24  203999 -0.258819  0.965926        -0.974928   \n",
       "\n",
       "        day_of_week_cos     month_sin  month_cos  \n",
       "0              0.623490  1.224647e-16       -1.0  \n",
       "1              0.623490  1.224647e-16       -1.0  \n",
       "2              0.623490  1.224647e-16       -1.0  \n",
       "3              0.623490  1.224647e-16       -1.0  \n",
       "4              0.623490  1.224647e-16       -1.0  \n",
       "...                 ...           ...        ...  \n",
       "203971        -0.222521 -8.660254e-01       -0.5  \n",
       "203972        -0.222521 -8.660254e-01       -0.5  \n",
       "203973        -0.222521 -8.660254e-01       -0.5  \n",
       "203974        -0.222521 -8.660254e-01       -0.5  \n",
       "203975        -0.222521 -8.660254e-01       -0.5  \n",
       "\n",
       "[203976 rows x 32 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13991eef-1a7f-4130-b82b-7ab15df29afe",
   "metadata": {},
   "source": [
    "## Data prep: Getting input & output sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0a1558-0aa0-43d1-8f60-248847198b84",
   "metadata": {},
   "source": [
    "We will create a \"shifted dataset\" where each row at time T contains the following columns:\n",
    "- Target value at T (consumption lead T+1),\n",
    "- Past value at T (consumption lag T-2),\n",
    "- Time covariates at T."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2699147e-7f37-4017-861c-6674868d35d0",
   "metadata": {},
   "source": [
    "Every input sequence will be the last 72 hours before 16:00, and every output sequence will be the next 32 hours after 16:00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cf65954-517b-4712-97aa-42e089573017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define forecasting and modeling constants\n",
    "INPUT_LENGTH = 72         # ê³¼ê±° ì‹œê³„ì—´ ê¸¸ì´ (T-L ~ T-1)\n",
    "OUTPUT_LENGTH = 168       # ë¯¸ë˜ ì˜ˆì¸¡ ê¸¸ì´ (T ~ T+167)\n",
    "HORIZON_START = 0         # ì˜ˆì¸¡ ì‹œì  ì¤‘ lossë¥¼ ê³„ì‚°í•  ì²« ì‹œì \n",
    "QUANTILES = [0.025, 0.5, 0.975]  # ì˜ˆì¸¡í•  ë¶„ìœ„ìˆ˜\n",
    "FORECAST_HOUR = 16        # ë§¤ì¼ ì˜ˆì¸¡ì„ ì‹œì‘í•  ì‹œê° (ì˜ˆ: ì˜¤í›„ 4ì‹œ)\n",
    "batch_size = 64  # ğŸ”¥ ì—¬ê¸°ì— ëª…ì‹œì ìœ¼ë¡œ ì •ì˜\n",
    "train_fraction = 0.8\n",
    "\n",
    "# 2. Feature ì •ì˜\n",
    "FEATURE_COLS = [\n",
    "    \"consumption_lag_24h\", \"trend\", \"hour_sin\", \"hour_cos\",\n",
    "    \"day_of_week_sin\", \"day_of_week_cos\", \"month_sin\", \"month_cos\"\n",
    "]\n",
    "\n",
    "STATIC_COLS = [col for col in df.columns if \"ê±´ë¬¼ìœ í˜•_\" in col or \"ë©´ì \" in col or \"ìš©ëŸ‰\" in col]\n",
    "\n",
    "TARGET_COL = \"ì „ë ¥ì†Œë¹„ëŸ‰(kWh)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee9c0ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. ì „ì²´ ê±´ë¬¼ì— ëŒ€í•´ ì‹œí€€ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ ì •ì˜\n",
    "def make_sequences_all_buildings(\n",
    "    df: pd.DataFrame,\n",
    "    input_length: int = INPUT_LENGTH,\n",
    "    output_length: int = OUTPUT_LENGTH,\n",
    "    forecast_hour: int = FORECAST_HOUR\n",
    "):\n",
    "    input_seqs = []\n",
    "    output_seqs = []\n",
    "\n",
    "    all_static_cols = STATIC_COLS.copy()\n",
    "\n",
    "    for building_id, group in df.groupby(\"ê±´ë¬¼ë²ˆí˜¸\"):\n",
    "        group = group.sort_values(\"ì¼ì‹œ\").reset_index(drop=True)\n",
    "        group[\"ì‹œê°„\"] = group[\"ì¼ì‹œ\"].dt.hour\n",
    "\n",
    "        # ëˆ„ë½ëœ ì •ì  ë³€ìˆ˜ ì±„ìš°ê¸°\n",
    "        for col in all_static_cols:\n",
    "            if col not in group.columns:\n",
    "                group[col] = 0\n",
    "\n",
    "        # ì˜ˆì¸¡ ê°€ëŠ¥í•œ ì‹œê°„ ì°¾ê¸°\n",
    "        forecast_points = group[\n",
    "            (group[\"ì‹œê°„\"] == forecast_hour)\n",
    "            & (group.index >= input_length)\n",
    "            & (group.index + output_length <= group.index.max())\n",
    "        ].index\n",
    "\n",
    "        for t in forecast_points:\n",
    "            input_seq = pd.concat([\n",
    "                group.loc[t - input_length:t - 1, [\"ì¼ì‹œ\"]],\n",
    "                group.loc[t - input_length:t - 1, FEATURE_COLS],\n",
    "            ], axis=1).copy()\n",
    "            for col in all_static_cols:\n",
    "                input_seq[col] = group[col].iloc[0]\n",
    "            input_seq = input_seq.set_index(\"ì¼ì‹œ\")\n",
    "\n",
    "            output_seq = pd.concat([\n",
    "                group.loc[t:t + output_length - 1, [\"ì¼ì‹œ\"]],\n",
    "                group.loc[t:t + output_length - 1, [TARGET_COL]],\n",
    "                group.loc[t:t + output_length - 1, FEATURE_COLS],  # âœ… ì´ ë¶€ë¶„ ìˆ˜ì •\n",
    "            ], axis=1).copy()\n",
    "            for col in all_static_cols:\n",
    "                output_seq[col] = group[col].iloc[0]\n",
    "            output_seq = output_seq.set_index(\"ì¼ì‹œ\")\n",
    "        \n",
    "            input_seqs.append((building_id, input_seq))     # tupleë¡œ ì €ì¥\n",
    "            output_seqs.append((building_id, output_seq))\n",
    "            \n",
    "\n",
    "    return input_seqs, output_seqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50c31de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ì‹œí€€ìŠ¤ ìˆ˜: 7499\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>consumption_lag_24h</th>\n",
       "      <th>trend</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>day_of_week_sin</th>\n",
       "      <th>day_of_week_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>ì—°ë©´ì (m2)</th>\n",
       "      <th>ëƒ‰ë°©ë©´ì (m2)</th>\n",
       "      <th>...</th>\n",
       "      <th>ê±´ë¬¼ìœ í˜•_IDC(ì „í™”êµ­)</th>\n",
       "      <th>ê±´ë¬¼ìœ í˜•_ê±´ë¬¼ê¸°íƒ€</th>\n",
       "      <th>ê±´ë¬¼ìœ í˜•_ê³µê³µ</th>\n",
       "      <th>ê±´ë¬¼ìœ í˜•_ë°±í™”ì </th>\n",
       "      <th>ê±´ë¬¼ìœ í˜•_ë³‘ì›</th>\n",
       "      <th>ê±´ë¬¼ìœ í˜•_ìƒìš©</th>\n",
       "      <th>ê±´ë¬¼ìœ í˜•_ì•„íŒŒíŠ¸</th>\n",
       "      <th>ê±´ë¬¼ìœ í˜•_ì—°êµ¬ì†Œ</th>\n",
       "      <th>ê±´ë¬¼ìœ í˜•_í•™êµ</th>\n",
       "      <th>ê±´ë¬¼ìœ í˜•_í˜¸í…”</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ì¼ì‹œ</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-06-02 16:00:00</th>\n",
       "      <td>4659.69</td>\n",
       "      <td>40</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-02 17:00:00</th>\n",
       "      <td>5358.84</td>\n",
       "      <td>41</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-02 18:00:00</th>\n",
       "      <td>5985.18</td>\n",
       "      <td>42</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-02 19:00:00</th>\n",
       "      <td>6292.32</td>\n",
       "      <td>43</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-02 20:00:00</th>\n",
       "      <td>5279.67</td>\n",
       "      <td>44</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     consumption_lag_24h  trend  hour_sin      hour_cos  \\\n",
       "ì¼ì‹œ                                                                        \n",
       "2024-06-02 16:00:00              4659.69     40 -0.866025 -5.000000e-01   \n",
       "2024-06-02 17:00:00              5358.84     41 -0.965926 -2.588190e-01   \n",
       "2024-06-02 18:00:00              5985.18     42 -1.000000 -1.836970e-16   \n",
       "2024-06-02 19:00:00              6292.32     43 -0.965926  2.588190e-01   \n",
       "2024-06-02 20:00:00              5279.67     44 -0.866025  5.000000e-01   \n",
       "\n",
       "                     day_of_week_sin  day_of_week_cos     month_sin  \\\n",
       "ì¼ì‹œ                                                                    \n",
       "2024-06-02 16:00:00        -0.781831          0.62349  1.224647e-16   \n",
       "2024-06-02 17:00:00        -0.781831          0.62349  1.224647e-16   \n",
       "2024-06-02 18:00:00        -0.781831          0.62349  1.224647e-16   \n",
       "2024-06-02 19:00:00        -0.781831          0.62349  1.224647e-16   \n",
       "2024-06-02 20:00:00        -0.781831          0.62349  1.224647e-16   \n",
       "\n",
       "                     month_cos   ì—°ë©´ì (m2)  ëƒ‰ë°©ë©´ì (m2)  ...  ê±´ë¬¼ìœ í˜•_IDC(ì „í™”êµ­)  \\\n",
       "ì¼ì‹œ                                                  ...                  \n",
       "2024-06-02 16:00:00       -1.0  82912.71   77586.0  ...          False   \n",
       "2024-06-02 17:00:00       -1.0  82912.71   77586.0  ...          False   \n",
       "2024-06-02 18:00:00       -1.0  82912.71   77586.0  ...          False   \n",
       "2024-06-02 19:00:00       -1.0  82912.71   77586.0  ...          False   \n",
       "2024-06-02 20:00:00       -1.0  82912.71   77586.0  ...          False   \n",
       "\n",
       "                     ê±´ë¬¼ìœ í˜•_ê±´ë¬¼ê¸°íƒ€  ê±´ë¬¼ìœ í˜•_ê³µê³µ  ê±´ë¬¼ìœ í˜•_ë°±í™”ì   ê±´ë¬¼ìœ í˜•_ë³‘ì›  ê±´ë¬¼ìœ í˜•_ìƒìš©  ê±´ë¬¼ìœ í˜•_ì•„íŒŒíŠ¸  \\\n",
       "ì¼ì‹œ                                                                              \n",
       "2024-06-02 16:00:00      False    False     False    False    False     False   \n",
       "2024-06-02 17:00:00      False    False     False    False    False     False   \n",
       "2024-06-02 18:00:00      False    False     False    False    False     False   \n",
       "2024-06-02 19:00:00      False    False     False    False    False     False   \n",
       "2024-06-02 20:00:00      False    False     False    False    False     False   \n",
       "\n",
       "                     ê±´ë¬¼ìœ í˜•_ì—°êµ¬ì†Œ  ê±´ë¬¼ìœ í˜•_í•™êµ  ê±´ë¬¼ìœ í˜•_í˜¸í…”  \n",
       "ì¼ì‹œ                                               \n",
       "2024-06-02 16:00:00     False    False     True  \n",
       "2024-06-02 17:00:00     False    False     True  \n",
       "2024-06-02 18:00:00     False    False     True  \n",
       "2024-06-02 19:00:00     False    False     True  \n",
       "2024-06-02 20:00:00     False    False     True  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. ì‹œí€€ìŠ¤ ìƒì„± ì‹¤í–‰\n",
    "input_sequences, output_sequences = make_sequences_all_buildings(df)\n",
    "\n",
    "print(f\"ì´ ì‹œí€€ìŠ¤ ìˆ˜: {len(input_sequences)}\")\n",
    "display(input_sequences[0][1].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8636db66-7ab4-490c-923f-09e1e1d84190",
   "metadata": {},
   "source": [
    "In the input sequence, we pair every past target value at T with the future covariates at T+1.\n",
    "\\\n",
    "In the output sequence, we pair every future target value at T+1 with the future covariates at T+2.\n",
    "\n",
    "This is because the future target at T+1 and the future covariates at T+2 will be the past target & future covariates in the next prediction step. \n",
    "\\\n",
    "LSTMs and RNNs can only forecast 1 step at a time as they need hidden & cell states from the previous step. \n",
    "\\\n",
    "For validation & prediciton steps, we will replace the future targets after T+1 with predicitons from the previous step, as these will be unknown values at real prediciton time.\n",
    "\n",
    "During training, we still use the real target values for all prediciton steps \"in hindsight\", as training with predictions as the target may mislead the model. In a real life scenario, we'd have the \"hindsight\" values available in the historic data, just like we do here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "253bf525-8f95-43af-9c5c-356248ae6cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7499"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45ecfbe6-7de0-46bc-8435-5fc5ae5ecaf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7499"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2a79ac-10d9-4de2-b973-99d6d60421cc",
   "metadata": {},
   "source": [
    "## Preprocessing: Custom scaler, Torch datasets & dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653354da-4abb-4dd0-b6de-b4c8b1c5e490",
   "metadata": {},
   "source": [
    "In a stateful LSTM, the last timestep's hidden & cell state for observation 1 in batch 1 will be used as the initial hidden & cell state for observation 1 in batch 2.\n",
    "\n",
    "Because of this, we need batches of constant size through training, val. and testing data. We'll divide the lengths of each data fold with the batch size, drop the remainder from the start of the training fold & the end of the val. & test folds.\n",
    "\\\n",
    "The data splitter is implemented in `src.deep_learning.testing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a977fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²´ì˜ 0.8ì„ í•™ìŠµ + íŠœë‹ìš©ìœ¼ë¡œ ì“°ê³  ì‹¶ë‹¤ë©´:\n",
    "train_input, train_output, test_input, test_output = train_val_split_const_batch_size(\n",
    "    input_sequences, output_sequences,\n",
    "    train_fraction=0.8,  # ì „ì²´ ì¤‘ í•™ìŠµ+íŠœë‹\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "# ê·¸ ì¤‘ íŠœë‹ìš©ì€ ë‹¤ì‹œ 0.9 ì •ë„ë¡œ ë‚˜ëˆ„ëŠ” ê²Œ ì ë‹¹í•¨:\n",
    "tr_input, tr_output, val_input, val_output = train_val_split_const_batch_size(\n",
    "    train_input,\n",
    "    train_output,\n",
    "    train_fraction=0.9,   # ì „ì²´ê°€ ì•„ë‹ˆë¼ trainì˜ ì¼ë¶€ë§Œ valë¡œ\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c720818",
   "metadata": {},
   "source": [
    "We have to scale the past consumption & trend values in the input sequences, and the future consumption & trend values in the output sequences, because they'll be the past values as the forecast horizon expands. We also need the ability to backtransform the network's final predictions accordingly.\n",
    "\n",
    "This can be done with the custom `SequenceScaler` implemented in `src.deep_learning.preprocessing`.\n",
    "\n",
    "The scaled data is then converted into Torch tensors using `SequenceDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90c9b772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Input ì‹œí€€ìŠ¤ shape ë¶„í¬: Counter({(72, 23): 5312})\n",
      "ğŸ” Output ì‹œí€€ìŠ¤ shape ë¶„í¬: Counter({(168, 24): 5312})\n",
      "ì œê±°ë  ì˜ëª»ëœ ì‹œí€€ìŠ¤ ê°œìˆ˜: 0\n"
     ]
    }
   ],
   "source": [
    "#í›ˆë ¨ ì‹œí€€ìŠ¤ ì¤‘ ê¸¸ì´ ë˜ëŠ” ì»¬ëŸ¼ ìˆ˜ê°€ ì˜ëª»ëœ ê²ƒ ì œê±°\n",
    "expected_input_shape = (INPUT_LENGTH, len(FEATURE_COLS) + len(STATIC_COLS))\n",
    "expected_output_shape = (OUTPUT_LENGTH, len(FEATURE_COLS) + 1 + len(STATIC_COLS))\n",
    "\n",
    "bad_indices = [\n",
    "    i for i, (x, y) in enumerate(zip(tr_input, tr_output))\n",
    "    if x.shape != expected_input_shape or y.shape != expected_output_shape\n",
    "]\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "input_shapes = [x.shape for x in tr_input]\n",
    "output_shapes = [y.shape for y in tr_output]\n",
    "\n",
    "print(\"ğŸ” Input ì‹œí€€ìŠ¤ shape ë¶„í¬:\", Counter(input_shapes))\n",
    "print(\"ğŸ” Output ì‹œí€€ìŠ¤ shape ë¶„í¬:\", Counter(output_shapes))\n",
    "\n",
    "\n",
    "print(f\"ì œê±°ë  ì˜ëª»ëœ ì‹œí€€ìŠ¤ ê°œìˆ˜: {len(bad_indices)}\")\n",
    "\n",
    "# ì•ˆì „í•˜ê²Œ ì—­ìˆœìœ¼ë¡œ ì‚­ì œ\n",
    "for i in sorted(bad_indices, reverse=True):\n",
    "    del tr_input[i]\n",
    "    del tr_output[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7961e203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. ì‹œí€€ìŠ¤ ìŠ¤ì¼€ì¼ëŸ¬ (min-max) - valìš©\n",
    "scaler_val = SequenceScaler()\n",
    "_ = scaler_val.fit(tr_input, tr_output)\n",
    "\n",
    "tr_data = SequenceDataset(\n",
    "    scaler_val.transform(tr_input), \n",
    "    scaler_val.transform(tr_output)\n",
    ")\n",
    "val_data = SequenceDataset(\n",
    "    scaler_val.transform(val_input), \n",
    "    scaler_val.transform(val_output)\n",
    ")\n",
    "\n",
    "# 5. ì‹œí€€ìŠ¤ ìŠ¤ì¼€ì¼ëŸ¬ - testìš©\n",
    "scaler_test = SequenceScaler()\n",
    "_ = scaler_test.fit(train_input, train_output)\n",
    "\n",
    "train_data = SequenceDataset(\n",
    "    scaler_test.transform(train_input), \n",
    "    scaler_test.transform(train_output)\n",
    ")\n",
    "test_data = SequenceDataset(\n",
    "    scaler_test.transform(test_input), \n",
    "    scaler_test.transform(test_output)\n",
    ")\n",
    "\n",
    "# 6. Torch Dataloaders ì„¤ì •\n",
    "num_workers = 0  # ì‹œìŠ¤í…œ ì½”ì–´ ìˆ˜ì— ë”°ë¼ ì¡°ì •\n",
    "pin_memory=True  # GPU ì„±ëŠ¥ ìµœì í™”\n",
    "shuffle = False\n",
    "\n",
    "tr_loader = torch.utils.data.DataLoader(tr_data, batch_size=batch_size, num_workers=num_workers, shuffle=shuffle, pin_memory=pin_memory)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers, shuffle=shuffle, pin_memory=pin_memory)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, num_workers=num_workers, shuffle=shuffle, pin_memory=pin_memory)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers, shuffle=shuffle, pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687c517f-376f-43e2-8839-16e9b261e80f",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f01bf7f-75d7-40e1-a69d-f3eb3514906b",
   "metadata": {},
   "source": [
    "The `StatefulQuantileLSTM` model, and the `QuantileLoss` function are both implemented in `src.deep_learning`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62efdf47-113d-49dd-8214-3cb2a4ff9c43",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a42fa951-e14b-49c6-8c20-98685c0adeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tuning parameters\n",
    "tol = 0.002 # Change in MAE to avoid early stopping\n",
    "patience = 5 # N. of rounds with no improvement before early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c158b25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Optuna objective\n",
    "def objective_lstm(trial):\n",
    "    output_length = OUTPUT_LENGTH\n",
    "    input_dims = len(FEATURE_COLS) + len(STATIC_COLS)\n",
    "    horizon_start = HORIZON_START\n",
    "    quantiles = QUANTILES\n",
    "\n",
    "    # Define search space\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 5e-4, 5e-2) # 0.0005 to 0.05\n",
    "    lr_decay = trial.suggest_float(\"lr_decay\", 0.9, 1)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 3)\n",
    "    hidden_size = 2 ** trial.suggest_int(\"hidden_size_pw\", 2, 6) # 4 to 64, powers of 2\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0, 0.1)\n",
    "\n",
    "    # Create hyperparameters dict\n",
    "    hyperparameters_dict = {\n",
    "        \"output_length\": output_length,\n",
    "        \"input_size\": input_dims,\n",
    "        \"horizon_start\": horizon_start,\n",
    "        \"quantiles\": quantiles,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"lr_decay\": lr_decay,\n",
    "        \"num_layers\": num_layers,\n",
    "        \"hidden_size\": hidden_size,\n",
    "        \"dropout_rate\": dropout_rate\n",
    "    }\n",
    "\n",
    "    # Create early stop callback\n",
    "    callback_earlystop = pl.pytorch.callbacks.EarlyStopping(\n",
    "        monitor = \"val_loss\",\n",
    "        mode = \"min\",\n",
    "        min_delta = tol,\n",
    "        patience = patience\n",
    "    )\n",
    "\n",
    "    # Create pruning callback\n",
    "    callback_pruner = PyTorchLightningPruningCallback(trial, monitor = \"val_loss\")\n",
    "\n",
    "    # Create trainer\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=50,\n",
    "        detect_anomaly=False,\n",
    "        accelerator=\"gpu\",     \n",
    "        devices=1,\n",
    "        precision=\"32\",     \n",
    "        callbacks=[callback_earlystop, callback_pruner],\n",
    "        enable_model_summary=False,\n",
    "        logger=False,\n",
    "        enable_progress_bar=True,  # â† Trueë¡œ ë°”ê¿”ë„ ë¬´ë°© (ì§„í–‰ìƒí™© ë³´ê¸°ìš©)\n",
    "        enable_checkpointing=False\n",
    "    )\n",
    "\n",
    "\n",
    "    # Model\n",
    "    model = StatefulQuantileLSTM(hyperparameters_dict)\n",
    "    model.to('cuda')  # âœ… ì§ì ‘ GPUë¡œ ì´ë™\n",
    "\n",
    "    # í™•ì¸ìš©\n",
    "    print(\"ğŸ“¦ Model device:\", next(model.parameters()).device)\n",
    "\n",
    "    # ë°°ì¹˜ë„ í™•ì¸\n",
    "    sample_batch = next(iter(tr_loader))\n",
    "    print(\"ğŸ“‚ Batch device:\", sample_batch[0].device)\n",
    "\n",
    "    # í•™ìŠµ\n",
    "    trainer.fit(model, tr_loader, val_loader)\n",
    "\n",
    "    # í‰ê°€ ê²°ê³¼\n",
    "    score = callback_earlystop.best_score.cpu().numpy()\n",
    "    epoch = trainer.current_epoch - callback_earlystop.wait_count\n",
    "    trial.set_user_attr(\"n_epochs\", epoch)\n",
    "\n",
    "    # âœ… ìë™ ì €ì¥ (í•¨ìˆ˜ ë°–ì— study_lstm ìˆì–´ì•¼ í•¨)\n",
    "    import pickle\n",
    "    try:\n",
    "        with open(\"c:/Users/Daniel/DeepLearningEnergyForecasting/study_lstm.pkl\", \"wb\") as f:\n",
    "            pickle.dump(study_lstm, f)\n",
    "        print(\"ğŸ’¾ study_lstm ì €ì¥ ì™„ë£Œ.\")\n",
    "    except Exception as e:\n",
    "        print(\"âš ï¸ study_lstm ì €ì¥ ì‹¤íŒ¨:\", e)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1574517f-1bfc-41f3-b7a1-e2a44d751696",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-27 16:36:21,993] A new study created in memory with name: tune_lstm\n"
     ]
    }
   ],
   "source": [
    "# Create study\n",
    "study_lstm = optuna.create_study(\n",
    "  sampler = optuna.samplers.TPESampler(seed = random_seed),\n",
    "  pruner = optuna.pruners.HyperbandPruner(),\n",
    "  study_name = \"tune_lstm\",\n",
    "  direction = \"minimize\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97e744c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0\n",
      "11.6\n",
      "True\n",
      "1\n",
      "NVIDIA GeForce RTX 3050 Ti Laptop GPU\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n",
    "import os\n",
    "print(os.cpu_count())  # ë…¼ë¦¬ì  ì½”ì–´ ìˆ˜ (í•˜ì´í¼ìŠ¤ë ˆë”© í¬í•¨)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2099ce40-0f12-4ef5-8702-2eb6509bacea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'try:\\n    study_lstm.optimize(objective_lstm, n_trials=50, show_progress_bar=True)\\nexcept KeyboardInterrupt:\\n    print(\"ì¤‘ë‹¨ë¨! Study ì €ì¥ ì¤‘...\")\\n    with open(file_path.replace(\\'.pkl\\', \\'_new.pkl\\'), \"wb\") as f:\\n        pickle.dump(study_lstm, f)'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''try:\n",
    "    study_lstm.optimize(objective_lstm, n_trials=50, show_progress_bar=True)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"ì¤‘ë‹¨ë¨! Study ì €ì¥ ì¤‘...\")\n",
    "    with open(file_path.replace('.pkl', '_new.pkl'), \"wb\") as f:\n",
    "        pickle.dump(study_lstm, f)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6a6e1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Model device: cuda:0\n",
      "ğŸ“‚ Batch device: cpu\n",
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92/92 [05:39<00:00,  3.69s/it, loss=10.4, train_loss_step=4.200, val_loss_step=5.260, val_loss_epoch=6.060, train_loss_epoch=11.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                                                                                                                             \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [10:57<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-27 16:47:22,357] Trial 10 pruned. Trial was pruned at epoch 1.\n",
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92/92 [05:39<00:00,  3.69s/it, loss=10.4, train_loss_step=4.200, val_loss_step=5.260, val_loss_epoch=6.060, train_loss_epoch=11.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 3.25528:   2%|â–         | 1/40 [10:57<7:07:29, 657.69s/it]GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Model device: cuda:0\n",
      "ğŸ“‚ Batch device: cpu\n",
      "Epoch 0:   0%|          | 0/92 [00:00<?, ?it/s]                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                                                                                                                             \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 3.25528:   2%|â–         | 1/40 [10:58<7:07:29, 657.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-07-27 16:47:23,281] Trial 11 failed with parameters: {'learning_rate': 0.027978459117020908, 'lr_decay': 0.9595647624706808, 'num_layers': 3, 'hidden_size_pw': 6, 'dropout_rate': 0.03476351032952749} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 4.00 GiB total capacity; 3.45 GiB already allocated; 0 bytes free; 3.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF').\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_42176\\830938251.py\", line 66, in objective_lstm\n",
      "    trainer.fit(model, tr_loader, val_loader)\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py\", line 608, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py\", line 38, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py\", line 650, in _fit_impl\n",
      "    self._run(model, ckpt_path=self.ckpt_path)\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py\", line 1103, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py\", line 1182, in _run_stage\n",
      "    self._run_train()\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py\", line 1205, in _run_train\n",
      "    self.fit_loop.run()\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\loops\\loop.py\", line 199, in run\n",
      "    self.advance(*args, **kwargs)\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py\", line 267, in advance\n",
      "    self._outputs = self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\loops\\loop.py\", line 199, in run\n",
      "    self.advance(*args, **kwargs)\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\loops\\epoch\\training_epoch_loop.py\", line 213, in advance\n",
      "    batch_output = self.batch_loop.run(kwargs)\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\loops\\loop.py\", line 199, in run\n",
      "    self.advance(*args, **kwargs)\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\loops\\batch\\training_batch_loop.py\", line 88, in advance\n",
      "    outputs = self.optimizer_loop.run(optimizers, kwargs)\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\loops\\loop.py\", line 199, in run\n",
      "    self.advance(*args, **kwargs)\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\optimizer_loop.py\", line 202, in advance\n",
      "    result = self._run_optimization(kwargs, self._optimizers[self.optim_progress.optimizer_position])\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\optimizer_loop.py\", line 249, in _run_optimization\n",
      "    self._optimizer_step(optimizer, opt_idx, kwargs.get(\"batch_idx\", 0), closure)\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\optimizer_loop.py\", line 370, in _optimizer_step\n",
      "    self.trainer._call_lightning_module_hook(\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py\", line 1347, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\core\\module.py\", line 1744, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\core\\optimizer.py\", line 169, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\strategies\\strategy.py\", line 234, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\precision_plugin.py\", line 119, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\torch\\optim\\lr_scheduler.py\", line 68, in wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\torch\\optim\\optimizer.py\", line 140, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\torch\\optim\\optimizer.py\", line 23, in _use_grad\n",
      "    ret = func(self, *args, **kwargs)\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\torch\\optim\\adam.py\", line 183, in step\n",
      "    loss = closure()\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\precision_plugin.py\", line 105, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\optimizer_loop.py\", line 149, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\optimizer_loop.py\", line 135, in closure\n",
      "    step_output = self._step_fn()\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\optimizer_loop.py\", line 419, in _training_step\n",
      "    training_step_output = self.trainer._call_strategy_hook(\"training_step\", *kwargs.values())\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py\", line 1485, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\strategies\\strategy.py\", line 378, in training_step\n",
      "    return self.model.training_step(*args, **kwargs)\n",
      "  File \"c:\\Users\\Daniel\\DeepLearningEnergyForecasting\\src\\deep_learning\\lstm.py\", line 97, in training_step\n",
      "    last_hidden_states, last_cell_states, preds = self.forward(\n",
      "  File \"c:\\Users\\Daniel\\DeepLearningEnergyForecasting\\src\\deep_learning\\lstm.py\", line 54, in forward\n",
      "    lstm_output, (last_hidden_states, last_cell_states) = self.lstm(input_chunk, prev_states)\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\", line 774, in forward\n",
      "    result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 4.00 GiB total capacity; 3.45 GiB already allocated; 0 bytes free; 3.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Epoch 0:   0%|          | 0/92 [00:00<?, ?it/s]3.70s/it, loss=10.4, train_loss_step=4.200, val_loss_step=5.260, val_loss_epoch=6.060, train_loss_epoch=11.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                                                                                                                             \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 3.25528:   2%|â–         | 1/40 [10:58<7:07:29, 657.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-07-27 16:47:23,303] Trial 11 failed with value None.\n",
      "Epoch 0:   0%|          | 0/92 [00:00<?, ?it/s]3.70s/it, loss=10.4, train_loss_step=4.200, val_loss_step=5.260, val_loss_epoch=6.060, train_loss_epoch=11.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 3.25528:   2%|â–         | 1/40 [10:58<7:08:06, 658.64s/it]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 4.00 GiB total capacity; 3.45 GiB already allocated; 0 bytes free; 3.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m     study_lstm \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# ê·¸ë¦¬ê³  ë‹¤ì‹œ\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mstudy_lstm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_lstm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstudy_lstm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrials\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\optuna\\study\\study.py:489\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    389\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    396\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    397\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    398\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \n\u001b[0;32m    400\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\optuna\\study\\_optimize.py:64\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 64\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     77\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\optuna\\study\\_optimize.py:161\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\optuna\\study\\_optimize.py:253\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    249\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    252\u001b[0m ):\n\u001b[1;32m--> 253\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\optuna\\study\\_optimize.py:201\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 201\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[20], line 66\u001b[0m, in \u001b[0;36mobjective_lstm\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ“‚ Batch device:\u001b[39m\u001b[38;5;124m\"\u001b[39m, sample_batch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# í•™ìŠµ\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtr_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# í‰ê°€ ê²°ê³¼\u001b[39;00m\n\u001b[0;32m     69\u001b[0m score \u001b[38;5;241m=\u001b[39m callback_earlystop\u001b[38;5;241m.\u001b[39mbest_score\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:608\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    606\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Trainer.fit()` requires a `LightningModule`, got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m--> 608\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     41\u001b[0m     trainer\u001b[38;5;241m.\u001b[39m_call_teardown_hook()\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:650\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    643\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m ckpt_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_from_checkpoint\n\u001b[0;32m    644\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_set_ckpt_path(\n\u001b[0;32m    645\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    646\u001b[0m     ckpt_path,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    647\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    648\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    649\u001b[0m )\n\u001b[1;32m--> 650\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1103\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mrestore_training_state()\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mresume_end()\n\u001b[1;32m-> 1103\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1105\u001b[0m log\u001b[38;5;241m.\u001b[39mdetail(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_teardown()\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1182\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n\u001b[0;32m   1181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_predict()\n\u001b[1;32m-> 1182\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1205\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m   1204\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m-> 1205\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\loops\\loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:267\u001b[0m, in \u001b[0;36mFitLoop.advance\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher\u001b[38;5;241m.\u001b[39msetup(dataloader, batch_to_device\u001b[38;5;241m=\u001b[39mbatch_to_device)\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 267\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\loops\\loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\loops\\epoch\\training_epoch_loop.py:213\u001b[0m, in \u001b[0;36mTrainingEpochLoop.advance\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_started()\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 213\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[0;32m    217\u001b[0m \u001b[38;5;66;03m# update non-plateau LR schedulers\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# update epoch-interval ones only when we are at the end of training epoch\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\loops\\loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\loops\\batch\\training_batch_loop.py:88\u001b[0m, in \u001b[0;36mTrainingBatchLoop.advance\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[0;32m     85\u001b[0m     optimizers \u001b[38;5;241m=\u001b[39m _get_active_optimizers(\n\u001b[0;32m     86\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39moptimizers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39moptimizer_frequencies, kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_idx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     87\u001b[0m     )\n\u001b[1;32m---> 88\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     90\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanual_loop\u001b[38;5;241m.\u001b[39mrun(kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\loops\\loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\optimizer_loop.py:202\u001b[0m, in \u001b[0;36mOptimizerLoop.advance\u001b[1;34m(self, optimizers, kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madvance\u001b[39m(\u001b[38;5;28mself\u001b[39m, optimizers: List[Tuple[\u001b[38;5;28mint\u001b[39m, Optimizer]], kwargs: OrderedDict) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_kwargs(kwargs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_idx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hiddens)\n\u001b[1;32m--> 202\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim_progress\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_position\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    204\u001b[0m         \u001b[38;5;66;03m# automatic optimization assumes a loss needs to be returned for extras to be considered as the batch\u001b[39;00m\n\u001b[0;32m    205\u001b[0m         \u001b[38;5;66;03m# would be skipped otherwise\u001b[39;00m\n\u001b[0;32m    206\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_idx] \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39masdict()\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\optimizer_loop.py:249\u001b[0m, in \u001b[0;36mOptimizerLoop._run_optimization\u001b[1;34m(self, kwargs, optimizer)\u001b[0m\n\u001b[0;32m    241\u001b[0m         closure()\n\u001b[0;32m    243\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;66;03m# the `batch_idx` is optional with inter-batch parallelism\u001b[39;00m\n\u001b[1;32m--> 249\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_idx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;66;03m# if no result, user decided to skip optimization\u001b[39;00m\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;66;03m# otherwise update running loss + reset accumulated loss\u001b[39;00m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;66;03m# TODO: find proper way to handle updating running loss\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\optimizer_loop.py:370\u001b[0m, in \u001b[0;36mOptimizerLoop._optimizer_step\u001b[1;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[0;32m    362\u001b[0m     rank_zero_deprecation(\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe NVIDIA/apex AMP implementation has been deprecated upstream. Consequently, its integration inside\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m PyTorch Lightning has been deprecated in v1.9.0 and will be removed in v2.0.0.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    367\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m return True.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    368\u001b[0m     )\n\u001b[0;32m    369\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing_native_amp\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprecision_plugin, MixedPrecisionPlugin)\n\u001b[1;32m--> 370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(\n\u001b[0;32m    371\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer_step\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    372\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mcurrent_epoch,\n\u001b[0;32m    373\u001b[0m     batch_idx,\n\u001b[0;32m    374\u001b[0m     optimizer,\n\u001b[0;32m    375\u001b[0m     opt_idx,\n\u001b[0;32m    376\u001b[0m     train_step_and_backward_closure,\n\u001b[0;32m    377\u001b[0m     on_tpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39maccelerator, TPUAccelerator),\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    379\u001b[0m     using_lbfgs\u001b[38;5;241m=\u001b[39mis_lbfgs,\n\u001b[0;32m    380\u001b[0m )\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_completed()\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1347\u001b[0m, in \u001b[0;36mTrainer._call_lightning_module_hook\u001b[1;34m(self, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1344\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m hook_name\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1347\u001b[0m     output \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1349\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m   1350\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\core\\module.py:1744\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[1;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_lbfgs)\u001b[0m\n\u001b[0;32m   1665\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimizer_step\u001b[39m(\n\u001b[0;32m   1666\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1667\u001b[0m     epoch: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1673\u001b[0m     using_lbfgs: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1674\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1675\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1676\u001b[0m \u001b[38;5;124;03m    Override this method to adjust the default way the :class:`~lightning.pytorch.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;124;03m    each optimizer.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \n\u001b[0;32m   1743\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1744\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\core\\optimizer.py:169\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[1;34m(self, closure, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 169\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy\u001b[38;5;241m.\u001b[39moptimizer_step(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_idx, closure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\strategies\\strategy.py:234\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[1;34m(self, optimizer, opt_idx, closure, model, **kwargs)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;66;03m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[1;32m--> 234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39moptimizer_step(\n\u001b[0;32m    235\u001b[0m     optimizer, model\u001b[38;5;241m=\u001b[39mmodel, optimizer_idx\u001b[38;5;241m=\u001b[39mopt_idx, closure\u001b[38;5;241m=\u001b[39mclosure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    236\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\precision_plugin.py:119\u001b[0m, in \u001b[0;36mPrecisionPlugin.optimizer_step\u001b[1;34m(self, optimizer, model, optimizer_idx, closure, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[39;00m\n\u001b[0;32m    118\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_closure, model, optimizer, optimizer_idx, closure)\n\u001b[1;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m optimizer\u001b[38;5;241m.\u001b[39mstep(closure\u001b[38;5;241m=\u001b[39mclosure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:68\u001b[0m, in \u001b[0;36m_LRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     67\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m---> 68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\torch\\optim\\optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m--> 140\u001b[0m     out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\torch\\optim\\optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     22\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 23\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\torch\\optim\\adam.py:183\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[1;32m--> 183\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[0;32m    186\u001b[0m     params_with_grad \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\precision_plugin.py:105\u001b[0m, in \u001b[0;36mPrecisionPlugin._wrap_closure\u001b[1;34m(self, model, optimizer, optimizer_idx, closure)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap_closure\u001b[39m(\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     94\u001b[0m     model: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     97\u001b[0m     closure: Callable[[], Any],\n\u001b[0;32m     98\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m     99\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03m    ``on_before_optimizer_step`` hook is called.\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \n\u001b[0;32m    102\u001b[0m \u001b[38;5;124;03m    The closure (generally) runs ``backward`` so this allows inspecting gradients in this hook. This structure is\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m    consistent with the ``PrecisionPlugin`` subclasses that cannot pass ``optimizer.step(closure)`` directly.\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m     closure_result \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_closure(model, optimizer, optimizer_idx)\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m closure_result\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\optimizer_loop.py:149\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[1;32m--> 149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclosure(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\optimizer_loop.py:135\u001b[0m, in \u001b[0;36mClosure.closure\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ClosureResult:\n\u001b[1;32m--> 135\u001b[0m     step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    138\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarning_cache\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`training_step` returned `None`. If this was on purpose, ignore this warning...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\optimizer_loop.py:419\u001b[0m, in \u001b[0;36mOptimizerLoop._training_step\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Performs the actual train step with the tied hooks.\u001b[39;00m\n\u001b[0;32m    411\u001b[0m \n\u001b[0;32m    412\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;124;03m    A ``ClosureResult`` containing the training step output.\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;66;03m# manually capture logged metrics\u001b[39;00m\n\u001b[1;32m--> 419\u001b[0m training_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mpost_training_step()\n\u001b[0;32m    422\u001b[0m model_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_step_end\u001b[39m\u001b[38;5;124m\"\u001b[39m, training_step_output)\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1485\u001b[0m, in \u001b[0;36mTrainer._call_strategy_hook\u001b[1;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1484\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1485\u001b[0m     output \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1487\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m   1488\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\lightning\\pytorch\\strategies\\strategy.py:378\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mtrain_step_context():\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, TrainingStep)\n\u001b[1;32m--> 378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtraining_step(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\DeepLearningEnergyForecasting\\src\\deep_learning\\lstm.py:97\u001b[0m, in \u001b[0;36mStatefulQuantileLSTM.training_step\u001b[1;34m(self, batch, batch_idx)\u001b[0m\n\u001b[0;32m     94\u001b[0m input_seq \u001b[38;5;241m=\u001b[39m new_input_seq\n\u001b[0;32m     95\u001b[0m output_seq \u001b[38;5;241m=\u001b[39m output_sequences[:, h, :]\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m---> 97\u001b[0m last_hidden_states, last_cell_states, preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprev_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprev_hiddens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_cells\u001b[49m\u001b[43m[\u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m prev_hiddens\u001b[38;5;241m.\u001b[39mappend(last_hidden_states\u001b[38;5;241m.\u001b[39mdetach())\n\u001b[0;32m    102\u001b[0m prev_cells\u001b[38;5;241m.\u001b[39mappend(last_cell_states\u001b[38;5;241m.\u001b[39mdetach())\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\DeepLearningEnergyForecasting\\src\\deep_learning\\lstm.py:54\u001b[0m, in \u001b[0;36mStatefulQuantileLSTM.forward\u001b[1;34m(self, input_chunk, prev_states)\u001b[0m\n\u001b[0;32m     52\u001b[0m     lstm_output, (last_hidden_states, last_cell_states) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(input_chunk)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 54\u001b[0m     lstm_output, (last_hidden_states, last_cell_states) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer(lstm_output[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m last_hidden_states, last_cell_states, preds\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:774\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 774\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    777\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    778\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 4.00 GiB total capacity; 3.45 GiB already allocated; 0 bytes free; 3.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# ì¬ì‹œì‘ í›„, ë‹¤ì‹œ ë¶ˆëŸ¬ì™€ì„œ ì´ì–´ì„œ í•  ë•Œ\n",
    "import pickle\n",
    "with open(\"c:/Users/Daniel/DeepLearningEnergyForecasting/study_lstm.pkl\", \"rb\") as f:\n",
    "    study_lstm = pickle.load(f)\n",
    "\n",
    "# ê·¸ë¦¬ê³  ë‹¤ì‹œ\n",
    "study_lstm.optimize(objective_lstm, n_trials=50 - len(study_lstm.trials), show_progress_bar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3a8f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# âœ… í†µì¼ëœ ê²½ë¡œ ì„¤ì •\n",
    "project_root = \"C:/Users/Daniel/DeepLearningEnergyForecasting\"\n",
    "log_path = os.path.join(project_root, \"data\", \"tuning_logs\")\n",
    "os.makedirs(log_path, exist_ok=True)\n",
    "\n",
    "# âœ… ì €ì¥\n",
    "export_trial_no = \"1\"\n",
    "trials_lstm = study_lstm.trials_dataframe().sort_values(\"value\", ascending=True)\n",
    "trials_lstm.to_csv(os.path.join(log_path, f\"trials_lstm{export_trial_no}.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d425b0d3-852e-4f68-9c2f-eba6f18d3043",
   "metadata": {},
   "source": [
    "## Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e30c250-b6c3-4770-9956-38d58f666135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "import_trial_no = \"1\"\n",
    "best_trial_lstm = pd.read_csv(os.path.join(log_path, f\"trials_lstm{import_trial_no}.csv\")).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6faea85-1885-4e39-858c-7b98e529c0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f49e3d8-26e5-44b1-af10-848cfb0bd0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hyperparameters dict\n",
    "hyperparameters_dict = {\n",
    "    \"output_length\": output_length,\n",
    "    \"input_size\": input_dims,\n",
    "    \"horizon_start\": horizon_start,\n",
    "    \"quantiles\": quantiles,\n",
    "    \"learning_rate\": best_trial_lstm[\"params_learning_rate\"],\n",
    "    \"lr_decay\": best_trial_lstm[\"params_lr_decay\"],\n",
    "    \"num_layers\": best_trial_lstm[\"params_num_layers\"],\n",
    "    \"hidden_size\": int(2 ** best_trial_lstm[\"params_hidden_size_pw\"]),\n",
    "    \"dropout_rate\": best_trial_lstm[\"params_dropout_rate\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6517c633-90b1-49f0-8ae1-1e3b4ab87314",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial_id = int(best_trial_lstm[\"number\"])\n",
    "best_trial_full = study_lstm.trials[best_trial_id]  # Optuna Trial ê°ì²´\n",
    "\n",
    "n_epochs = best_trial_full.user_attrs.get(\"n_epochs\", 30)  # ì—†ìœ¼ë©´ 30\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=n_epochs,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    precision=32,\n",
    "    enable_model_summary=True,\n",
    "    logger=False,\n",
    "    enable_progress_bar=False,\n",
    "    enable_checkpointing=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa853b4b-e694-4c14-a14a-84eaf6bae6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "# Create & train model\n",
    "model = StatefulQuantileLSTM(hyperparameters_dict)\n",
    "trainer.fit(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b66ee1e-d4cc-47d6-8298-656e219725c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data & backtransform scaled values\n",
    "preds_raw = trainer.predict(model, test_loader)\n",
    "preds_raw = torch.cat(preds_raw, dim = 0).cpu().numpy().astype(np.float32)\n",
    "preds = scaler_test.backtransform_preds(preds_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a723191c-a3b1-4a96-8298-988e7c1163d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine back prediction sequences with times\n",
    "df_preds = predictions_to_dataframe(preds, test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e257d78-6ee2-4987-9884-3d66ce4fd31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2612b0c0-ad61-4ed9-a69c-30b3919116b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine back testing output sequences with input sequences & times\n",
    "df_test = test_sequences_to_dataframe(test_input, test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8b9fd9-f804-47d9-876b-3d0fc3959d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73239262-7730-4f87-b4c9-a2951a3f328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted vs. actual plot, hourly, entire test period\n",
    "_ = plot_actual_predicted(df_test, df_preds, \"Stateful LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bc5993-8e19-48f9-b1d6-db9f1c66b28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted vs. actual plots, zoomed in\n",
    "indices = [i for i in range(0, len(test_output), len(test_output) // 4)]\n",
    "indices.append(len(test_output) - 1)\n",
    "for idx in indices:\n",
    "    _ = plot_sequence_preds(preds, test_input, test_output, \"Stateful LSTM\", sequence_index = idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ee5b6c-8634-4622-8074-32c44a40ab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance metrics: MAE, RMSLE, MAPE, pinball loss\n",
    "calculate_metrics(df_test, df_preds, \"Stateful LSTM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d58f5e-0e4e-4ead-bc40-23152ccf4885",
   "metadata": {},
   "source": [
    "Keep in mind that for the median quantile, pinball loss equals MAE / 2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
