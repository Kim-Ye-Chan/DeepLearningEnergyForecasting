{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8917e856-0b5b-40a0-b9de-3efee4cecab0",
   "metadata": {
    "id": "8917e856-0b5b-40a0-b9de-3efee4cecab0"
   },
   "source": [
    "This notebook applies an inverted Transformer model using PyTorch & Lightning, to get multi-step quantile energy consumption forecasts.\n",
    "\n",
    "It also performs & demonstrates the necessary data handling & preprocessing steps to get source & target sequences for the Transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "Jj6L1r-NrfuA",
   "metadata": {
    "id": "Jj6L1r-NrfuA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ CWD: C:\\Users\\Daniel\\DeepLearningEnergyForecasting\n",
      "ğŸ“ src/deep_learning exists?: True\n",
      "âœ… BASE_DIR: C:/Users/Daniel/DeepLearningEnergyForecasting\n",
      "âœ… SAFE_ROOT: C:/Users/Daniel/DeepLearningEnergyForecasting\\pl_work\n",
      "âœ… OPT_LOG_DIR: C:/Users/Daniel/DeepLearningEnergyForecasting\\opt_logs\n",
      "âœ… FINAL_DIR: C:/Users/Daniel/DeepLearningEnergyForecasting\\TimesNet_final_run\n",
      "âœ… S1_PATH: C:/Users/Daniel/DeepLearningEnergyForecasting\\TimesNet_study_s1.pkl\n",
      "âœ… S2_PATH: C:/Users/Daniel/DeepLearningEnergyForecasting\\TimesNet_study_s2.pkl\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# Robust Project Bootstrap (Colab/Drive-safe)\n",
    "# ===========================\n",
    "import os, sys, pickle, warnings\n",
    "\n",
    "# --- í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì„¤ì • ---\n",
    "PROJECT_ROOT = \"C:/Users/Daniel/DeepLearningEnergyForecasting\"\n",
    "\n",
    "def ensure_dir(path: str) -> str:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    return path\n",
    "\n",
    "def safe_chdir(path: str, fallback: str = \"/content\") -> None:\n",
    "    \"\"\"ì‘ì—… ë””ë ‰í† ë¦¬ê°€ ì‚¬ë¼ì¡Œê±°ë‚˜ ê¶Œí•œ ë¬¸ì œì¼ ë•Œë„ ì•ˆì „í•˜ê²Œ ì´ë™.\"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(path):\n",
    "            warnings.warn(f\"[bootstrap] path not found: {path}  â†’ creating it.\")\n",
    "            ensure_dir(path)\n",
    "        os.chdir(path)\n",
    "    except Exception as e:\n",
    "        warnings.warn(f\"[bootstrap] chdir({path}) failed: {e}  â†’ chdir({fallback})\")\n",
    "        ensure_dir(fallback)\n",
    "        os.chdir(fallback)\n",
    "\n",
    "# í˜„ì¬ CWD ì ê²€(ì‚¬ë¼ì¡Œì„ ìˆ˜ ìˆìŒ)\n",
    "try:\n",
    "    _ = os.getcwd()\n",
    "except FileNotFoundError:\n",
    "    os.chdir(\"/content\")\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¡œ ì´ë™(ë³µêµ¬ í¬í•¨)\n",
    "safe_chdir(PROJECT_ROOT)\n",
    "\n",
    "# --- sys.path ë“±ë¡(idempotent) ---\n",
    "def _add_path(p: str):\n",
    "    if p and p not in sys.path:\n",
    "        sys.path.insert(0, p)\n",
    "\n",
    "_add_path(PROJECT_ROOT)\n",
    "SRC_PATH = os.path.join(PROJECT_ROOT, \"src\")\n",
    "_add_path(SRC_PATH)\n",
    "\n",
    "print(\"ğŸ“‚ CWD:\", os.getcwd())\n",
    "print(\"ğŸ“ src/deep_learning exists?:\", os.path.exists(os.path.join(SRC_PATH, \"deep_learning\")))\n",
    "\n",
    "# --- ê³µí†µ ê²½ë¡œ ìƒìˆ˜ ---\n",
    "BASE_DIR    = PROJECT_ROOT\n",
    "SAFE_ROOT   = ensure_dir(os.path.join(BASE_DIR, \"pl_work\"))      # Lightning default_root_dir\n",
    "OPT_LOG_DIR = ensure_dir(os.path.join(BASE_DIR, \"opt_logs\"))     # Optuna/CSVLogger ë“±\n",
    "FINAL_DIR   = ensure_dir(os.path.join(BASE_DIR, \"TimesNet_final_run\"))\n",
    "\n",
    "S1_PATH = os.path.join(BASE_DIR, \"TimesNet_study_s1.pkl\")\n",
    "S2_PATH = os.path.join(BASE_DIR, \"TimesNet_study_s2.pkl\")\n",
    "\n",
    "# --- ìœ í‹¸ ---\n",
    "def load_study(path: str):\n",
    "    \"\"\"Optuna study pkl ë¡œë“œ. ì—†ìœ¼ë©´ None.\"\"\"\n",
    "    try:\n",
    "        with open(path, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def save_study(study, path: str):\n",
    "    \"\"\"Optuna study pkl ì €ì¥(ë¶€ëª¨ í´ë” ë³´ì¥).\"\"\"\n",
    "    ensure_dir(os.path.dirname(path))\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(study, f)\n",
    "\n",
    "# --- í’ˆì§ˆ ë¡œê·¸ ---\n",
    "print(\"âœ… BASE_DIR:\", BASE_DIR)\n",
    "print(\"âœ… SAFE_ROOT:\", SAFE_ROOT)\n",
    "print(\"âœ… OPT_LOG_DIR:\", OPT_LOG_DIR)\n",
    "print(\"âœ… FINAL_DIR:\", FINAL_DIR)\n",
    "print(\"âœ… S1_PATH:\", S1_PATH)\n",
    "print(\"âœ… S2_PATH:\", S2_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dATS5Y5MxJkJ",
   "metadata": {
    "id": "dATS5Y5MxJkJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightning in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (1.9.0)\n",
      "Requirement already satisfied: Jinja2<5.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning) (3.1.6)\n",
      "Requirement already satisfied: PyYAML<8.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning) (6.0.2)\n",
      "Requirement already satisfied: arrow<3.0,>=1.2.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning) (1.3.0)\n",
      "Requirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning) (4.13.4)\n",
      "Requirement already satisfied: click<10.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning) (8.1.8)\n",
      "Requirement already satisfied: croniter<1.4.0,>=1.3.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning) (1.3.15)\n",
      "Requirement already satisfied: dateutils<2.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning) (0.6.12)\n",
      "Requirement already satisfied: deepdiff<8.0,>=5.7.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning) (7.0.1)\n",
      "Requirement already satisfied: fastapi<0.89.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning) (0.88.0)\n",
      "Requirement already satisfied: fsspec<2024.0,>=2022.5.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning) (2023.12.2)\n",
      "Requirement already satisfied: inquirer<5.0,>=2.10.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning) (3.4.0)\n",
      "Requirement already satisfied: lightning-cloud<2.0,>=0.5.12 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning) (0.5.70)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.4.2 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning) (0.11.9)\n",
      "Requirement already satisfied: numpy<3.0,>=1.17.2 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning) (2.0.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning) (22.0)\n",
      "Requirement already satisfied: psutil<7.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning) (5.9.0)\n",
      "Requirement already satisfied: pydantic<3.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning) (1.10.22)\n",
      "Requirement already satisfied: requests<4.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning) (2.32.4)\n",
      "Requirement already satisfied: rich<15.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning) (13.3.5)\n",
      "Requirement already satisfied: starlette<2.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning) (0.22.0)\n",
      "Requirement already satisfied: starsessions<2.0,>=1.2.1 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning) (1.3.0)\n",
      "Requirement already satisfied: torch<3.0,>=1.10.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning) (1.13.0+cu116)\n",
      "Requirement already satisfied: torchmetrics<2.0,>=0.7.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning) (1.5.2)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning) (4.67.1)\n",
      "Requirement already satisfied: traitlets<7.0,>=5.3.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning) (5.14.3)\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning) (4.12.2)\n",
      "Requirement already satisfied: urllib3<3.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning) (1.26.20)\n",
      "Requirement already satisfied: uvicorn<2.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning) (0.33.0)\n",
      "Requirement already satisfied: websocket-client<3.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning) (1.8.0)\n",
      "Requirement already satisfied: websockets<12.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning) (11.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from arrow<3.0,>=1.2.0->lightning) (2.9.0.post0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from arrow<3.0,>=1.2.0->lightning) (2.9.0.20241206)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from beautifulsoup4<6.0,>=4.8.0->lightning) (2.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from click<10.0->lightning) (0.4.6)\n",
      "Requirement already satisfied: pytz in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from dateutils<2.0->lightning) (2025.2)\n",
      "Requirement already satisfied: ordered-set<4.2.0,>=4.1.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from deepdiff<8.0,>=5.7.0->lightning) (4.1.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from starlette<2.0->lightning) (4.5.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<2.0->lightning) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<2.0->lightning) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<2.0->lightning) (1.3.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from fsspec[http]<2024.0,>2021.06.0->lightning) (3.10.11)\n",
      "Requirement already satisfied: blessed>=1.19.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from inquirer<5.0,>=2.10.0->lightning) (1.21.0)\n",
      "Requirement already satisfied: editor>=1.6.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from inquirer<5.0,>=2.10.0->lightning) (1.6.6)\n",
      "Requirement already satisfied: readchar>=4.2.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from inquirer<5.0,>=2.10.0->lightning) (4.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from Jinja2<5.0->lightning) (2.1.5)\n",
      "Requirement already satisfied: pyjwt in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning-cloud<2.0,>=0.5.12->lightning) (2.9.0)\n",
      "Requirement already satisfied: python-multipart in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning-cloud<2.0,>=0.5.12->lightning) (0.0.20)\n",
      "Requirement already satisfied: six in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning-cloud<2.0,>=0.5.12->lightning) (1.16.0)\n",
      "Requirement already satisfied: boto3 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning-cloud<2.0,>=0.5.12->lightning) (1.37.38)\n",
      "Requirement already satisfied: protobuf in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning-cloud<2.0,>=0.5.12->lightning) (5.29.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning-utilities<2.0,>=0.4.2->lightning) (72.1.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from requests<4.0->lightning) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from requests<4.0->lightning) (2025.7.14)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from rich<15.0->lightning) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from rich<15.0->lightning) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich<15.0->lightning) (0.1.2)\n",
      "Requirement already satisfied: itsdangerous<3.0.0,>=2.0.1 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from starsessions<2.0,>=1.2.1->lightning) (2.2.0)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from uvicorn<2.0->lightning) (0.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2024.0,>2021.06.0->lightning) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2024.0,>2021.06.0->lightning) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2024.0,>2021.06.0->lightning) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2024.0,>2021.06.0->lightning) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2024.0,>2021.06.0->lightning) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2024.0,>2021.06.0->lightning) (1.15.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2024.0,>2021.06.0->lightning) (5.0.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2024.0,>2021.06.0->lightning) (0.2.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.4 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning) (0.2.13)\n",
      "Requirement already satisfied: jinxed>=1.1.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning) (1.3.0)\n",
      "Requirement already satisfied: runs in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from editor>=1.6.0->inquirer<5.0,>=2.10.0->lightning) (1.2.2)\n",
      "Requirement already satisfied: xmod in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from editor>=1.6.0->inquirer<5.0,>=2.10.0->lightning) (1.8.1)\n",
      "Requirement already satisfied: ansicon in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from jinxed>=1.1.0->blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning) (1.89.0)\n",
      "Requirement already satisfied: botocore<1.38.0,>=1.37.38 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from boto3->lightning-cloud<2.0,>=0.5.12->lightning) (1.37.38)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from boto3->lightning-cloud<2.0,>=0.5.12->lightning) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from boto3->lightning-cloud<2.0,>=0.5.12->lightning) (0.11.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: optuna in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (4.4.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from optuna) (1.14.1)\n",
      "Requirement already satisfied: colorlog in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from optuna) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from optuna) (22.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from optuna) (2.0.41)\n",
      "Requirement already satisfied: tqdm in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: Mako in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: optuna-integration[pytorch_lightning] in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (4.4.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: optuna in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from optuna-integration[pytorch_lightning]) (4.4.0)\n",
      "Requirement already satisfied: lightning in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from optuna-integration[pytorch_lightning]) (1.9.0)\n",
      "Requirement already satisfied: Jinja2<5.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning->optuna-integration[pytorch_lightning]) (3.1.6)\n",
      "Requirement already satisfied: PyYAML<8.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning->optuna-integration[pytorch_lightning]) (6.0.2)\n",
      "Requirement already satisfied: arrow<3.0,>=1.2.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning->optuna-integration[pytorch_lightning]) (1.3.0)\n",
      "Requirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning->optuna-integration[pytorch_lightning]) (4.13.4)\n",
      "Requirement already satisfied: click<10.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning->optuna-integration[pytorch_lightning]) (8.1.8)\n",
      "Requirement already satisfied: croniter<1.4.0,>=1.3.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning->optuna-integration[pytorch_lightning]) (1.3.15)\n",
      "Requirement already satisfied: dateutils<2.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning->optuna-integration[pytorch_lightning]) (0.6.12)\n",
      "Requirement already satisfied: deepdiff<8.0,>=5.7.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning->optuna-integration[pytorch_lightning]) (7.0.1)\n",
      "Requirement already satisfied: fastapi<0.89.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning->optuna-integration[pytorch_lightning]) (0.88.0)\n",
      "Requirement already satisfied: fsspec<2024.0,>=2022.5.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning->optuna-integration[pytorch_lightning]) (2023.12.2)\n",
      "Requirement already satisfied: inquirer<5.0,>=2.10.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning->optuna-integration[pytorch_lightning]) (3.4.0)\n",
      "Requirement already satisfied: lightning-cloud<2.0,>=0.5.12 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning->optuna-integration[pytorch_lightning]) (0.5.70)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.4.2 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning->optuna-integration[pytorch_lightning]) (0.11.9)\n",
      "Requirement already satisfied: numpy<3.0,>=1.17.2 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning->optuna-integration[pytorch_lightning]) (2.0.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning->optuna-integration[pytorch_lightning]) (22.0)\n",
      "Requirement already satisfied: psutil<7.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning->optuna-integration[pytorch_lightning]) (5.9.0)\n",
      "Requirement already satisfied: pydantic<3.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning->optuna-integration[pytorch_lightning]) (1.10.22)\n",
      "Requirement already satisfied: requests<4.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning->optuna-integration[pytorch_lightning]) (2.32.4)\n",
      "Requirement already satisfied: rich<15.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning->optuna-integration[pytorch_lightning]) (13.3.5)\n",
      "Requirement already satisfied: starlette<2.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning->optuna-integration[pytorch_lightning]) (0.22.0)\n",
      "Requirement already satisfied: starsessions<2.0,>=1.2.1 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning->optuna-integration[pytorch_lightning]) (1.3.0)\n",
      "Requirement already satisfied: torch<3.0,>=1.10.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning->optuna-integration[pytorch_lightning]) (1.13.0+cu116)\n",
      "Requirement already satisfied: torchmetrics<2.0,>=0.7.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning->optuna-integration[pytorch_lightning]) (1.5.2)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning->optuna-integration[pytorch_lightning]) (4.67.1)\n",
      "Requirement already satisfied: traitlets<7.0,>=5.3.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning->optuna-integration[pytorch_lightning]) (5.14.3)\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning->optuna-integration[pytorch_lightning]) (4.12.2)\n",
      "Requirement already satisfied: urllib3<3.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning->optuna-integration[pytorch_lightning]) (1.26.20)\n",
      "Requirement already satisfied: uvicorn<2.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning->optuna-integration[pytorch_lightning]) (0.33.0)\n",
      "Requirement already satisfied: websocket-client<3.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning->optuna-integration[pytorch_lightning]) (1.8.0)\n",
      "Requirement already satisfied: websockets<12.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning->optuna-integration[pytorch_lightning]) (11.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from arrow<3.0,>=1.2.0->lightning->optuna-integration[pytorch_lightning]) (2.9.0.post0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from arrow<3.0,>=1.2.0->lightning->optuna-integration[pytorch_lightning]) (2.9.0.20241206)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from beautifulsoup4<6.0,>=4.8.0->lightning->optuna-integration[pytorch_lightning]) (2.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from click<10.0->lightning->optuna-integration[pytorch_lightning]) (0.4.6)\n",
      "Requirement already satisfied: pytz in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from dateutils<2.0->lightning->optuna-integration[pytorch_lightning]) (2025.2)\n",
      "Requirement already satisfied: ordered-set<4.2.0,>=4.1.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from deepdiff<8.0,>=5.7.0->lightning->optuna-integration[pytorch_lightning]) (4.1.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from starlette<2.0->lightning->optuna-integration[pytorch_lightning]) (4.5.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<2.0->lightning->optuna-integration[pytorch_lightning]) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<2.0->lightning->optuna-integration[pytorch_lightning]) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<2.0->lightning->optuna-integration[pytorch_lightning]) (1.3.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from fsspec[http]<2024.0,>2021.06.0->lightning->optuna-integration[pytorch_lightning]) (3.10.11)\n",
      "Requirement already satisfied: blessed>=1.19.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from inquirer<5.0,>=2.10.0->lightning->optuna-integration[pytorch_lightning]) (1.21.0)\n",
      "Requirement already satisfied: editor>=1.6.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from inquirer<5.0,>=2.10.0->lightning->optuna-integration[pytorch_lightning]) (1.6.6)\n",
      "Requirement already satisfied: readchar>=4.2.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from inquirer<5.0,>=2.10.0->lightning->optuna-integration[pytorch_lightning]) (4.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from Jinja2<5.0->lightning->optuna-integration[pytorch_lightning]) (2.1.5)\n",
      "Requirement already satisfied: pyjwt in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning-cloud<2.0,>=0.5.12->lightning->optuna-integration[pytorch_lightning]) (2.9.0)\n",
      "Requirement already satisfied: python-multipart in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning-cloud<2.0,>=0.5.12->lightning->optuna-integration[pytorch_lightning]) (0.0.20)\n",
      "Requirement already satisfied: six in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning-cloud<2.0,>=0.5.12->lightning->optuna-integration[pytorch_lightning]) (1.16.0)\n",
      "Requirement already satisfied: boto3 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning-cloud<2.0,>=0.5.12->lightning->optuna-integration[pytorch_lightning]) (1.37.38)\n",
      "Requirement already satisfied: protobuf in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning-cloud<2.0,>=0.5.12->lightning->optuna-integration[pytorch_lightning]) (5.29.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from lightning-utilities<2.0,>=0.4.2->lightning->optuna-integration[pytorch_lightning]) (72.1.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from requests<4.0->lightning->optuna-integration[pytorch_lightning]) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from requests<4.0->lightning->optuna-integration[pytorch_lightning]) (2025.7.14)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from rich<15.0->lightning->optuna-integration[pytorch_lightning]) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from rich<15.0->lightning->optuna-integration[pytorch_lightning]) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich<15.0->lightning->optuna-integration[pytorch_lightning]) (0.1.2)\n",
      "Requirement already satisfied: itsdangerous<3.0.0,>=2.0.1 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from starsessions<2.0,>=1.2.1->lightning->optuna-integration[pytorch_lightning]) (2.2.0)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from uvicorn<2.0->lightning->optuna-integration[pytorch_lightning]) (0.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2024.0,>2021.06.0->lightning->optuna-integration[pytorch_lightning]) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2024.0,>2021.06.0->lightning->optuna-integration[pytorch_lightning]) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2024.0,>2021.06.0->lightning->optuna-integration[pytorch_lightning]) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2024.0,>2021.06.0->lightning->optuna-integration[pytorch_lightning]) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2024.0,>2021.06.0->lightning->optuna-integration[pytorch_lightning]) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2024.0,>2021.06.0->lightning->optuna-integration[pytorch_lightning]) (1.15.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2024.0,>2021.06.0->lightning->optuna-integration[pytorch_lightning]) (5.0.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2024.0,>2021.06.0->lightning->optuna-integration[pytorch_lightning]) (0.2.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.4 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning->optuna-integration[pytorch_lightning]) (0.2.13)\n",
      "Requirement already satisfied: jinxed>=1.1.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning->optuna-integration[pytorch_lightning]) (1.3.0)\n",
      "Requirement already satisfied: runs in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from editor>=1.6.0->inquirer<5.0,>=2.10.0->lightning->optuna-integration[pytorch_lightning]) (1.2.2)\n",
      "Requirement already satisfied: xmod in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from editor>=1.6.0->inquirer<5.0,>=2.10.0->lightning->optuna-integration[pytorch_lightning]) (1.8.1)\n",
      "Requirement already satisfied: ansicon in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from jinxed>=1.1.0->blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning->optuna-integration[pytorch_lightning]) (1.89.0)\n",
      "Requirement already satisfied: botocore<1.38.0,>=1.37.38 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from boto3->lightning-cloud<2.0,>=0.5.12->lightning->optuna-integration[pytorch_lightning]) (1.37.38)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from boto3->lightning-cloud<2.0,>=0.5.12->lightning->optuna-integration[pytorch_lightning]) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from boto3->lightning-cloud<2.0,>=0.5.12->lightning->optuna-integration[pytorch_lightning]) (0.11.5)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from optuna->optuna-integration[pytorch_lightning]) (1.14.1)\n",
      "Requirement already satisfied: colorlog in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from optuna->optuna-integration[pytorch_lightning]) (6.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from optuna->optuna-integration[pytorch_lightning]) (2.0.41)\n",
      "Requirement already satisfied: Mako in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from alembic>=1.5.0->optuna->optuna-integration[pytorch_lightning]) (1.3.10)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\daniel\\anaconda3\\envs\\aiot\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna->optuna-integration[pytorch_lightning]) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "%pip install lightning\n",
    "%pip install optuna\n",
    "%pip install optuna-integration[pytorch_lightning]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OkO2SZu9jmhN",
   "metadata": {
    "id": "OkO2SZu9jmhN"
   },
   "outputs": [],
   "source": [
    "# ==== imports (êµì²´ë³¸) ====\n",
    "import math\n",
    "import warnings  # í•„ìš” ì—†ìœ¼ë©´ ì§€ì›Œë„ ë¨\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import lightning as L\n",
    "import optuna\n",
    "import types, importlib, sys\n",
    "sys.modules['imp'] = types.SimpleNamespace(reload=importlib.reload)\n",
    "\n",
    "from lightning.pytorch.callbacks import EarlyStopping   # âœ… ì¶”ê°€\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "\n",
    "from src.deep_learning.preprocessing import SequenceScaler, SequenceDataset, SequenceDatasetWithBld\n",
    "from src.deep_learning.quantile_loss import QuantileLoss\n",
    "from src.deep_learning.TimesNet import TimesNet\n",
    "from src.deep_learning.testing import (\n",
    "    train_val_split, train_val_split_const_batch_size,\n",
    "    test_sequences_to_dataframe, plot_actual_predicted,\n",
    "    plot_sequence_preds, calculate_metrics\n",
    ")\n",
    "from src.deep_learning.prediction import predictions_to_dataframe\n",
    "\n",
    "# (ì„ íƒ) ê²½ê³  ì–µì œ\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"lightning\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e71e0c-c3b7-412d-a8b3-35c750a66899",
   "metadata": {
    "id": "f5e71e0c-c3b7-412d-a8b3-35c750a66899"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb5262f-36ee-4d06-9457-771df657d8ab",
   "metadata": {
    "id": "cbb5262f-36ee-4d06-9457-771df657d8ab"
   },
   "outputs": [],
   "source": [
    "random_seed = 1923"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b59f93-6e6e-4fdb-8a8b-53a7551ba5b7",
   "metadata": {
    "id": "f0b59f93-6e6e-4fdb-8a8b-53a7551ba5b7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1923\n"
     ]
    }
   ],
   "source": [
    "# Set Torch settings\n",
    "torch.set_default_dtype(torch.float32)\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "L.seed_everything(random_seed, workers = True)\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f04ab1c-13d2-43b0-9fef-de865238c890",
   "metadata": {
    "id": "4f04ab1c-13d2-43b0-9fef-de865238c890"
   },
   "outputs": [],
   "source": [
    "# Plot settings\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ScfYmeWcxyGY",
   "metadata": {
    "id": "ScfYmeWcxyGY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¡œì»¬ ê²½ë¡œì—ì„œ ë°ì´í„° ë¡œë”© ì™„ë£Œ.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# --- 1. Google Drive ê²½ë¡œì— ìˆëŠ” ë°ì´í„° íŒŒì¼ì„ Colab ë¡œì»¬ë¡œ ë³µì‚¬ ---\n",
    "\n",
    "# ì›ë³¸ íŒŒì¼ì´ ìˆëŠ” Google Drive ê²½ë¡œ\n",
    "local_train_path = \"C:/Users/Daniel/DeepLearningEnergyForecasting/data/analysis/processed/train_advanced_featured.csv\"\n",
    "local_test_path = \"C:/Users/Daniel/DeepLearningEnergyForecasting/data/analysis/processed/test_advanced_featured.csv\"\n",
    "\n",
    "# --- 2. ì´ì œë¶€í„°ëŠ” Colab ë¡œì»¬ ê²½ë¡œì—ì„œ ë°ì´í„°ë¥¼ ë¹ ë¥´ê²Œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤ ---\n",
    "\n",
    "# ìˆ˜ì • ì½”ë“œ\n",
    "train_df = pd.read_csv(local_train_path)\n",
    "test_df = pd.read_csv(local_test_path)\n",
    "\n",
    "print(\"ë¡œì»¬ ê²½ë¡œì—ì„œ ë°ì´í„° ë¡œë”© ì™„ë£Œ.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59o8FprOx2D-",
   "metadata": {
    "id": "59o8FprOx2D-"
   },
   "outputs": [],
   "source": [
    "train_df[\"ì¼ì‹œ\"] = pd.to_datetime(train_df[\"ì¼ì‹œ\"])\n",
    "test_df[\"ì¼ì‹œ\"] = pd.to_datetime(test_df[\"ì¼ì‹œ\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ab82ca-f92d-4c00-9b57-aff3d00637fb",
   "metadata": {
    "id": "57ab82ca-f92d-4c00-9b57-aff3d00637fb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ESSì €ì¥ìš©ëŸ‰(kWh)</th>\n",
       "      <th>PCSìš©ëŸ‰(kW)</th>\n",
       "      <th>month</th>\n",
       "      <th>ê±´ë¬¼ë²ˆí˜¸</th>\n",
       "      <th>ê±´ë¬¼ìœ í˜•_IDC(ì „í™”êµ­)</th>\n",
       "      <th>ê±´ë¬¼ìœ í˜•_ê±´ë¬¼ê¸°íƒ€</th>\n",
       "      <th>ê±´ë¬¼ìœ í˜•_ê³µê³µ</th>\n",
       "      <th>ê±´ë¬¼ìœ í˜•_ë°±í™”ì </th>\n",
       "      <th>ê±´ë¬¼ìœ í˜•_ë³‘ì›</th>\n",
       "      <th>ê±´ë¬¼ìœ í˜•_ìƒìš©</th>\n",
       "      <th>...</th>\n",
       "      <th>ì—°ë©´ì (m2)</th>\n",
       "      <th>ì¼ì‹œ</th>\n",
       "      <th>ì „ë ¥ì†Œë¹„ëŸ‰(kWh)</th>\n",
       "      <th>íƒœì–‘ê´‘ìš©ëŸ‰(kW)</th>\n",
       "      <th>consumption_lag_24h</th>\n",
       "      <th>trend</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>day_of_week_sin</th>\n",
       "      <th>day_of_week_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>2024-06-02 00:00:00</td>\n",
       "      <td>3870.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5794.80</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>2024-06-02 01:00:00</td>\n",
       "      <td>5733.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5591.85</td>\n",
       "      <td>25</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>2024-06-02 02:00:00</td>\n",
       "      <td>5689.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5338.17</td>\n",
       "      <td>26</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>2024-06-02 03:00:00</td>\n",
       "      <td>5579.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4554.42</td>\n",
       "      <td>27</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>2024-06-02 04:00:00</td>\n",
       "      <td>4113.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3602.25</td>\n",
       "      <td>28</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203971</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>162070.24</td>\n",
       "      <td>2024-08-24 19:00:00</td>\n",
       "      <td>3276.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2206.92</td>\n",
       "      <td>203995</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203972</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>162070.24</td>\n",
       "      <td>2024-08-24 20:00:00</td>\n",
       "      <td>3197.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2064.12</td>\n",
       "      <td>203996</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203973</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>162070.24</td>\n",
       "      <td>2024-08-24 21:00:00</td>\n",
       "      <td>3006.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1161.12</td>\n",
       "      <td>203997</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203974</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>162070.24</td>\n",
       "      <td>2024-08-24 22:00:00</td>\n",
       "      <td>2649.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2076.36</td>\n",
       "      <td>203998</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203975</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>162070.24</td>\n",
       "      <td>2024-08-24 23:00:00</td>\n",
       "      <td>2929.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2763.24</td>\n",
       "      <td>203999</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203976 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ESSì €ì¥ìš©ëŸ‰(kWh)  PCSìš©ëŸ‰(kW)  month  ê±´ë¬¼ë²ˆí˜¸  ê±´ë¬¼ìœ í˜•_IDC(ì „í™”êµ­)  ê±´ë¬¼ìœ í˜•_ê±´ë¬¼ê¸°íƒ€  \\\n",
       "0                0.0          0      6     1          False      False   \n",
       "1                0.0          0      6     1          False      False   \n",
       "2                0.0          0      6     1          False      False   \n",
       "3                0.0          0      6     1          False      False   \n",
       "4                0.0          0      6     1          False      False   \n",
       "...              ...        ...    ...   ...            ...        ...   \n",
       "203971           0.0          0      8   100          False      False   \n",
       "203972           0.0          0      8   100          False      False   \n",
       "203973           0.0          0      8   100          False      False   \n",
       "203974           0.0          0      8   100          False      False   \n",
       "203975           0.0          0      8   100          False      False   \n",
       "\n",
       "        ê±´ë¬¼ìœ í˜•_ê³µê³µ  ê±´ë¬¼ìœ í˜•_ë°±í™”ì   ê±´ë¬¼ìœ í˜•_ë³‘ì›  ê±´ë¬¼ìœ í˜•_ìƒìš©  ...    ì—°ë©´ì (m2)  \\\n",
       "0         False     False    False    False  ...   82912.71   \n",
       "1         False     False    False    False  ...   82912.71   \n",
       "2         False     False    False    False  ...   82912.71   \n",
       "3         False     False    False    False  ...   82912.71   \n",
       "4         False     False    False    False  ...   82912.71   \n",
       "...         ...       ...      ...      ...  ...        ...   \n",
       "203971    False     False    False    False  ...  162070.24   \n",
       "203972    False     False    False    False  ...  162070.24   \n",
       "203973    False     False    False    False  ...  162070.24   \n",
       "203974    False     False    False    False  ...  162070.24   \n",
       "203975    False     False    False    False  ...  162070.24   \n",
       "\n",
       "                        ì¼ì‹œ  ì „ë ¥ì†Œë¹„ëŸ‰(kWh)  íƒœì–‘ê´‘ìš©ëŸ‰(kW)  consumption_lag_24h  \\\n",
       "0      2024-06-02 00:00:00     3870.42        0.0              5794.80   \n",
       "1      2024-06-02 01:00:00     5733.45        0.0              5591.85   \n",
       "2      2024-06-02 02:00:00     5689.17        0.0              5338.17   \n",
       "3      2024-06-02 03:00:00     5579.04        0.0              4554.42   \n",
       "4      2024-06-02 04:00:00     4113.60        0.0              3602.25   \n",
       "...                    ...         ...        ...                  ...   \n",
       "203971 2024-08-24 19:00:00     3276.00        0.0              2206.92   \n",
       "203972 2024-08-24 20:00:00     3197.52        0.0              2064.12   \n",
       "203973 2024-08-24 21:00:00     3006.60        0.0              1161.12   \n",
       "203974 2024-08-24 22:00:00     2649.72        0.0              2076.36   \n",
       "203975 2024-08-24 23:00:00     2929.32        0.0              2763.24   \n",
       "\n",
       "         trend  hour_sin  hour_cos  day_of_week_sin  day_of_week_cos  \n",
       "0           24  0.000000  1.000000        -0.781831         0.623490  \n",
       "1           25  0.258819  0.965926        -0.781831         0.623490  \n",
       "2           26  0.500000  0.866025        -0.781831         0.623490  \n",
       "3           27  0.707107  0.707107        -0.781831         0.623490  \n",
       "4           28  0.866025  0.500000        -0.781831         0.623490  \n",
       "...        ...       ...       ...              ...              ...  \n",
       "203971  203995 -0.965926  0.258819        -0.974928        -0.222521  \n",
       "203972  203996 -0.866025  0.500000        -0.974928        -0.222521  \n",
       "203973  203997 -0.707107  0.707107        -0.974928        -0.222521  \n",
       "203974  203998 -0.500000  0.866025        -0.974928        -0.222521  \n",
       "203975  203999 -0.258819  0.965926        -0.974928        -0.222521  \n",
       "\n",
       "[203976 rows x 26 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s9G_2-T50TkQ",
   "metadata": {
    "id": "s9G_2-T50TkQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_test shape: (16800, 26)\n",
      "df_test columns: Index(['ESSì €ì¥ìš©ëŸ‰(kWh)', 'PCSìš©ëŸ‰(kW)', 'month', 'ê±´ë¬¼ë²ˆí˜¸', 'ê±´ë¬¼ìœ í˜•_IDC(ì „í™”êµ­)',\n",
      "       'ê±´ë¬¼ìœ í˜•_ê±´ë¬¼ê¸°íƒ€', 'ê±´ë¬¼ìœ í˜•_ê³µê³µ', 'ê±´ë¬¼ìœ í˜•_ë°±í™”ì ', 'ê±´ë¬¼ìœ í˜•_ë³‘ì›', 'ê±´ë¬¼ìœ í˜•_ìƒìš©', 'ê±´ë¬¼ìœ í˜•_ì•„íŒŒíŠ¸',\n",
      "       'ê±´ë¬¼ìœ í˜•_ì—°êµ¬ì†Œ', 'ê±´ë¬¼ìœ í˜•_í•™êµ', 'ê±´ë¬¼ìœ í˜•_í˜¸í…”', 'ê¸°ì˜¨(Â°C)', 'ëƒ‰ë°©ë©´ì (m2)', 'ì—°ë©´ì (m2)', 'ì¼ì‹œ',\n",
      "       'ì „ë ¥ì†Œë¹„ëŸ‰(kWh)', 'íƒœì–‘ê´‘ìš©ëŸ‰(kW)', 'hour_sin', 'hour_cos', 'day_of_week_sin',\n",
      "       'day_of_week_cos', 'consumption_lag_24h', 'trend'],\n",
      "      dtype='object')\n",
      "df_test head:    ê±´ë¬¼ë²ˆí˜¸                  ì¼ì‹œ  consumption_lag_24h  trend\n",
      "0     1 2024-08-25 00:00:00              4897.59      0\n",
      "1     1 2024-08-25 01:00:00              4664.22      1\n",
      "2     1 2024-08-25 02:00:00              3716.73      2\n",
      "3     1 2024-08-25 03:00:00              3073.47      3\n",
      "4     1 2024-08-25 04:00:00              3399.63      4\n",
      "df_test tail:        ê±´ë¬¼ë²ˆí˜¸                  ì¼ì‹œ  consumption_lag_24h  trend\n",
      "16795   100 2024-08-31 19:00:00          3329.432482  16795\n",
      "16796   100 2024-08-31 20:00:00          3329.432482  16796\n",
      "16797   100 2024-08-31 21:00:00          3329.432482  16797\n",
      "16798   100 2024-08-31 22:00:00          3329.432482  16798\n",
      "16799   100 2024-08-31 23:00:00          3329.432482  16799\n",
      "Missing consumption_lag_24h: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ESSì €ì¥ìš©ëŸ‰(kWh)</th>\n",
       "      <th>PCSìš©ëŸ‰(kW)</th>\n",
       "      <th>month</th>\n",
       "      <th>ê±´ë¬¼ë²ˆí˜¸</th>\n",
       "      <th>ê±´ë¬¼ìœ í˜•_IDC(ì „í™”êµ­)</th>\n",
       "      <th>ê±´ë¬¼ìœ í˜•_ê±´ë¬¼ê¸°íƒ€</th>\n",
       "      <th>ê±´ë¬¼ìœ í˜•_ê³µê³µ</th>\n",
       "      <th>ê±´ë¬¼ìœ í˜•_ë°±í™”ì </th>\n",
       "      <th>ê±´ë¬¼ìœ í˜•_ë³‘ì›</th>\n",
       "      <th>ê±´ë¬¼ìœ í˜•_ìƒìš©</th>\n",
       "      <th>...</th>\n",
       "      <th>ì—°ë©´ì (m2)</th>\n",
       "      <th>ì¼ì‹œ</th>\n",
       "      <th>ì „ë ¥ì†Œë¹„ëŸ‰(kWh)</th>\n",
       "      <th>íƒœì–‘ê´‘ìš©ëŸ‰(kW)</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>day_of_week_sin</th>\n",
       "      <th>day_of_week_cos</th>\n",
       "      <th>consumption_lag_24h</th>\n",
       "      <th>trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>2024-08-25 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>4897.590000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>2024-08-25 01:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>4664.220000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>2024-08-25 02:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>3716.730000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>2024-08-25 03:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>3073.470000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>2024-08-25 04:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>3399.630000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>162070.24</td>\n",
       "      <td>2024-08-31 19:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>3329.432482</td>\n",
       "      <td>16795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>162070.24</td>\n",
       "      <td>2024-08-31 20:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>3329.432482</td>\n",
       "      <td>16796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16797</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>162070.24</td>\n",
       "      <td>2024-08-31 21:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>3329.432482</td>\n",
       "      <td>16797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16798</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>162070.24</td>\n",
       "      <td>2024-08-31 22:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>3329.432482</td>\n",
       "      <td>16798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16799</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>162070.24</td>\n",
       "      <td>2024-08-31 23:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>3329.432482</td>\n",
       "      <td>16799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16800 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ESSì €ì¥ìš©ëŸ‰(kWh)  PCSìš©ëŸ‰(kW)  month  ê±´ë¬¼ë²ˆí˜¸  ê±´ë¬¼ìœ í˜•_IDC(ì „í™”êµ­)  ê±´ë¬¼ìœ í˜•_ê±´ë¬¼ê¸°íƒ€  \\\n",
       "0               0.0          0      8     1          False      False   \n",
       "1               0.0          0      8     1          False      False   \n",
       "2               0.0          0      8     1          False      False   \n",
       "3               0.0          0      8     1          False      False   \n",
       "4               0.0          0      8     1          False      False   \n",
       "...             ...        ...    ...   ...            ...        ...   \n",
       "16795           0.0          0      8   100          False      False   \n",
       "16796           0.0          0      8   100          False      False   \n",
       "16797           0.0          0      8   100          False      False   \n",
       "16798           0.0          0      8   100          False      False   \n",
       "16799           0.0          0      8   100          False      False   \n",
       "\n",
       "       ê±´ë¬¼ìœ í˜•_ê³µê³µ  ê±´ë¬¼ìœ í˜•_ë°±í™”ì   ê±´ë¬¼ìœ í˜•_ë³‘ì›  ê±´ë¬¼ìœ í˜•_ìƒìš©  ...    ì—°ë©´ì (m2)  \\\n",
       "0        False     False    False    False  ...   82912.71   \n",
       "1        False     False    False    False  ...   82912.71   \n",
       "2        False     False    False    False  ...   82912.71   \n",
       "3        False     False    False    False  ...   82912.71   \n",
       "4        False     False    False    False  ...   82912.71   \n",
       "...        ...       ...      ...      ...  ...        ...   \n",
       "16795    False     False    False    False  ...  162070.24   \n",
       "16796    False     False    False    False  ...  162070.24   \n",
       "16797    False     False    False    False  ...  162070.24   \n",
       "16798    False     False    False    False  ...  162070.24   \n",
       "16799    False     False    False    False  ...  162070.24   \n",
       "\n",
       "                       ì¼ì‹œ  ì „ë ¥ì†Œë¹„ëŸ‰(kWh)  íƒœì–‘ê´‘ìš©ëŸ‰(kW)  hour_sin  hour_cos  \\\n",
       "0     2024-08-25 00:00:00           0        0.0  0.000000  1.000000   \n",
       "1     2024-08-25 01:00:00           0        0.0  0.258819  0.965926   \n",
       "2     2024-08-25 02:00:00           0        0.0  0.500000  0.866025   \n",
       "3     2024-08-25 03:00:00           0        0.0  0.707107  0.707107   \n",
       "4     2024-08-25 04:00:00           0        0.0  0.866025  0.500000   \n",
       "...                   ...         ...        ...       ...       ...   \n",
       "16795 2024-08-31 19:00:00           0        0.0 -0.965926  0.258819   \n",
       "16796 2024-08-31 20:00:00           0        0.0 -0.866025  0.500000   \n",
       "16797 2024-08-31 21:00:00           0        0.0 -0.707107  0.707107   \n",
       "16798 2024-08-31 22:00:00           0        0.0 -0.500000  0.866025   \n",
       "16799 2024-08-31 23:00:00           0        0.0 -0.258819  0.965926   \n",
       "\n",
       "       day_of_week_sin day_of_week_cos  consumption_lag_24h  trend  \n",
       "0            -0.781831        0.623490          4897.590000      0  \n",
       "1            -0.781831        0.623490          4664.220000      1  \n",
       "2            -0.781831        0.623490          3716.730000      2  \n",
       "3            -0.781831        0.623490          3073.470000      3  \n",
       "4            -0.781831        0.623490          3399.630000      4  \n",
       "...                ...             ...                  ...    ...  \n",
       "16795        -0.974928       -0.222521          3329.432482  16795  \n",
       "16796        -0.974928       -0.222521          3329.432482  16796  \n",
       "16797        -0.974928       -0.222521          3329.432482  16797  \n",
       "16798        -0.974928       -0.222521          3329.432482  16798  \n",
       "16799        -0.974928       -0.222521          3329.432482  16799  \n",
       "\n",
       "[16800 rows x 26 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_24h = train_df.groupby(\"ê±´ë¬¼ë²ˆí˜¸\").tail(24)[[\"ê±´ë¬¼ë²ˆí˜¸\", \"ì¼ì‹œ\", \"ì „ë ¥ì†Œë¹„ëŸ‰(kWh)\"]]\n",
    "last_24h[\"ì¼ì‹œ\"] = last_24h[\"ì¼ì‹œ\"] + pd.Timedelta(hours=24)\n",
    "last_24h = last_24h.rename(columns={\"ì „ë ¥ì†Œë¹„ëŸ‰(kWh)\": \"consumption_lag_24h\"})\n",
    "test_df = test_df.merge(last_24h, on=[\"ê±´ë¬¼ë²ˆí˜¸\", \"ì¼ì‹œ\"], how=\"left\")\n",
    "test_df[\"consumption_lag_24h\"] = test_df[\"consumption_lag_24h\"].fillna(train_df[\"ì „ë ¥ì†Œë¹„ëŸ‰(kWh)\"].mean())\n",
    "test_df = test_df.sort_values([\"ê±´ë¬¼ë²ˆí˜¸\", \"ì¼ì‹œ\"]).reset_index(drop=True)\n",
    "test_df[\"trend\"] = range(len(test_df))\n",
    "\n",
    "# ê²€ì¦\n",
    "print(\"df_test shape:\", test_df.shape)\n",
    "print(\"df_test columns:\", test_df.columns)\n",
    "print(\"df_test head:\", test_df[[\"ê±´ë¬¼ë²ˆí˜¸\", \"ì¼ì‹œ\", \"consumption_lag_24h\", \"trend\"]].head())\n",
    "print(\"df_test tail:\", test_df[[\"ê±´ë¬¼ë²ˆí˜¸\", \"ì¼ì‹œ\", \"consumption_lag_24h\", \"trend\"]].tail())\n",
    "print(\"Missing consumption_lag_24h:\", test_df[\"consumption_lag_24h\"].isna().sum())\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13991eef-1a7f-4130-b82b-7ab15df29afe",
   "metadata": {
    "id": "13991eef-1a7f-4130-b82b-7ab15df29afe"
   },
   "source": [
    "## Data prep: Getting input & output sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0a1558-0aa0-43d1-8f60-248847198b84",
   "metadata": {
    "id": "af0a1558-0aa0-43d1-8f60-248847198b84"
   },
   "source": [
    "We will create a \"shifted dataset\" where each row at time T contains the following columns:\n",
    "- Target value at T (consumption lead T+1),\n",
    "- Past value at T (consumption lag T-2),\n",
    "- Time covariates at T."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2699147e-7f37-4017-861c-6674868d35d0",
   "metadata": {
    "id": "2699147e-7f37-4017-861c-6674868d35d0"
   },
   "source": [
    "Every source sequence will be the last 72 hours before 16:00, and every target sequence will be the next 32 hours after 16:00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9v-3Vwlq6APq",
   "metadata": {
    "id": "9v-3Vwlq6APq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… íŒŒë¼ë¯¸í„° ë° í”¼ì²˜ ë¦¬ìŠ¤íŠ¸ ì •ì˜ ì™„ë£Œ.\n",
      "ì´ ì…ë ¥ ì±„ë„ ìˆ˜(ê±´ë¬¼ë²ˆí˜¸ í¬í•¨): 24\n",
      "\n",
      "âœ… Transformerìš© ì‹œí€€ìŠ¤ ìƒì„± ì™„ë£Œ!\n",
      "Source ì‹œí€€ìŠ¤ ê°œìˆ˜: 7199\n",
      "Target ì‹œí€€ìŠ¤ ê°œìˆ˜: 7199\n",
      "\n",
      "--- ì²« ë²ˆì§¸ ê±´ë¬¼ì˜ Source Sequence (ë§ˆì§€ë§‰ 5í–‰) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ê±´ë¬¼ë²ˆí˜¸</th>\n",
       "      <th>ê¸°ì˜¨(Â°C)</th>\n",
       "      <th>consumption_lag_24h</th>\n",
       "      <th>trend</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>day_of_week_sin</th>\n",
       "      <th>day_of_week_cos</th>\n",
       "      <th>ESSì €ì¥ìš©ëŸ‰(kWh)</th>\n",
       "      <th>PCSìš©ëŸ‰(kW)</th>\n",
       "      <th>...</th>\n",
       "      <th>ê±´ë¬¼ìœ í˜•_ë³‘ì›</th>\n",
       "      <th>ê±´ë¬¼ìœ í˜•_ìƒìš©</th>\n",
       "      <th>ê±´ë¬¼ìœ í˜•_ì•„íŒŒíŠ¸</th>\n",
       "      <th>ê±´ë¬¼ìœ í˜•_ì—°êµ¬ì†Œ</th>\n",
       "      <th>ê±´ë¬¼ìœ í˜•_í•™êµ</th>\n",
       "      <th>ê±´ë¬¼ìœ í˜•_í˜¸í…”</th>\n",
       "      <th>ëƒ‰ë°©ë©´ì (m2)</th>\n",
       "      <th>ì—°ë©´ì (m2)</th>\n",
       "      <th>íƒœì–‘ê´‘ìš©ëŸ‰(kW)</th>\n",
       "      <th>ì „ë ¥ì†Œë¹„ëŸ‰(kWh)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ì¼ì‹œ</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-06-08 19:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>23.2</td>\n",
       "      <td>6125.85</td>\n",
       "      <td>187</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5333.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-08 20:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5478.39</td>\n",
       "      <td>188</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5411.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-08 21:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>21.2</td>\n",
       "      <td>4299.99</td>\n",
       "      <td>189</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4292.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-08 22:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>20.6</td>\n",
       "      <td>3914.49</td>\n",
       "      <td>190</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4599.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-08 23:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>20.2</td>\n",
       "      <td>5652.33</td>\n",
       "      <td>191</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5150.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ê±´ë¬¼ë²ˆí˜¸  ê¸°ì˜¨(Â°C)  consumption_lag_24h  trend  hour_sin  \\\n",
       "ì¼ì‹œ                                                                        \n",
       "2024-06-08 19:00:00     1    23.2              6125.85    187 -0.965926   \n",
       "2024-06-08 20:00:00     1    22.0              5478.39    188 -0.866025   \n",
       "2024-06-08 21:00:00     1    21.2              4299.99    189 -0.707107   \n",
       "2024-06-08 22:00:00     1    20.6              3914.49    190 -0.500000   \n",
       "2024-06-08 23:00:00     1    20.2              5652.33    191 -0.258819   \n",
       "\n",
       "                     hour_cos  day_of_week_sin  day_of_week_cos  ESSì €ì¥ìš©ëŸ‰(kWh)  \\\n",
       "ì¼ì‹œ                                                                              \n",
       "2024-06-08 19:00:00  0.258819        -0.974928        -0.222521           0.0   \n",
       "2024-06-08 20:00:00  0.500000        -0.974928        -0.222521           0.0   \n",
       "2024-06-08 21:00:00  0.707107        -0.974928        -0.222521           0.0   \n",
       "2024-06-08 22:00:00  0.866025        -0.974928        -0.222521           0.0   \n",
       "2024-06-08 23:00:00  0.965926        -0.974928        -0.222521           0.0   \n",
       "\n",
       "                     PCSìš©ëŸ‰(kW)  ...  ê±´ë¬¼ìœ í˜•_ë³‘ì›  ê±´ë¬¼ìœ í˜•_ìƒìš©  ê±´ë¬¼ìœ í˜•_ì•„íŒŒíŠ¸  ê±´ë¬¼ìœ í˜•_ì—°êµ¬ì†Œ  \\\n",
       "ì¼ì‹œ                              ...                                         \n",
       "2024-06-08 19:00:00          0  ...    False    False     False     False   \n",
       "2024-06-08 20:00:00          0  ...    False    False     False     False   \n",
       "2024-06-08 21:00:00          0  ...    False    False     False     False   \n",
       "2024-06-08 22:00:00          0  ...    False    False     False     False   \n",
       "2024-06-08 23:00:00          0  ...    False    False     False     False   \n",
       "\n",
       "                     ê±´ë¬¼ìœ í˜•_í•™êµ  ê±´ë¬¼ìœ í˜•_í˜¸í…”  ëƒ‰ë°©ë©´ì (m2)   ì—°ë©´ì (m2)  íƒœì–‘ê´‘ìš©ëŸ‰(kW)  \\\n",
       "ì¼ì‹œ                                                                     \n",
       "2024-06-08 19:00:00    False     True   77586.0  82912.71        0.0   \n",
       "2024-06-08 20:00:00    False     True   77586.0  82912.71        0.0   \n",
       "2024-06-08 21:00:00    False     True   77586.0  82912.71        0.0   \n",
       "2024-06-08 22:00:00    False     True   77586.0  82912.71        0.0   \n",
       "2024-06-08 23:00:00    False     True   77586.0  82912.71        0.0   \n",
       "\n",
       "                     ì „ë ¥ì†Œë¹„ëŸ‰(kWh)  \n",
       "ì¼ì‹œ                               \n",
       "2024-06-08 19:00:00     5333.49  \n",
       "2024-06-08 20:00:00     5411.25  \n",
       "2024-06-08 21:00:00     4292.37  \n",
       "2024-06-08 22:00:00     4599.39  \n",
       "2024-06-08 23:00:00     5150.10  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ì²« ë²ˆì§¸ ê±´ë¬¼ì˜ Target Sequence (ì²˜ìŒ 5í–‰) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ê±´ë¬¼ë²ˆí˜¸</th>\n",
       "      <th>ê¸°ì˜¨(Â°C)</th>\n",
       "      <th>consumption_lag_24h</th>\n",
       "      <th>trend</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>day_of_week_sin</th>\n",
       "      <th>day_of_week_cos</th>\n",
       "      <th>ESSì €ì¥ìš©ëŸ‰(kWh)</th>\n",
       "      <th>PCSìš©ëŸ‰(kW)</th>\n",
       "      <th>...</th>\n",
       "      <th>ê±´ë¬¼ìœ í˜•_ë³‘ì›</th>\n",
       "      <th>ê±´ë¬¼ìœ í˜•_ìƒìš©</th>\n",
       "      <th>ê±´ë¬¼ìœ í˜•_ì•„íŒŒíŠ¸</th>\n",
       "      <th>ê±´ë¬¼ìœ í˜•_ì—°êµ¬ì†Œ</th>\n",
       "      <th>ê±´ë¬¼ìœ í˜•_í•™êµ</th>\n",
       "      <th>ê±´ë¬¼ìœ í˜•_í˜¸í…”</th>\n",
       "      <th>ëƒ‰ë°©ë©´ì (m2)</th>\n",
       "      <th>ì—°ë©´ì (m2)</th>\n",
       "      <th>íƒœì–‘ê´‘ìš©ëŸ‰(kW)</th>\n",
       "      <th>ì „ë ¥ì†Œë¹„ëŸ‰(kWh)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ì¼ì‹œ</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-06-09 00:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>19.5</td>\n",
       "      <td>4960.32</td>\n",
       "      <td>192</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5350.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-09 01:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4391.73</td>\n",
       "      <td>193</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5523.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-09 02:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>18.6</td>\n",
       "      <td>5055.51</td>\n",
       "      <td>194</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5441.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-09 03:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>18.1</td>\n",
       "      <td>5389.44</td>\n",
       "      <td>195</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5365.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-09 04:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>17.7</td>\n",
       "      <td>5146.26</td>\n",
       "      <td>196</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4025.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ê±´ë¬¼ë²ˆí˜¸  ê¸°ì˜¨(Â°C)  consumption_lag_24h  trend  hour_sin  \\\n",
       "ì¼ì‹œ                                                                        \n",
       "2024-06-09 00:00:00     1    19.5              4960.32    192  0.000000   \n",
       "2024-06-09 01:00:00     1    19.0              4391.73    193  0.258819   \n",
       "2024-06-09 02:00:00     1    18.6              5055.51    194  0.500000   \n",
       "2024-06-09 03:00:00     1    18.1              5389.44    195  0.707107   \n",
       "2024-06-09 04:00:00     1    17.7              5146.26    196  0.866025   \n",
       "\n",
       "                     hour_cos  day_of_week_sin  day_of_week_cos  ESSì €ì¥ìš©ëŸ‰(kWh)  \\\n",
       "ì¼ì‹œ                                                                              \n",
       "2024-06-09 00:00:00  1.000000        -0.781831          0.62349           0.0   \n",
       "2024-06-09 01:00:00  0.965926        -0.781831          0.62349           0.0   \n",
       "2024-06-09 02:00:00  0.866025        -0.781831          0.62349           0.0   \n",
       "2024-06-09 03:00:00  0.707107        -0.781831          0.62349           0.0   \n",
       "2024-06-09 04:00:00  0.500000        -0.781831          0.62349           0.0   \n",
       "\n",
       "                     PCSìš©ëŸ‰(kW)  ...  ê±´ë¬¼ìœ í˜•_ë³‘ì›  ê±´ë¬¼ìœ í˜•_ìƒìš©  ê±´ë¬¼ìœ í˜•_ì•„íŒŒíŠ¸  ê±´ë¬¼ìœ í˜•_ì—°êµ¬ì†Œ  \\\n",
       "ì¼ì‹œ                              ...                                         \n",
       "2024-06-09 00:00:00          0  ...    False    False     False     False   \n",
       "2024-06-09 01:00:00          0  ...    False    False     False     False   \n",
       "2024-06-09 02:00:00          0  ...    False    False     False     False   \n",
       "2024-06-09 03:00:00          0  ...    False    False     False     False   \n",
       "2024-06-09 04:00:00          0  ...    False    False     False     False   \n",
       "\n",
       "                     ê±´ë¬¼ìœ í˜•_í•™êµ  ê±´ë¬¼ìœ í˜•_í˜¸í…”  ëƒ‰ë°©ë©´ì (m2)   ì—°ë©´ì (m2)  íƒœì–‘ê´‘ìš©ëŸ‰(kW)  \\\n",
       "ì¼ì‹œ                                                                     \n",
       "2024-06-09 00:00:00    False     True   77586.0  82912.71        0.0   \n",
       "2024-06-09 01:00:00    False     True   77586.0  82912.71        0.0   \n",
       "2024-06-09 02:00:00    False     True   77586.0  82912.71        0.0   \n",
       "2024-06-09 03:00:00    False     True   77586.0  82912.71        0.0   \n",
       "2024-06-09 04:00:00    False     True   77586.0  82912.71        0.0   \n",
       "\n",
       "                     ì „ë ¥ì†Œë¹„ëŸ‰(kWh)  \n",
       "ì¼ì‹œ                               \n",
       "2024-06-09 00:00:00     5350.35  \n",
       "2024-06-09 01:00:00     5523.81  \n",
       "2024-06-09 02:00:00     5441.73  \n",
       "2024-06-09 03:00:00     5365.44  \n",
       "2024-06-09 04:00:00     4025.13  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 1. ìµœì¢… íŒŒë¼ë¯¸í„° ë° í”¼ì²˜ ë¦¬ìŠ¤íŠ¸ ì •ì˜\n",
    "# ===================================================================\n",
    "SOURCE_LENGTH = 168\n",
    "TARGET_LENGTH = 168\n",
    "TARGET_COL = 'ì „ë ¥ì†Œë¹„ëŸ‰(kWh)'\n",
    "BUILDING_COL = 'ê±´ë¬¼ë²ˆí˜¸'  # âœ… ê±´ë¬¼ ID ëª…ì‹œ\n",
    "\n",
    "# ì‹œê°„ì— ë”°ë¼ ë³€í•˜ëŠ” ë³€ìˆ˜ë“¤ (TARGET_COL ì œì™¸)\n",
    "FEATURE_COLS = [\n",
    "    'ê¸°ì˜¨(Â°C)',\n",
    "    'consumption_lag_24h', 'trend',\n",
    "    'hour_sin', 'hour_cos', 'day_of_week_sin', 'day_of_week_cos'\n",
    "]\n",
    "\n",
    "# ê±´ë¬¼ë³„ë¡œ ê³ ì •ëœ ë³€ìˆ˜ë“¤\n",
    "STATIC_COLS = [col for col in train_df.columns if \"ê±´ë¬¼ìœ í˜•_\" in col or \"ë©´ì \" in col or \"ìš©ëŸ‰\" in col]\n",
    "\n",
    "# (ì¤‘ìš”) ìŠ¤ì¼€ì¼ë§/ëª¨ë¸ ì…ë ¥ ì»¬ëŸ¼ ìµœì¢… ìˆœì„œ: [ê±´ë¬¼ë²ˆí˜¸] + ë™ì  + ì •ì  + [íƒ€ê¹ƒ]\n",
    "FINAL_COLS_ORDERED = [BUILDING_COL] + FEATURE_COLS + STATIC_COLS + [TARGET_COL]\n",
    "\n",
    "print(\"âœ… íŒŒë¼ë¯¸í„° ë° í”¼ì²˜ ë¦¬ìŠ¤íŠ¸ ì •ì˜ ì™„ë£Œ.\")\n",
    "print(f\"ì´ ì…ë ¥ ì±„ë„ ìˆ˜(ê±´ë¬¼ë²ˆí˜¸ í¬í•¨): {len(FINAL_COLS_ORDERED)}\")\n",
    "\n",
    "# ===================================================================\n",
    "# 2. ë‹¤ì¤‘ ì‹œê³„ì—´ Transformerìš© ì‹œí€€ìŠ¤ ìƒì„± í•¨ìˆ˜ (ê±´ë¬¼ë²ˆí˜¸ ë³´ì¡´ ë²„ì „)\n",
    "# ===================================================================\n",
    "def create_transformer_sequences_for_prediction(\n",
    "    train_df,\n",
    "    test_df,\n",
    "    feature_cols,\n",
    "    static_cols,\n",
    "    target_col,\n",
    "    source_length,\n",
    "    target_length,\n",
    "    mode: str = \"inference\",   # \"inference\" or \"train\"\n",
    "    stride: int = 1            # train ëª¨ë“œì—ì„œ ë¡¤ë§ ê°„ê²©\n",
    "):\n",
    "    import numpy as np\n",
    "\n",
    "    assert mode in (\"inference\", \"train\"), \"mode must be 'inference' or 'train'\"\n",
    "    source_sequences, target_sequences = [], []\n",
    "\n",
    "    train_df = train_df.sort_values([BUILDING_COL, 'ì¼ì‹œ'])\n",
    "    if mode == \"inference\":\n",
    "        test_df = test_df.sort_values([BUILDING_COL, 'ì¼ì‹œ'])\n",
    "\n",
    "    final_cols_ordered = [BUILDING_COL] + feature_cols + static_cols + [target_col]\n",
    "\n",
    "    for building_id in train_df[BUILDING_COL].unique():\n",
    "        g_train = train_df[train_df[BUILDING_COL] == building_id]\n",
    "\n",
    "        # ì •ì ê°’(ê±´ë¬¼ ë‹¨ìœ„ë¡œ ë™ì¼í•˜ë‹¤ëŠ” ê°€ì •)\n",
    "        static_vals = g_train.iloc[0][static_cols]\n",
    "\n",
    "        if mode == \"inference\":\n",
    "            g_test = test_df[test_df[BUILDING_COL] == building_id]\n",
    "\n",
    "            # --- Source (train tail) ---\n",
    "            if len(g_train) < source_length:\n",
    "                continue\n",
    "            source_seq = g_train.tail(source_length).copy()\n",
    "\n",
    "            # --- Target (test head) ---\n",
    "            if len(g_test) < target_length:\n",
    "                continue\n",
    "            target_seq = g_test.head(target_length).copy()\n",
    "\n",
    "            # ---- íƒ€ê¹ƒ ì´ˆê¸°ê°’: ì„ í˜• ì™¸ì‚½ ----\n",
    "            y_hist = source_seq[target_col].to_numpy(dtype=np.float32)  # (L,)\n",
    "            L, H = source_length, target_length\n",
    "            x = np.arange(L, dtype=np.float32)\n",
    "            A = np.vstack([x, np.ones_like(x)]).T\n",
    "            m, c = np.linalg.lstsq(A, y_hist, rcond=None)[0]\n",
    "            fut_idx = np.arange(L, L + H, dtype=np.float32)\n",
    "            y_init = (m * fut_idx + c).astype(np.float32)\n",
    "            if not np.isfinite(y_init).all():\n",
    "                y_init = np.full(H, y_hist[-1], dtype=np.float32)\n",
    "            target_seq[target_col] = y_init  # ì™¸ì‚½ê°’ìœ¼ë¡œ ì±„ì›€ (y_true ì—†ìŒ)\n",
    "\n",
    "            # --- ì •ì  í”¼ì²˜ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ---\n",
    "            for col in static_cols:\n",
    "                source_seq[col] = static_vals[col]\n",
    "                target_seq[col] = static_vals[col]\n",
    "\n",
    "            # âœ… ê±´ë¬¼ë²ˆí˜¸ ëª…ì‹œ ë³´ì¡´ (í˜¹ì‹œ ëˆ„ë½ ë°©ì§€)\n",
    "            source_seq[BUILDING_COL] = building_id\n",
    "            target_seq[BUILDING_COL] = building_id\n",
    "\n",
    "            # ì‹œê°„ ì¸ë±ìŠ¤ë§Œ ì„¤ì • (ê±´ë¬¼ë²ˆí˜¸ëŠ” ì»¬ëŸ¼ìœ¼ë¡œ ë‚¨ê¹€)\n",
    "            source_sequences.append(source_seq.set_index('ì¼ì‹œ')[final_cols_ordered])\n",
    "            target_sequences.append(target_seq.set_index('ì¼ì‹œ')[final_cols_ordered])\n",
    "\n",
    "        else:  # mode == \"train\"\n",
    "            total_len = len(g_train)\n",
    "            if total_len < source_length + target_length:\n",
    "                continue\n",
    "\n",
    "            g_train = g_train.reset_index(drop=True)\n",
    "            for start in range(0, total_len - (source_length + target_length) + 1, stride):\n",
    "                s0 = start\n",
    "                s1 = start + source_length\n",
    "                t1 = s1 + target_length\n",
    "\n",
    "                source_seq = g_train.iloc[s0:s1].copy()\n",
    "                target_seq = g_train.iloc[s1:t1].copy()\n",
    "\n",
    "                # ì •ì  í”¼ì²˜ ë¸Œë¡œë“œìºìŠ¤íŠ¸\n",
    "                for col in static_cols:\n",
    "                    source_seq[col] = static_vals[col]\n",
    "                    target_seq[col] = static_vals[col]\n",
    "\n",
    "                # âœ… ê±´ë¬¼ë²ˆí˜¸ ëª…ì‹œ ë³´ì¡´\n",
    "                source_seq[BUILDING_COL] = building_id\n",
    "                target_seq[BUILDING_COL] = building_id\n",
    "\n",
    "                source_sequences.append(source_seq.set_index('ì¼ì‹œ')[final_cols_ordered])\n",
    "                target_sequences.append(target_seq.set_index('ì¼ì‹œ')[final_cols_ordered])\n",
    "\n",
    "    return source_sequences, target_sequences\n",
    "\n",
    "# ===================================================================\n",
    "# 3. í•¨ìˆ˜ ì‹¤í–‰ ë° ê²°ê³¼ í™•ì¸\n",
    "# ===================================================================\n",
    "train_src, train_tgt = create_transformer_sequences_for_prediction(\n",
    "    train_df, test_df,\n",
    "    FEATURE_COLS, STATIC_COLS, TARGET_COL,\n",
    "    SOURCE_LENGTH, TARGET_LENGTH,\n",
    "    mode=\"train\",\n",
    "    stride=24\n",
    ")\n",
    "infer_src, infer_tgt = create_transformer_sequences_for_prediction(\n",
    "    train_df, test_df,\n",
    "    FEATURE_COLS, STATIC_COLS, TARGET_COL,\n",
    "    SOURCE_LENGTH, TARGET_LENGTH,\n",
    "    mode=\"inference\"\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Transformerìš© ì‹œí€€ìŠ¤ ìƒì„± ì™„ë£Œ!\")\n",
    "print(f\"Source ì‹œí€€ìŠ¤ ê°œìˆ˜: {len(train_src)}\")\n",
    "print(f\"Target ì‹œí€€ìŠ¤ ê°œìˆ˜: {len(train_tgt)}\")\n",
    "print(\"\\n--- ì²« ë²ˆì§¸ ê±´ë¬¼ì˜ Source Sequence (ë§ˆì§€ë§‰ 5í–‰) ---\")\n",
    "display(train_src[0].tail())\n",
    "print(\"\\n--- ì²« ë²ˆì§¸ ê±´ë¬¼ì˜ Target Sequence (ì²˜ìŒ 5í–‰) ---\")\n",
    "display(train_tgt[0].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d49c1ac-3f13-4df7-a39a-26b63e14dfac",
   "metadata": {
    "id": "4d49c1ac-3f13-4df7-a39a-26b63e14dfac"
   },
   "source": [
    "Each source sequence will contain the following:\n",
    "- Consumption lag 2 at [T - source_length, T] (past targets),\n",
    "- Time covariates at [T - source_length, T] (past covariates)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2532030-85c4-4e5a-86b7-1f1e95b14f2e",
   "metadata": {
    "id": "c2532030-85c4-4e5a-86b7-1f1e95b14f2e"
   },
   "source": [
    "Each output sequence will contain the following:\n",
    "- Consumption at [T+1, T + output_length] (future targets),\n",
    "- Time covariates at [T+1, T + output_length] (future known covariates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8636db66-7ab4-490c-923f-09e1e1d84190",
   "metadata": {
    "id": "8636db66-7ab4-490c-923f-09e1e1d84190"
   },
   "source": [
    "In the source sequence, we pair every past target value at T with the past covariates at T.\n",
    "\\\n",
    "In the output sequence, we pair every future target value at T+1 with the future covariates at T+1.\n",
    "\n",
    "This is more straightforward than the LSTM sequencing in notebook 4.0, because we will make our predictions in one go, and don't need to combine predictions at T+1 with future covariates at T+2 to get the input sequence for T+1.\n",
    "\n",
    "We will simply initialize the future targets from T+1 onwards as a linear extrapolation of the past targets from T - source_length to T. We'll do this in training as well as validation & prediction.\n",
    "\\\n",
    "The idea is that the model should learn to \"enrich\" a simple linear extrapolation given additional future known covariates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253bf525-8f95-43af-9c5c-356248ae6cc9",
   "metadata": {
    "id": "253bf525-8f95-43af-9c5c-356248ae6cc9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7199"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ecfbe6-7de0-46bc-8435-5fc5ae5ecaf5",
   "metadata": {
    "id": "45ecfbe6-7de0-46bc-8435-5fc5ae5ecaf5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7199"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_tgt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2a79ac-10d9-4de2-b973-99d6d60421cc",
   "metadata": {
    "id": "ff2a79ac-10d9-4de2-b973-99d6d60421cc"
   },
   "source": [
    "## Preprocessing: Custom scaler, Torch datasets & dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653354da-4abb-4dd0-b6de-b4c8b1c5e490",
   "metadata": {
    "id": "653354da-4abb-4dd0-b6de-b4c8b1c5e490"
   },
   "source": [
    "We'll keep batch sizes constant to match the evaluation scheme with the stateful LSTM in notebook 4.0, though there should be no need with this model.\n",
    "\\\n",
    "We'll divide the lengths of each data fold with the batch size, drop the remainder from the start of the training folds & the end of the val. & test folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jKciUirwZ7Ec",
   "metadata": {
    "id": "jKciUirwZ7Ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ë¶„í•  ì™„ë£Œ\n",
      "í•™ìŠµìš© ë°ì´í„°: 6464ê°œ, ê²€ì¦ìš© ë°ì´í„°: 704ê°œ\n",
      "âœ… group_ids_val ì¤€ë¹„ ì™„ë£Œ:  704\n",
      "\n",
      "Fitting the scaler on the training data...\n",
      "Transforming all datasets...\n",
      "âœ… í”¼ì²˜ë³„ ìŠ¤ì¼€ì¼ë§ ì ìš© (íƒ€ê¹ƒ: ê±´ë¬¼ë³„ MinMax ì¤€ë¹„ ì™„ë£Œ)\n",
      "Creating PyTorch Datasets...\n",
      "âœ… Datasets created successfully.\n",
      "\n",
      "âœ… Transformerìš© DataLoaderê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "torch.Size([64, 168, 23]) torch.Size([64, 168, 23]) torch.Size([64])\n",
      "âœ… val_pred_loader ì¤€ë¹„ ì™„ë£Œ (predict ì „ìš©)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# ===================================================================\n",
    "# 0) ì»¬ëŸ¼ êµ¬ì„±: \"ìŠ¤ì¼€ì¼ëŸ¬ìš©\"ê³¼ \"ëª¨ë¸ì…ë ¥ìš©\"ì„ ë¶„ë¦¬\n",
    "# ===================================================================\n",
    "BUILDING_COL = \"ê±´ë¬¼ë²ˆí˜¸\"\n",
    "TARGET_COL   = \"ì „ë ¥ì†Œë¹„ëŸ‰(kWh)\"\n",
    "\n",
    "# ìŠ¤ì¼€ì¼ëŸ¬/ì‹œí€€ìŠ¤ DFì—ëŠ” ê±´ë¬¼ë²ˆí˜¸ë¥¼ í¬í•¨í•´ë‘ (ê·¸ë£¹ë³„ í†µê³„ ê³„ì‚°ìš©)\n",
    "FINAL_COLS_WITH_BUILDING = [BUILDING_COL] + FEATURE_COLS + STATIC_COLS + [TARGET_COL]\n",
    "\n",
    "# ëª¨ë¸ ì…ë ¥ í…ì„œëŠ” 'ê±´ë¬¼ë²ˆí˜¸' ì±„ë„ì„ ì œê±°í•˜ê³  ì‚¬ìš©\n",
    "FINAL_COLS_FOR_MODEL = FEATURE_COLS + STATIC_COLS + [TARGET_COL]   # (íƒ€ê¹ƒì€ í•­ìƒ ë§ˆì§€ë§‰)\n",
    "\n",
    "# ===================================================================\n",
    "# 1. ë°ì´í„° ë¶„í• \n",
    "# ===================================================================\n",
    "train_source, train_target, val_source, val_target = train_val_split_const_batch_size(\n",
    "    train_src,\n",
    "    train_tgt,\n",
    "    train_fraction=0.9,\n",
    ")\n",
    "print(\"ë°ì´í„° ë¶„í•  ì™„ë£Œ\")\n",
    "print(f\"í•™ìŠµìš© ë°ì´í„°: {len(train_source)}ê°œ, ê²€ì¦ìš© ë°ì´í„°: {len(val_source)}ê°œ\")\n",
    "\n",
    "# 0..NUM_BUILDINGS-1 ë§¤í•‘\n",
    "uniq_ids = sorted(train_df[BUILDING_COL].unique().tolist())\n",
    "bld2idx = {bid: i for i, bid in enumerate(uniq_ids)}\n",
    "\n",
    "# ë¶„í•  ì§í›„, bld2idx ë§Œë“¤ê³  ë‚œ ë‹¤ìŒì— ë°”ë¡œ ì¶”ê°€\n",
    "group_ids_val = [df.iloc[0][BUILDING_COL] for df in val_target]\n",
    "print(\"âœ… group_ids_val ì¤€ë¹„ ì™„ë£Œ: \", len(group_ids_val))\n",
    "\n",
    "# ê° ì‹œí€€ìŠ¤ì˜ ê±´ë¬¼ id â†’ index\n",
    "train_bld_ids_idx = np.array([bld2idx[int(df[BUILDING_COL].iloc[0])] for df in train_source], dtype=np.int64)\n",
    "val_bld_ids_idx   = np.array([bld2idx[int(df[BUILDING_COL].iloc[0])] for df in val_source],   dtype=np.int64)\n",
    "infer_bld_ids_idx = np.array([bld2idx[int(df[BUILDING_COL].iloc[0])] for df in infer_src],    dtype=np.int64)\n",
    "\n",
    "import json\n",
    "with open(\"C:/Users/Daniel/DeepLearningEnergyForecasting/bld2idx.json\", \"w\") as f:\n",
    "    json.dump({str(k): int(v) for k, v in bld2idx.items()}, f)\n",
    "\n",
    "# ===================================================================\n",
    "# 2. ìŠ¤ì¼€ì¼ëŸ¬ ì •ì˜ ë° í•™ìŠµ\n",
    "#    - í•µì‹¬: íƒ€ê¹ƒì„ 'ê±´ë¬¼ë³„' MinMax(0â€“1)ë¡œ ì •ê·œí™”í•  ì¤€ë¹„\n",
    "#    - SequenceScalerëŠ” ë‚´ë¶€ì—ì„œ targetì„ ë§ˆì§€ë§‰ ì»¬ëŸ¼ìœ¼ë¡œ ê°•ì œ ì •ë ¬í•œë‹¤ê³  ê°€ì •\n",
    "# ===================================================================\n",
    "\n",
    "# ğŸ‘‰ STATIC_COLSëŠ” ì´ë¯¸ DFì— í¬í•¨ë©ë‹ˆë‹¤. ì—¬ê¸°ì˜ feature ë¦¬ìŠ¤íŠ¸ëŠ” \"ìŠ¤ì¼€ì¼ ë°©ì‹\"ë§Œ ì§€ì •í•˜ëŠ” ëª©ì ì…ë‹ˆë‹¤.\n",
    "#    (ì¤‘ë³µ ì§€ì •í•´ë„ ë‚´ë¶€ì—ì„œ ì¤‘ë³µ ì œê±°/ìš°ì„ ìˆœìœ„ ì²˜ë¦¬í•˜ë„ë¡ ì„¤ê³„ë˜ì–´ ìˆìŒ)\n",
    "standard_features = ['ê¸°ì˜¨(Â°C)', 'consumption_lag_24h', 'trend']  # (ê¶Œì¥) ìˆœìˆ˜ ë™ì ë§Œ í‘œì¤€í™”\n",
    "# ë©´ì /ìš©ëŸ‰ ê°™ì€ ì •ì ì€ ëŒ€ì²´ë¡œ MinMax ë˜ëŠ” ê·¸ëŒ€ë¡œ ë‘ì–´ë„ ë¨. ì•„ë˜ëŠ” ì˜ˆì‹œ:\n",
    "minmax_features   = ['ì—°ë©´ì (m2)', 'ëƒ‰ë°©ë©´ì (m2)', 'ESSì €ì¥ìš©ëŸ‰(kWh)', 'PCSìš©ëŸ‰(kW)', 'íƒœì–‘ê´‘ìš©ëŸ‰(kW)']\n",
    "\n",
    "# ì‚¬ì¸/ì½”ì‚¬ì¸/ìš”ì¼ ì„ë² ë”©ì€ ê·¸ëŒ€ë¡œ í†µê³¼\n",
    "passthrough_features = ['hour_sin','hour_cos','day_of_week_sin','day_of_week_cos']\n",
    "\n",
    "# ê±´ë¬¼ë³„ íƒ€ê¹ƒ ì •ê·œí™” ì˜µì…˜ ì¶”ê°€ (í´ë˜ìŠ¤ ë‚´ë¶€ êµ¬í˜„ ì˜ˆì •)\n",
    "scaler = SequenceScaler(\n",
    "    target_col=TARGET_COL,\n",
    "    standard_scale_cols=standard_features,\n",
    "    minmax_scale_cols=minmax_features,\n",
    "    passthrough_cols=passthrough_features,\n",
    "    per_building=True,              # ê±´ë¬¼ë³„ë¡œ íƒ€ê¹ƒ ì •ê·œí™” í†µê³„ë¥¼ ê°€ì§\n",
    "    groupby_key=BUILDING_COL,       # ê·¸ë£¹í•‘ í‚¤\n",
    "    target_minmax=(0.0, 1.0),       # íƒ€ê¹ƒ ìŠ¤ì¼€ì¼ ë²”ìœ„\n",
    "    use_group_for=['target']        # (ì„ íƒ) íƒ€ê¹ƒë§Œ ê·¸ë£¹ë³„ ì •ê·œí™”\n",
    ")\n",
    "print(\"\\nFitting the scaler on the training data...\")\n",
    "\n",
    "# (id, df) íŠœí”Œ í˜•íƒœë¡œ ì „ë‹¬ (dfëŠ” 'ê±´ë¬¼ë²ˆí˜¸' ì»¬ëŸ¼ì„ í¬í•¨)\n",
    "train_source_with_ids = list(enumerate(train_source))\n",
    "train_target_with_ids = list(enumerate(train_target))\n",
    "\n",
    "scaler.fit(train_source_with_ids, train_target_with_ids)\n",
    "\n",
    "print(\"Transforming all datasets...\")\n",
    "val_source_with_ids = list(enumerate(val_source))\n",
    "val_target_with_ids = list(enumerate(val_target))\n",
    "\n",
    "train_source_scaled = scaler.transform(train_source_with_ids)\n",
    "train_target_scaled = scaler.transform(train_target_with_ids)\n",
    "val_source_scaled   = scaler.transform(val_source_with_ids)\n",
    "val_target_scaled   = scaler.transform(val_target_with_ids)\n",
    "\n",
    "print(\"âœ… í”¼ì²˜ë³„ ìŠ¤ì¼€ì¼ë§ ì ìš© (íƒ€ê¹ƒ: ê±´ë¬¼ë³„ MinMax ì¤€ë¹„ ì™„ë£Œ)\")\n",
    "\n",
    "# ===================================================================\n",
    "# 3. ë°ì´í„°ë¡œë” ìƒì„±\n",
    "#    - ëª¨ë¸ ì…ë ¥ì—ì„œ 'ê±´ë¬¼ë²ˆí˜¸' ì±„ë„ì„ ì œê±° (ìŠ¤ì¼€ì¼ëŸ¬ëŠ” ì‚¬ìš©í–ˆì§€ë§Œ ëª¨ë¸ì—ëŠ” ì•„ì§ íˆ¬ì…í•˜ì§€ ì•ŠìŒ)\n",
    "# ===================================================================\n",
    "\n",
    "# ìŠ¤ì¼€ì¼ëŸ¬ëŠ” ì› DF ì»¬ëŸ¼ ìˆœì„œë¥¼ ìœ ì§€í•˜ë˜ íƒ€ê¹ƒì„ ë§ˆì§€ë§‰ìœ¼ë¡œ ë‘”ë‹¤ê³  ê°€ì •\n",
    "# ìš°ë¦¬ëŠ” ì²« ë²ˆì§¸ ì—´(ê±´ë¬¼ë²ˆí˜¸)ì„ ë“œë¡­í•˜ê³  ëª¨ë¸ ì…ë ¥ìš© ë°°ì—´ì„ ë§Œë“ ë‹¤.\n",
    "def drop_building_col(arr: np.ndarray) -> np.ndarray:\n",
    "    # arr shape: (T, D_with_building); building colì´ 0ë²ˆ, targetì€ ë§ˆì§€ë§‰\n",
    "    return arr[:, 1:]  # ê±´ë¬¼ë²ˆí˜¸ ì œê±°\n",
    "\n",
    "train_source_arrays_full = [seq_arr for _, seq_arr in train_source_scaled]\n",
    "train_target_arrays_full = [seq_arr for _, seq_arr in train_target_scaled]\n",
    "val_source_arrays_full   = [seq_arr for _, seq_arr in val_source_scaled]\n",
    "val_target_arrays_full   = [seq_arr for _, seq_arr in val_target_scaled]\n",
    "\n",
    "# ëª¨ë¸ ì…ë ¥ìš©ìœ¼ë¡œ building col ì œê±°\n",
    "train_source_arrays = [drop_building_col(a) for a in train_source_arrays_full]\n",
    "train_target_arrays = [drop_building_col(a) for a in train_target_arrays_full]\n",
    "val_source_arrays   = [drop_building_col(a) for a in val_source_arrays_full]\n",
    "val_target_arrays   = [drop_building_col(a) for a in val_target_arrays_full]\n",
    "\n",
    "# ê²€ì¦: íƒ€ê¹ƒì´ ë§ˆì§€ë§‰ì¸ì§€, ëª¨ë¸ìš© ìµœì¢… ì»¬ëŸ¼ ìˆ˜ê°€ ë§ëŠ”ì§€\n",
    "target_col_index = FINAL_COLS_FOR_MODEL.index(TARGET_COL)\n",
    "assert train_target_arrays[0].shape[1] - 1 == target_col_index\n",
    "assert FINAL_COLS_FOR_MODEL[-1] == TARGET_COL\n",
    "assert train_target_arrays[0].shape[1] == len(FINAL_COLS_FOR_MODEL)\n",
    "\n",
    "print(\"Creating PyTorch Datasets...\")\n",
    "train_data = SequenceDatasetWithBld(np.array(train_source_arrays),\n",
    "                                    np.array(train_target_arrays),\n",
    "                                    train_bld_ids_idx)\n",
    "val_data   = SequenceDatasetWithBld(np.array(val_source_arrays),\n",
    "                                    np.array(val_target_arrays),\n",
    "                                    val_bld_ids_idx)\n",
    "print(\"âœ… Datasets created successfully.\")\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = torch.utils.data.DataLoader(val_data,   batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"\\nâœ… Transformerìš© DataLoaderê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "first_src, first_tgt, first_bld = next(iter(train_loader))\n",
    "print(first_src.shape, first_tgt.shape, first_bld.shape)\n",
    "\n",
    "# 0) ì˜ˆì¸¡ ì „ìš©(Validation) DataLoader ì¤€ë¹„\n",
    "#    - predict_stepì€ targetì— 'íƒ€ê¹ƒ ì œì™¸(covariates-only)' ë°°ì—´ì„ ê¸°ëŒ€ â†’ ë§ˆì§€ë§‰ ì»¬ëŸ¼(íƒ€ê¹ƒ) ì œê±°\n",
    "val_target_cov_arrays = [arr[:, :-1] for arr in val_target_arrays]\n",
    "val_pred_data = SequenceDatasetWithBld(\n",
    "    np.array(val_source_arrays),\n",
    "    np.array(val_target_cov_arrays),\n",
    "    bld_ids=val_bld_ids_idx\n",
    ")\n",
    "val_pred_loader = torch.utils.data.DataLoader(val_pred_data, batch_size=batch_size, shuffle=False)\n",
    "print(\"âœ… val_pred_loader ì¤€ë¹„ ì™„ë£Œ (predict ì „ìš©)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fbb6dc-8bb4-488f-aa19-98c76dfe73d0",
   "metadata": {
    "id": "83fbb6dc-8bb4-488f-aa19-98c76dfe73d0"
   },
   "source": [
    "We have to scale the past consumption values in the source sequences, and covariates in both source & target sequences.\n",
    "\\\n",
    "We also need to scale the real target consumption values because they are used in the loss calculation, even if not passed as input to the model.\n",
    "\\\n",
    "We also need the ability to backtransform the network's final predictions accordingly. Again, we use `SequenceScaler`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1e73f1-6b80-4c22-ac88-4a447673bf1f",
   "metadata": {
    "id": "8d1e73f1-6b80-4c22-ac88-4a447673bf1f"
   },
   "source": [
    "We can use one Torch dataset class both for training & validation (known future targets part of passed target sequences), and for prediction (no known future targets in the target sequences).\n",
    "\\\n",
    "In the former case, both the source & target sequence need to have D feature dimensions (including targets). In the latter case, the target sequence needs to have D-1 feature dimensions, without targets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687c517f-376f-43e2-8839-16e9b261e80f",
   "metadata": {
    "id": "687c517f-376f-43e2-8839-16e9b261e80f"
   },
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a25f72-06e3-4a8f-a911-ec0483f355db",
   "metadata": {
    "id": "96a25f72-06e3-4a8f-a911-ec0483f355db"
   },
   "source": [
    "The `LITransformer` model is implemented in `src.deep_learning.transformer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PYF2yxl2N9Os",
   "metadata": {
    "id": "PYF2yxl2N9Os"
   },
   "outputs": [],
   "source": [
    "# íŒŒì¼ ìµœìƒë‹¨ (í•œ ë²ˆë§Œ)\n",
    "import math, numpy as np, torch, optuna, pickle  # â† pickle ì¶”ê°€\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "\n",
    "PUBLIC_H = 72\n",
    "EPS_PUBLIC = 1.0\n",
    "NONNEG_CLIP = True\n",
    "num_buildings = len(uniq_ids)\n",
    "\n",
    "def _smape_np(y_true, y_pred, eps=EPS_PUBLIC):\n",
    "    y_true = np.asarray(y_true, np.float32)\n",
    "    y_pred = np.asarray(y_pred, np.float32)\n",
    "    m = np.isfinite(y_true) & np.isfinite(y_pred)\n",
    "    if not np.any(m): return 1e9\n",
    "    y_true = y_true[m]; y_pred = y_pred[m]\n",
    "    return float(np.mean(2.0*np.abs(y_pred - y_true) /\n",
    "                         (np.abs(y_true) + np.abs(y_pred) + eps)))\n",
    "\n",
    "def _public_tail(arr, Hpub):\n",
    "    return arr[:, -Hpub:] if arr.shape[1] >= Hpub else arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f022425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "def stage1_objective(trial, source_dims, target_dims):\n",
    "    \"\"\"Stage-1: TimesNet ìš©ëŸ‰/êµ¬ì¡° + ì¼ë¶€ í•™ìŠµ í•˜ì´í¼ íƒìƒ‰ (proxy: val_loss)\"\"\"\n",
    "\n",
    "    # ===== TimesNet êµ¬ì¡° í•˜ì´í¼(í™•ì¥) =====\n",
    "    d_model_exp  = trial.suggest_int(\"d_model_exp\", 7, 9)   # {128,256,512}\n",
    "    d_model      = 2 ** d_model_exp\n",
    "    n_encoders   = trial.suggest_int(\"n_encoders\", 1, 3)\n",
    "    n_decoders   = 1  # Stage-1 í”„ë¡ì‹œëŠ” 1ë¡œ ê³ ì •(ì†ë„â†‘, Stage-2/Finalì—ì„œ decoder ëŠ˜ë ¤ë„ ë¨)\n",
    "\n",
    "    # TimesNet ê³ ìœ \n",
    "    top_k        = trial.suggest_categorical(\"top_k\", [2, 3, 4])\n",
    "    num_kernels  = trial.suggest_categorical(\"num_kernels\", [4, 6, 8])\n",
    "    d_ff_mult    = trial.suggest_categorical(\"d_ff_mult\", [2, 3, 4])\n",
    "    d_ff_tn      = d_model * d_ff_mult\n",
    "\n",
    "    # ===== í•™ìŠµ ê´€ë ¨ =====\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 3e-4, 2e-3, log=True)\n",
    "    dropout_rate  = trial.suggest_float(\"dropout_rate\", 0.0, 0.4)\n",
    "    lr_decay      = trial.suggest_float(\"lr_decay\", 0.985, 1.0)\n",
    "    d_bld         = trial.suggest_categorical(\"d_bld\", [8, 16, 32])\n",
    "    emb_dropout   = trial.suggest_float(\"emb_dropout\", 0.0, 0.2)\n",
    "    grad_clip     = trial.suggest_float(\"gradient_clip_val\", 0.5, 2.0)\n",
    "    accum         = trial.suggest_categorical(\"accumulate_grad_batches\", [1, 2, 4])\n",
    "\n",
    "    # S2ì—ì„œ ë™ì‘ íŠœë‹í•  ê°’ì€ Stage-1 ê³ ì •(í”„ë¡ì‹œ ë‹¨ìˆœí™”)\n",
    "    beta_week = 0.7\n",
    "    alpha     = 0.8\n",
    "    use_adaptive_beta = trial.suggest_categorical(\"use_adaptive_beta\", [True, False])\n",
    "\n",
    "    h = {\n",
    "        \"source_length\": SOURCE_LENGTH, \"target_length\": TARGET_LENGTH,\n",
    "        \"source_dims\": source_dims, \"target_dims\": target_dims,\n",
    "        \"horizon_start\": 0, \"quantiles\": [0.025, 0.5, 0.975],\n",
    "\n",
    "        \"d_model\": d_model, \"n_encoders\": n_encoders, \"n_decoders\": n_decoders,\n",
    "        \"learning_rate\": learning_rate, \"dropout_rate\": dropout_rate, \"lr_decay\": lr_decay,\n",
    "\n",
    "        \"num_buildings\": len(uniq_ids),\n",
    "        \"d_bld\": d_bld, \"emb_dropout\": emb_dropout,\n",
    "\n",
    "        # TimesNet ì „ìš©\n",
    "        \"top_k\": top_k, \"num_kernels\": num_kernels, \"d_ff_tn\": d_ff_tn,\n",
    "\n",
    "        # Stage-1 ê³ ì •(ë™ì‘)\n",
    "        \"beta_week\": beta_week, \"alpha\": alpha,\n",
    "        \"use_adaptive_beta\": use_adaptive_beta,\n",
    "    }\n",
    "\n",
    "    model = TimesNet(h)\n",
    "\n",
    "    # ===== ì½œë°±/ë¡œê±° =====\n",
    "    pruner_cb = PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")\n",
    "    # proxy í•™ìŠµ ì¡°ê¸ˆ ë” ê¸¸ê²Œ â†’ patience=3\n",
    "    es_cb = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=3, check_on_train_epoch_end=False)\n",
    "    logger = CSVLogger(OPT_LOG_DIR, name=f\"s1_tn_trial{trial.number}\")\n",
    "\n",
    "    # ===== Trainer: í”„ë¡ì‹œ ì„¸íŒ…(ëŠ˜ë¦¼) =====\n",
    "    trainer = Trainer(\n",
    "        default_root_dir=SAFE_ROOT,       # ì•ˆì „ ë£¨íŠ¸\n",
    "        max_epochs=30,\n",
    "        accelerator=\"cpu\", devices=1,\n",
    "        precision=32,\n",
    "        logger=logger,\n",
    "        enable_progress_bar=False,\n",
    "        enable_checkpointing=False,\n",
    "        gradient_clip_val=grad_clip,\n",
    "        accumulate_grad_batches=accum,\n",
    "        check_val_every_n_epoch=1,\n",
    "        # í”„ë¡ì‹œ ìƒ˜í”Œ ë¹„ìœ¨ í™•ì¥(í•™ìŠµ 60%, ê²€ì¦ 100%)\n",
    "        limit_train_batches=0.6,\n",
    "        limit_val_batches=1.0,\n",
    "        callbacks=[pruner_cb, es_cb],\n",
    "        deterministic=False, benchmark=True,\n",
    "        num_sanity_val_steps=0,\n",
    "    )\n",
    "\n",
    "    # ===== í•™ìŠµ =====\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # ===== ë² ìŠ¤íŠ¸ val_loss ì•ˆì „ ì·¨ë“ =====\n",
    "    val_loss_obj = getattr(es_cb, \"best_score\", None)\n",
    "    if val_loss_obj is None:\n",
    "        val_loss_obj = trainer.callback_metrics.get(\"val_loss\", None)\n",
    "\n",
    "    if val_loss_obj is None:\n",
    "        best_val = float(\"inf\")\n",
    "    else:\n",
    "        best_val = float(val_loss_obj.detach().cpu().item() if hasattr(val_loss_obj, \"detach\") else val_loss_obj)\n",
    "\n",
    "    # ë¡œê¹…\n",
    "    trial.set_user_attr(\"n_epochs\", trainer.current_epoch + 1)\n",
    "    trial.set_user_attr(\"val_loss\", best_val)\n",
    "    # ëª¨ë¸ ìš©ëŸ‰ ë¡œê·¸(ì‚¬í›„ ë¶„ì„ìš©)\n",
    "    trial.set_user_attr(\"param_count_M\", sum(p.numel() for p in model.parameters()) / 1e6)\n",
    "\n",
    "    return best_val\n",
    "\n",
    "#ì„ì‹œ ì½”ë“œ\n",
    "import os\n",
    "if os.path.exists(S1_PATH):\n",
    "    os.remove(S1_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d5f721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage2_objective(trial, source_dims, target_dims, s1_params):\n",
    "    \"\"\"\n",
    "    Stage-2: ë™ì‘ í•˜ì´í¼(ë² ì´ìŠ¤ë¼ì¸/ë¡œìŠ¤ í˜¼í•©)ë§Œ íƒìƒ‰ â€” objective: public SMAPE\n",
    "    - êµ¬ì¡°/ìš©ëŸ‰ í•˜ì´í¼ëŠ” Stage-1 ê²°ê³¼ë¥¼ ê³ ì • ì‚¬ìš©\n",
    "    \"\"\"\n",
    "    # --- Stage-1ì—ì„œ ê³ ì •í•  êµ¬ì¡°/ìš©ëŸ‰ í•˜ì´í¼ ê°€ì ¸ì˜¤ê¸° ---\n",
    "    # d_model\n",
    "    d_model = s1_params.get(\"d_model\", 2 ** s1_params.get(\"d_model_exp\", 7))  # fallback 128\n",
    "    # ê¹Šì´\n",
    "    n_encoders = s1_params.get(\"n_encoders\", 2)\n",
    "    n_decoders = s1_params.get(\"n_decoders\", max(1, n_encoders))\n",
    "    # TimesNet ì „ìš©\n",
    "    top_k       = s1_params.get(\"top_k\", 3)\n",
    "    num_kernels = s1_params.get(\"num_kernels\", 6)\n",
    "    d_ff_tn = s1_params.get(\"d_ff_tn\", int(d_model * 3))\n",
    "    # í•™ìŠµ ê´€ë ¨\n",
    "    learning_rate = s1_params.get(\"learning_rate\", 1e-3)\n",
    "    dropout_rate  = s1_params.get(\"dropout_rate\", 0.2)\n",
    "    lr_decay      = s1_params.get(\"lr_decay\", 1.0)\n",
    "    grad_clip     = s1_params.get(\"gradient_clip_val\", 1.0)\n",
    "    accum         = s1_params.get(\"accumulate_grad_batches\", 1)\n",
    "    # ì„ë² ë”©\n",
    "    d_bld       = s1_params.get(\"d_bld\", 16)\n",
    "    emb_dropout = s1_params.get(\"emb_dropout\", 0.0)\n",
    "\n",
    "    # --- Stage-2 íƒìƒ‰: ë™ì‘ í•˜ì´í¼ ---\n",
    "    beta_week = trial.suggest_float(\"beta_week\", 0.55, 0.85)\n",
    "    alpha     = trial.suggest_float(\"alpha\",     0.70, 0.85)\n",
    "    # ì ì‘í˜• Î² on/off ì–´ë¸”ë ˆì´ì…˜ (ì›í•˜ë©´ True ê³ ì •ë„ ê°€ëŠ¥)\n",
    "    use_adaptive_beta = trial.suggest_categorical(\"use_adaptive_beta\", [True, False])\n",
    "\n",
    "    # === Hyperparams dict ===\n",
    "    h = {\n",
    "        \"source_length\": SOURCE_LENGTH, \"target_length\": TARGET_LENGTH,\n",
    "        \"source_dims\": source_dims,     \"target_dims\": target_dims,\n",
    "        \"horizon_start\": 0,             \"quantiles\": [0.025, 0.5, 0.975],\n",
    "\n",
    "        # êµ¬ì¡°/ìš©ëŸ‰ (Stage-1 ê³ ì •)\n",
    "        \"d_model\": d_model,\n",
    "        \"n_encoders\": n_encoders,\n",
    "        \"n_decoders\": n_decoders,\n",
    "\n",
    "        # í•™ìŠµ ê´€ë ¨\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"dropout_rate\":  dropout_rate,\n",
    "        \"lr_decay\":      lr_decay,\n",
    "\n",
    "        # ì„ë² ë”©\n",
    "        \"num_buildings\": num_buildings,\n",
    "        \"d_bld\": d_bld,\n",
    "        \"emb_dropout\": emb_dropout,\n",
    "\n",
    "        # TimesNet ì „ìš©\n",
    "        \"top_k\": top_k,\n",
    "        \"num_kernels\": num_kernels,\n",
    "        \"d_ff_tn\": d_ff_tn,\n",
    "\n",
    "        # ë™ì‘ í•˜ì´í¼(íƒìƒ‰)\n",
    "        \"beta_week\": beta_week,\n",
    "        \"alpha\": alpha,\n",
    "        \"use_adaptive_beta\": use_adaptive_beta,\n",
    "    }\n",
    "\n",
    "    # === Model ===\n",
    "    model = TimesNet(h)\n",
    "\n",
    "    # ì½œë°±/í”„ë£¨ë„ˆ: ì§§ì€ ì—í­ì— ë§ê²Œ ì™„í™”\n",
    "    es_cb = EarlyStopping(\n",
    "        monitor=\"val_loss\", mode=\"min\",\n",
    "        patience=2, check_on_train_epoch_end=False\n",
    "    )\n",
    "    pruner = optuna.pruners.MedianPruner(\n",
    "        n_startup_trials=10,      # ì´ˆë°˜ 8ê°œëŠ” ì‚´ë ¤ì„œ ë¶„í¬ íŒŒì•…\n",
    "        n_warmup_steps=1,        # ì²« ì—í­ì€ ë²„í¼\n",
    "        interval_steps=1         # ë§¤ ì—í­ë§ˆë‹¤ í”„ë£¨ë‹ íŒì •\n",
    "    )\n",
    "    pruner_cb = PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")\n",
    "\n",
    "    trainer = Trainer(\n",
    "        max_epochs=5,\n",
    "        accelerator=\"cpu\", devices=1,\n",
    "        precision=32,\n",
    "        logger=False, enable_checkpointing=False,\n",
    "        enable_progress_bar=False,\n",
    "        gradient_clip_val=s1_params.get(\"gradient_clip_val\", 1.0),\n",
    "        accumulate_grad_batches=s1_params.get(\"accumulate_grad_batches\", 1),\n",
    "        check_val_every_n_epoch=1,\n",
    "        # ì†ë„â†‘ + ê²€ì¦ ì‹ í˜¸ ì•ˆì •ì„±(80%)\n",
    "        limit_train_batches=0.6,\n",
    "        limit_val_batches=0.8,\n",
    "        callbacks=[es_cb, pruner_cb],\n",
    "        deterministic=False, benchmark=True,\n",
    "        num_sanity_val_steps=0,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    try:\n",
    "        # === ì˜ˆì¸¡ ì‚°ì¶œ ===\n",
    "        model_eval = model.eval()\n",
    "        with torch.inference_mode():\n",
    "            raw = trainer.predict(model_eval, dataloaders=val_pred_loader)\n",
    "        preds_raw_list, fut_ex_list = zip(*raw)\n",
    "        residual_q = torch.cat(preds_raw_list, dim=0).cpu().numpy().astype(np.float32)  # (N,H,Q)\n",
    "        fut_ex     = torch.cat(fut_ex_list,   dim=0).cpu().numpy().astype(np.float32)   # (N,H)\n",
    "\n",
    "        # === íƒ€ê¹ƒ ìŠ¤ì¼€ì¼ ê³µê°„ ì¤€ë¹„ ===\n",
    "        mid = getattr(model_eval, \"median_idx\", 1)\n",
    "        y_scaled_full = np.stack([arr[:, -1] for arr in val_target_arrays], axis=0).astype(np.float32)\n",
    "\n",
    "        # ê¸¸ì´ ë™ê¸°í™”\n",
    "        n = min(residual_q.shape[0], len(group_ids_val), y_scaled_full.shape[0], fut_ex.shape[0])\n",
    "        y_scaled_used  = y_scaled_full[:n]\n",
    "        fut_ex_used    = fut_ex[:n]\n",
    "        group_ids_used = list(group_ids_val[:n])\n",
    "\n",
    "        # ===== (A) ìŠ¤ì¼€ì¼ ê³µê°„ ë°”ì´ì–´ìŠ¤ ì¶”ì • (ì¤‘ì•™ ë¶„ìœ„ìˆ˜ ê¸°ì¤€) =====\n",
    "        got  = residual_q[:n, :, mid]                 # (N,H)\n",
    "        need = y_scaled_used - fut_ex_used            # (N,H)\n",
    "        residual_bias = float((got - need).mean())    # scalar\n",
    "\n",
    "        # ===== (B) ë³´ì • ì „/í›„ ë‘ ë²„ì „ ëª¨ë‘ í‰ê°€ =====\n",
    "        yhat_scaled_full_raw  = got + fut_ex_used                 # ë³´ì • ì „\n",
    "        yhat_scaled_full_bias = (got - residual_bias) + fut_ex_used  # ë³´ì • í›„\n",
    "\n",
    "        Hpub = min(int(PUBLIC_H), y_scaled_used.shape[1])\n",
    "\n",
    "        def _eval_smape(yhat_scaled_full):\n",
    "            yhat_scaled = yhat_scaled_full[:, -Hpub:]\n",
    "            y_scaled    = y_scaled_used[:, -Hpub:]\n",
    "            yhat_real = scaler.backtransform_preds(yhat_scaled, group_ids=group_ids_used)\n",
    "            y_real    = scaler.backtransform_preds(y_scaled,    group_ids=group_ids_used)\n",
    "            yhat_real = np.clip(yhat_real, 0.0, None); y_real = np.clip(y_real, 0.0, None)\n",
    "            sm = _smape_np(y_real, yhat_real, eps=EPS_PUBLIC)\n",
    "            bs = float(np.nanmean(yhat_real - y_real))\n",
    "            return sm, bs\n",
    "\n",
    "        sm0, bs0 = _eval_smape(yhat_scaled_full_raw)    # ë³´ì • ì „\n",
    "        sm1, bs1 = _eval_smape(yhat_scaled_full_bias)   # ë³´ì • í›„\n",
    "\n",
    "        # ===== (C) ë” ì¢‹ì€ ìª½ ì±„íƒ =====\n",
    "        if sm1 <= sm0:\n",
    "            smape_pub, bias_pub = sm1, bs1\n",
    "            used_bias = residual_bias\n",
    "        else:\n",
    "            smape_pub, bias_pub = sm0, bs0\n",
    "            used_bias = 0.0\n",
    "\n",
    "        # (ì„ íƒ) í° í¸í–¥ í˜ë„í‹°\n",
    "        if abs(bias_pub) > 0.05 * (np.nanmean(y_scaled_used[:, -Hpub:]) + 1e-6):\n",
    "            smape_pub *= 1.01\n",
    "\n",
    "        # Optuna ê¸°ë¡\n",
    "        val_loss_tensor = trainer.callback_metrics.get(\"val_loss\", torch.tensor(float(\"inf\")))\n",
    "        trial.set_user_attr(\"val_loss\", float(val_loss_tensor.detach().cpu().item() if hasattr(val_loss_tensor, \"detach\") else val_loss_tensor))\n",
    "        trial.set_user_attr(\"smape_public\", smape_pub)\n",
    "        trial.set_user_attr(\"bias_public\", bias_pub)\n",
    "        trial.set_user_attr(\"bias_used_in_eval\", used_bias)\n",
    "        trial.set_user_attr(\"smape_no_bias\", sm0)\n",
    "        trial.set_user_attr(\"smape_with_bias\", sm1)\n",
    "        trial.set_user_attr(\"public_H_used\", Hpub)\n",
    "        trial.set_user_attr(\"beta_week\", beta_week)\n",
    "        trial.set_user_attr(\"alpha\", alpha)\n",
    "        trial.set_user_attr(\"use_adaptive_beta\", use_adaptive_beta)\n",
    "\n",
    "        return smape_pub\n",
    "\n",
    "    except Exception as e:\n",
    "        trial.set_user_attr(\"public_eval_error\", str(e))\n",
    "        return float(\"inf\")\n",
    "\n",
    "#ì„ì‹œ ì½”ë“œ\n",
    "import os\n",
    "if os.path.exists(S2_PATH):\n",
    "    os.remove(S2_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YaxIpzqcC7Xh",
   "metadata": {
    "id": "YaxIpzqcC7Xh"
   },
   "source": [
    "## Hyperparameter tuning with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CFA6rCXu0sM0",
   "metadata": {
    "id": "CFA6rCXu0sM0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\optuna\\_experimental.py:32: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Daniel\\anaconda3\\envs\\aiot\\lib\\site-packages\\optuna\\_experimental.py:32: ExperimentalWarning: Argument ``group`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "[I 2025-08-21 00:48:26,793] A new study created in memory with name: TimesNet_stage1_capacity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Dims: 23, Target Dims: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [00:00<?, ?it/s]Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type       | Params\n",
      "----------------------------------------------\n",
      "0 | bld_emb        | Embedding  | 800   \n",
      "1 | bld_to_d       | Linear     | 1.2 K \n",
      "2 | bld_drop       | Dropout    | 0     \n",
      "3 | source_project | Linear     | 3.1 K \n",
      "4 | target_project | Linear     | 3.1 K \n",
      "5 | dropout        | Dropout    | 0     \n",
      "6 | encoder        | ModuleList | 5.5 M \n",
      "7 | decoder        | ModuleList | 5.5 M \n",
      "8 | output_layer   | Linear     | 387   \n",
      "----------------------------------------------\n",
      "11.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 M    Total params\n",
      "22.043    Total estimated model params size (MB)\n",
      "  0%|          | 0/150 [02:08<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-21 00:50:35,066] Trial 0 finished with value: 0.42607203125953674 and parameters: {'d_model_exp': 7, 'n_encoders': 1, 'top_k': 2, 'num_kernels': 4, 'd_ff_mult': 2, 'learning_rate': 0.0006729379254033839, 'dropout_rate': 0.1040268209025972, 'lr_decay': 0.9948039965565193, 'd_bld': 8, 'emb_dropout': 0.09949814801609339, 'gradient_clip_val': 1.4394564889044064, 'accumulate_grad_batches': 4, 'use_adaptive_beta': True}. Best is trial 0 with value: 0.42607203125953674.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.426072:   1%|          | 1/150 [02:08<5:20:19, 128.99s/it]Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type       | Params\n",
      "----------------------------------------------\n",
      "0 | bld_emb        | Embedding  | 1.6 K \n",
      "1 | bld_to_d       | Linear     | 2.2 K \n",
      "2 | bld_drop       | Dropout    | 0     \n",
      "3 | source_project | Linear     | 3.1 K \n",
      "4 | target_project | Linear     | 3.1 K \n",
      "5 | dropout        | Dropout    | 0     \n",
      "6 | encoder        | ModuleList | 5.5 M \n",
      "7 | decoder        | ModuleList | 5.5 M \n",
      "8 | output_layer   | Linear     | 387   \n",
      "----------------------------------------------\n",
      "11.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 M    Total params\n",
      "22.047    Total estimated model params size (MB)\n",
      "Best trial: 0. Best value: 0.426072:   1%|          | 1/150 [03:53<5:20:19, 128.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-21 00:52:20,597] Trial 1 finished with value: 0.2706039845943451 and parameters: {'d_model_exp': 7, 'n_encoders': 1, 'top_k': 2, 'num_kernels': 4, 'd_ff_mult': 2, 'learning_rate': 0.00048781839275657195, 'dropout_rate': 0.04705512781468122, 'lr_decay': 0.9883643242927729, 'd_bld': 16, 'emb_dropout': 0.1278787865753874, 'gradient_clip_val': 1.8670456897738648, 'accumulate_grad_batches': 2, 'use_adaptive_beta': False}. Best is trial 1 with value: 0.2706039845943451.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.270604:   1%|â–         | 2/150 [03:54<4:44:09, 115.20s/it]Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type       | Params\n",
      "----------------------------------------------\n",
      "0 | bld_emb        | Embedding  | 800   \n",
      "1 | bld_to_d       | Linear     | 1.2 K \n",
      "2 | bld_drop       | Dropout    | 0     \n",
      "3 | source_project | Linear     | 3.1 K \n",
      "4 | target_project | Linear     | 3.1 K \n",
      "5 | dropout        | Dropout    | 0     \n",
      "6 | encoder        | ModuleList | 5.5 M \n",
      "7 | decoder        | ModuleList | 5.5 M \n",
      "8 | output_layer   | Linear     | 387   \n",
      "----------------------------------------------\n",
      "11.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 M    Total params\n",
      "22.043    Total estimated model params size (MB)\n",
      "Best trial: 1. Best value: 0.270604:   1%|â–         | 2/150 [04:47<4:44:09, 115.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-21 00:53:14,371] Trial 2 finished with value: 0.31652435660362244 and parameters: {'d_model_exp': 7, 'n_encoders': 1, 'top_k': 2, 'num_kernels': 4, 'd_ff_mult': 2, 'learning_rate': 0.0011924638532876466, 'dropout_rate': 0.013055590674040206, 'lr_decay': 0.9948968942631489, 'd_bld': 8, 'emb_dropout': 0.07784047963521197, 'gradient_clip_val': 1.0601852051232301, 'accumulate_grad_batches': 2, 'use_adaptive_beta': True}. Best is trial 1 with value: 0.2706039845943451.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.270604:   2%|â–         | 3/150 [04:48<3:33:29, 87.14s/it] Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type       | Params\n",
      "----------------------------------------------\n",
      "0 | bld_emb        | Embedding  | 800   \n",
      "1 | bld_to_d       | Linear     | 1.2 K \n",
      "2 | bld_drop       | Dropout    | 0     \n",
      "3 | source_project | Linear     | 3.1 K \n",
      "4 | target_project | Linear     | 3.1 K \n",
      "5 | dropout        | Dropout    | 0     \n",
      "6 | encoder        | ModuleList | 5.5 M \n",
      "7 | decoder        | ModuleList | 5.5 M \n",
      "8 | output_layer   | Linear     | 387   \n",
      "----------------------------------------------\n",
      "11.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 M    Total params\n",
      "22.043    Total estimated model params size (MB)\n",
      "Best trial: 1. Best value: 0.270604:   2%|â–         | 3/150 [05:15<3:33:29, 87.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-21 00:53:41,829] Trial 3 pruned. Trial was pruned at epoch 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.270604:   3%|â–         | 4/150 [05:15<2:34:41, 63.57s/it]Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type       | Params\n",
      "----------------------------------------------\n",
      "0 | bld_emb        | Embedding  | 800   \n",
      "1 | bld_to_d       | Linear     | 1.2 K \n",
      "2 | bld_drop       | Dropout    | 0     \n",
      "3 | source_project | Linear     | 3.1 K \n",
      "4 | target_project | Linear     | 3.1 K \n",
      "5 | dropout        | Dropout    | 0     \n",
      "6 | encoder        | ModuleList | 5.5 M \n",
      "7 | decoder        | ModuleList | 5.5 M \n",
      "8 | output_layer   | Linear     | 387   \n",
      "----------------------------------------------\n",
      "11.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 M    Total params\n",
      "22.043    Total estimated model params size (MB)\n",
      "Best trial: 1. Best value: 0.270604:   3%|â–         | 4/150 [07:12<2:34:41, 63.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-21 00:55:39,684] Trial 4 finished with value: 0.26438188552856445 and parameters: {'d_model_exp': 7, 'n_encoders': 1, 'top_k': 2, 'num_kernels': 4, 'd_ff_mult': 2, 'learning_rate': 0.0011677462344176614, 'dropout_rate': 0.2467988321660723, 'lr_decay': 0.9931819106931228, 'd_bld': 8, 'emb_dropout': 0.05430672992434067, 'gradient_clip_val': 1.9393171476716962, 'accumulate_grad_batches': 4, 'use_adaptive_beta': True}. Best is trial 4 with value: 0.26438188552856445.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.264382:   3%|â–         | 5/150 [07:13<3:21:00, 83.18s/it]Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type       | Params\n",
      "----------------------------------------------\n",
      "0 | bld_emb        | Embedding  | 800   \n",
      "1 | bld_to_d       | Linear     | 1.2 K \n",
      "2 | bld_drop       | Dropout    | 0     \n",
      "3 | source_project | Linear     | 3.1 K \n",
      "4 | target_project | Linear     | 3.1 K \n",
      "5 | dropout        | Dropout    | 0     \n",
      "6 | encoder        | ModuleList | 5.5 M \n",
      "7 | decoder        | ModuleList | 5.5 M \n",
      "8 | output_layer   | Linear     | 387   \n",
      "----------------------------------------------\n",
      "11.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 M    Total params\n",
      "22.043    Total estimated model params size (MB)\n",
      "Best trial: 4. Best value: 0.264382:   3%|â–         | 5/150 [07:41<3:21:00, 83.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-21 00:56:07,861] Trial 5 pruned. Trial was pruned at epoch 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.264382:   4%|â–         | 6/150 [07:41<2:34:40, 64.45s/it]Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type       | Params\n",
      "----------------------------------------------\n",
      "0 | bld_emb        | Embedding  | 1.6 K \n",
      "1 | bld_to_d       | Linear     | 2.2 K \n",
      "2 | bld_drop       | Dropout    | 0     \n",
      "3 | source_project | Linear     | 3.1 K \n",
      "4 | target_project | Linear     | 3.1 K \n",
      "5 | dropout        | Dropout    | 0     \n",
      "6 | encoder        | ModuleList | 5.5 M \n",
      "7 | decoder        | ModuleList | 5.5 M \n",
      "8 | output_layer   | Linear     | 387   \n",
      "----------------------------------------------\n",
      "11.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 M    Total params\n",
      "22.047    Total estimated model params size (MB)\n",
      "Best trial: 4. Best value: 0.264382:   4%|â–         | 6/150 [08:08<2:34:40, 64.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-21 00:56:35,631] Trial 6 pruned. Trial was pruned at epoch 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.264382:   5%|â–         | 7/150 [08:09<2:05:01, 52.46s/it]Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type       | Params\n",
      "----------------------------------------------\n",
      "0 | bld_emb        | Embedding  | 1.6 K \n",
      "1 | bld_to_d       | Linear     | 2.2 K \n",
      "2 | bld_drop       | Dropout    | 0     \n",
      "3 | source_project | Linear     | 3.1 K \n",
      "4 | target_project | Linear     | 3.1 K \n",
      "5 | dropout        | Dropout    | 0     \n",
      "6 | encoder        | ModuleList | 5.5 M \n",
      "7 | decoder        | ModuleList | 5.5 M \n",
      "8 | output_layer   | Linear     | 387   \n",
      "----------------------------------------------\n",
      "11.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 M    Total params\n",
      "22.047    Total estimated model params size (MB)\n",
      "Best trial: 4. Best value: 0.264382:   5%|â–         | 7/150 [08:36<2:05:01, 52.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-21 00:57:03,357] Trial 7 pruned. Trial was pruned at epoch 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.264382:   5%|â–Œ         | 8/150 [08:37<1:45:31, 44.59s/it]Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type       | Params\n",
      "----------------------------------------------\n",
      "0 | bld_emb        | Embedding  | 1.6 K \n",
      "1 | bld_to_d       | Linear     | 2.2 K \n",
      "2 | bld_drop       | Dropout    | 0     \n",
      "3 | source_project | Linear     | 3.1 K \n",
      "4 | target_project | Linear     | 3.1 K \n",
      "5 | dropout        | Dropout    | 0     \n",
      "6 | encoder        | ModuleList | 5.5 M \n",
      "7 | decoder        | ModuleList | 5.5 M \n",
      "8 | output_layer   | Linear     | 387   \n",
      "----------------------------------------------\n",
      "11.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 M    Total params\n",
      "22.047    Total estimated model params size (MB)\n",
      "Best trial: 4. Best value: 0.264382:   5%|â–Œ         | 8/150 [09:30<1:45:31, 44.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-21 00:57:57,589] Trial 8 pruned. Trial was pruned at epoch 3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.264382:   6%|â–Œ         | 9/150 [09:31<1:51:52, 47.61s/it]Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type       | Params\n",
      "----------------------------------------------\n",
      "0 | bld_emb        | Embedding  | 800   \n",
      "1 | bld_to_d       | Linear     | 1.2 K \n",
      "2 | bld_drop       | Dropout    | 0     \n",
      "3 | source_project | Linear     | 3.1 K \n",
      "4 | target_project | Linear     | 3.1 K \n",
      "5 | dropout        | Dropout    | 0     \n",
      "6 | encoder        | ModuleList | 5.5 M \n",
      "7 | decoder        | ModuleList | 5.5 M \n",
      "8 | output_layer   | Linear     | 387   \n",
      "----------------------------------------------\n",
      "11.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 M    Total params\n",
      "22.043    Total estimated model params size (MB)\n",
      "Best trial: 4. Best value: 0.264382:   6%|â–Œ         | 9/150 [11:29<1:51:52, 47.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-21 00:59:56,103] Trial 9 finished with value: 0.201958566904068 and parameters: {'d_model_exp': 7, 'n_encoders': 1, 'top_k': 2, 'num_kernels': 4, 'd_ff_mult': 2, 'learning_rate': 0.0019568031436697246, 'dropout_rate': 0.08185935786716114, 'lr_decay': 0.985976304283168, 'd_bld': 8, 'emb_dropout': 0.1060221397095156, 'gradient_clip_val': 1.0755984672112182, 'accumulate_grad_batches': 2, 'use_adaptive_beta': False}. Best is trial 9 with value: 0.201958566904068.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.201959:   7%|â–‹         | 10/150 [11:30<2:42:08, 69.49s/it]Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type       | Params\n",
      "----------------------------------------------\n",
      "0 | bld_emb        | Embedding  | 800   \n",
      "1 | bld_to_d       | Linear     | 1.2 K \n",
      "2 | bld_drop       | Dropout    | 0     \n",
      "3 | source_project | Linear     | 3.1 K \n",
      "4 | target_project | Linear     | 3.1 K \n",
      "5 | dropout        | Dropout    | 0     \n",
      "6 | encoder        | ModuleList | 5.5 M \n",
      "7 | decoder        | ModuleList | 5.5 M \n",
      "8 | output_layer   | Linear     | 387   \n",
      "----------------------------------------------\n",
      "11.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 M    Total params\n",
      "22.043    Total estimated model params size (MB)\n",
      "Best trial: 9. Best value: 0.201959:   7%|â–‹         | 10/150 [11:57<2:42:08, 69.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-21 01:00:23,887] Trial 10 pruned. Trial was pruned at epoch 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.201959:   7%|â–‹         | 11/150 [11:57<2:11:27, 56.74s/it]Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type       | Params\n",
      "----------------------------------------------\n",
      "0 | bld_emb        | Embedding  | 800   \n",
      "1 | bld_to_d       | Linear     | 1.2 K \n",
      "2 | bld_drop       | Dropout    | 0     \n",
      "3 | source_project | Linear     | 3.1 K \n",
      "4 | target_project | Linear     | 3.1 K \n",
      "5 | dropout        | Dropout    | 0     \n",
      "6 | encoder        | ModuleList | 5.5 M \n",
      "7 | decoder        | ModuleList | 5.5 M \n",
      "8 | output_layer   | Linear     | 387   \n",
      "----------------------------------------------\n",
      "11.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 M    Total params\n",
      "22.043    Total estimated model params size (MB)\n",
      "Best trial: 9. Best value: 0.201959:   7%|â–‹         | 11/150 [12:24<2:11:27, 56.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-21 01:00:51,754] Trial 11 pruned. Trial was pruned at epoch 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.201959:   8%|â–Š         | 12/150 [12:25<1:50:17, 47.95s/it]Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type       | Params\n",
      "----------------------------------------------\n",
      "0 | bld_emb        | Embedding  | 800   \n",
      "1 | bld_to_d       | Linear     | 1.2 K \n",
      "2 | bld_drop       | Dropout    | 0     \n",
      "3 | source_project | Linear     | 3.1 K \n",
      "4 | target_project | Linear     | 3.1 K \n",
      "5 | dropout        | Dropout    | 0     \n",
      "6 | encoder        | ModuleList | 5.5 M \n",
      "7 | decoder        | ModuleList | 5.5 M \n",
      "8 | output_layer   | Linear     | 387   \n",
      "----------------------------------------------\n",
      "11.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 M    Total params\n",
      "22.043    Total estimated model params size (MB)\n",
      "Best trial: 9. Best value: 0.201959:   8%|â–Š         | 12/150 [12:52<1:50:17, 47.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-21 01:01:19,421] Trial 12 pruned. Trial was pruned at epoch 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.201959:   9%|â–Š         | 13/150 [12:53<1:35:27, 41.81s/it]Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type       | Params\n",
      "----------------------------------------------\n",
      "0 | bld_emb        | Embedding  | 800   \n",
      "1 | bld_to_d       | Linear     | 1.2 K \n",
      "2 | bld_drop       | Dropout    | 0     \n",
      "3 | source_project | Linear     | 3.1 K \n",
      "4 | target_project | Linear     | 3.1 K \n",
      "5 | dropout        | Dropout    | 0     \n",
      "6 | encoder        | ModuleList | 5.5 M \n",
      "7 | decoder        | ModuleList | 5.5 M \n",
      "8 | output_layer   | Linear     | 387   \n",
      "----------------------------------------------\n",
      "11.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 M    Total params\n",
      "22.043    Total estimated model params size (MB)\n",
      "Best trial: 9. Best value: 0.201959:   9%|â–Š         | 13/150 [13:20<1:35:27, 41.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-21 01:01:47,549] Trial 13 pruned. Trial was pruned at epoch 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.201959:   9%|â–‰         | 14/150 [13:21<1:25:22, 37.66s/it]Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type       | Params\n",
      "----------------------------------------------\n",
      "0 | bld_emb        | Embedding  | 800   \n",
      "1 | bld_to_d       | Linear     | 1.2 K \n",
      "2 | bld_drop       | Dropout    | 0     \n",
      "3 | source_project | Linear     | 3.1 K \n",
      "4 | target_project | Linear     | 3.1 K \n",
      "5 | dropout        | Dropout    | 0     \n",
      "6 | encoder        | ModuleList | 5.5 M \n",
      "7 | decoder        | ModuleList | 5.5 M \n",
      "8 | output_layer   | Linear     | 387   \n",
      "----------------------------------------------\n",
      "11.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 M    Total params\n",
      "22.043    Total estimated model params size (MB)\n",
      "Best trial: 9. Best value: 0.201959:   9%|â–‰         | 14/150 [14:40<1:25:22, 37.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-21 01:03:07,118] Trial 14 finished with value: 0.2557673156261444 and parameters: {'d_model_exp': 7, 'n_encoders': 1, 'top_k': 2, 'num_kernels': 4, 'd_ff_mult': 2, 'learning_rate': 0.001987282041699552, 'dropout_rate': 0.04169874259626259, 'lr_decay': 0.9923894396949745, 'd_bld': 8, 'emb_dropout': 0.16349132487100246, 'gradient_clip_val': 0.648915908183638, 'accumulate_grad_batches': 2, 'use_adaptive_beta': False}. Best is trial 9 with value: 0.201958566904068.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.201959:  10%|â–ˆ         | 15/150 [14:41<1:53:11, 50.31s/it]Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type       | Params\n",
      "----------------------------------------------\n",
      "0 | bld_emb        | Embedding  | 800   \n",
      "1 | bld_to_d       | Linear     | 1.2 K \n",
      "2 | bld_drop       | Dropout    | 0     \n",
      "3 | source_project | Linear     | 3.1 K \n",
      "4 | target_project | Linear     | 3.1 K \n",
      "5 | dropout        | Dropout    | 0     \n",
      "6 | encoder        | ModuleList | 5.5 M \n",
      "7 | decoder        | ModuleList | 5.5 M \n",
      "8 | output_layer   | Linear     | 387   \n",
      "----------------------------------------------\n",
      "11.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 M    Total params\n",
      "22.043    Total estimated model params size (MB)\n",
      "Best trial: 9. Best value: 0.201959:  10%|â–ˆ         | 15/150 [15:34<1:53:11, 50.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-21 01:04:00,967] Trial 15 pruned. Trial was pruned at epoch 3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.201959:  11%|â–ˆ         | 16/150 [15:34<1:54:44, 51.38s/it]Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type       | Params\n",
      "----------------------------------------------\n",
      "0 | bld_emb        | Embedding  | 800   \n",
      "1 | bld_to_d       | Linear     | 1.2 K \n",
      "2 | bld_drop       | Dropout    | 0     \n",
      "3 | source_project | Linear     | 3.1 K \n",
      "4 | target_project | Linear     | 3.1 K \n",
      "5 | dropout        | Dropout    | 0     \n",
      "6 | encoder        | ModuleList | 5.5 M \n",
      "7 | decoder        | ModuleList | 5.5 M \n",
      "8 | output_layer   | Linear     | 387   \n",
      "----------------------------------------------\n",
      "11.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 M    Total params\n",
      "22.043    Total estimated model params size (MB)\n",
      "Best trial: 9. Best value: 0.201959:  11%|â–ˆ         | 16/150 [16:01<1:54:44, 51.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-21 01:04:28,774] Trial 16 pruned. Trial was pruned at epoch 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.201959:  11%|â–ˆâ–        | 17/150 [16:02<1:38:10, 44.29s/it]Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type       | Params\n",
      "----------------------------------------------\n",
      "0 | bld_emb        | Embedding  | 800   \n",
      "1 | bld_to_d       | Linear     | 1.2 K \n",
      "2 | bld_drop       | Dropout    | 0     \n",
      "3 | source_project | Linear     | 3.1 K \n",
      "4 | target_project | Linear     | 3.1 K \n",
      "5 | dropout        | Dropout    | 0     \n",
      "6 | encoder        | ModuleList | 5.5 M \n",
      "7 | decoder        | ModuleList | 5.5 M \n",
      "8 | output_layer   | Linear     | 387   \n",
      "----------------------------------------------\n",
      "11.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 M    Total params\n",
      "22.043    Total estimated model params size (MB)\n",
      "Best trial: 9. Best value: 0.201959:  11%|â–ˆâ–        | 17/150 [16:56<1:38:10, 44.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-21 01:05:23,015] Trial 17 pruned. Trial was pruned at epoch 3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.201959:  12%|â–ˆâ–        | 18/150 [16:56<1:44:00, 47.28s/it]Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type       | Params\n",
      "----------------------------------------------\n",
      "0 | bld_emb        | Embedding  | 1.6 K \n",
      "1 | bld_to_d       | Linear     | 2.2 K \n",
      "2 | bld_drop       | Dropout    | 0     \n",
      "3 | source_project | Linear     | 3.1 K \n",
      "4 | target_project | Linear     | 3.1 K \n",
      "5 | dropout        | Dropout    | 0     \n",
      "6 | encoder        | ModuleList | 5.5 M \n",
      "7 | decoder        | ModuleList | 5.5 M \n",
      "8 | output_layer   | Linear     | 387   \n",
      "----------------------------------------------\n",
      "11.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 M    Total params\n",
      "22.047    Total estimated model params size (MB)\n",
      "Best trial: 9. Best value: 0.201959:  12%|â–ˆâ–        | 18/150 [17:24<1:44:00, 47.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-21 01:05:51,185] Trial 18 pruned. Trial was pruned at epoch 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.201959:  13%|â–ˆâ–        | 19/150 [17:25<1:30:40, 41.53s/it]Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type       | Params\n",
      "----------------------------------------------\n",
      "0 | bld_emb        | Embedding  | 800   \n",
      "1 | bld_to_d       | Linear     | 1.2 K \n",
      "2 | bld_drop       | Dropout    | 0     \n",
      "3 | source_project | Linear     | 3.1 K \n",
      "4 | target_project | Linear     | 3.1 K \n",
      "5 | dropout        | Dropout    | 0     \n",
      "6 | encoder        | ModuleList | 5.5 M \n",
      "7 | decoder        | ModuleList | 5.5 M \n",
      "8 | output_layer   | Linear     | 387   \n",
      "----------------------------------------------\n",
      "11.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 M    Total params\n",
      "22.043    Total estimated model params size (MB)\n",
      "Best trial: 9. Best value: 0.201959:  13%|â–ˆâ–        | 19/150 [18:19<1:30:40, 41.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-21 01:06:45,846] Trial 19 pruned. Trial was pruned at epoch 3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.201959:  13%|â–ˆâ–        | 20/150 [18:19<1:38:32, 45.48s/it]Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type       | Params\n",
      "----------------------------------------------\n",
      "0 | bld_emb        | Embedding  | 1.6 K \n",
      "1 | bld_to_d       | Linear     | 2.2 K \n",
      "2 | bld_drop       | Dropout    | 0     \n",
      "3 | source_project | Linear     | 3.1 K \n",
      "4 | target_project | Linear     | 3.1 K \n",
      "5 | dropout        | Dropout    | 0     \n",
      "6 | encoder        | ModuleList | 5.5 M \n",
      "7 | decoder        | ModuleList | 5.5 M \n",
      "8 | output_layer   | Linear     | 387   \n",
      "----------------------------------------------\n",
      "11.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 M    Total params\n",
      "22.047    Total estimated model params size (MB)\n",
      "Best trial: 9. Best value: 0.201959:  13%|â–ˆâ–        | 20/150 [18:47<1:38:32, 45.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-21 01:07:13,861] Trial 20 pruned. Trial was pruned at epoch 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.201959:  14%|â–ˆâ–        | 21/150 [18:47<1:26:37, 40.29s/it]Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type       | Params\n",
      "----------------------------------------------\n",
      "0 | bld_emb        | Embedding  | 1.6 K \n",
      "1 | bld_to_d       | Linear     | 2.2 K \n",
      "2 | bld_drop       | Dropout    | 0     \n",
      "3 | source_project | Linear     | 3.1 K \n",
      "4 | target_project | Linear     | 3.1 K \n",
      "5 | dropout        | Dropout    | 0     \n",
      "6 | encoder        | ModuleList | 5.5 M \n",
      "7 | decoder        | ModuleList | 5.5 M \n",
      "8 | output_layer   | Linear     | 387   \n",
      "----------------------------------------------\n",
      "11.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 M    Total params\n",
      "22.047    Total estimated model params size (MB)\n",
      "Best trial: 9. Best value: 0.201959:  14%|â–ˆâ–        | 21/150 [19:15<1:26:37, 40.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-21 01:07:42,182] Trial 21 pruned. Trial was pruned at epoch 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.201959:  15%|â–ˆâ–        | 22/150 [19:16<1:18:09, 36.63s/it]Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type       | Params\n",
      "----------------------------------------------\n",
      "0 | bld_emb        | Embedding  | 800   \n",
      "1 | bld_to_d       | Linear     | 1.2 K \n",
      "2 | bld_drop       | Dropout    | 0     \n",
      "3 | source_project | Linear     | 3.1 K \n",
      "4 | target_project | Linear     | 3.1 K \n",
      "5 | dropout        | Dropout    | 0     \n",
      "6 | encoder        | ModuleList | 5.5 M \n",
      "7 | decoder        | ModuleList | 5.5 M \n",
      "8 | output_layer   | Linear     | 387   \n",
      "----------------------------------------------\n",
      "11.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 M    Total params\n",
      "22.043    Total estimated model params size (MB)\n",
      "Best trial: 9. Best value: 0.201959:  15%|â–ˆâ–        | 22/150 [19:18<1:18:09, 36.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-21 01:07:45,127] Trial 22 finished with value: inf and parameters: {'d_model_exp': 7, 'n_encoders': 1, 'top_k': 2, 'num_kernels': 4, 'd_ff_mult': 2, 'learning_rate': 0.001553779841792309, 'dropout_rate': 0.09954350505567366, 'lr_decay': 0.9863993291691993, 'd_bld': 8, 'emb_dropout': 0.1174328663870561, 'gradient_clip_val': 1.1399339025834854, 'accumulate_grad_batches': 4, 'use_adaptive_beta': False}. Best is trial 9 with value: 0.201958566904068.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.201959:  15%|â–ˆâ–Œ        | 23/150 [19:19<56:08, 26.52s/it]  Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type       | Params\n",
      "----------------------------------------------\n",
      "0 | bld_emb        | Embedding  | 800   \n",
      "1 | bld_to_d       | Linear     | 1.2 K \n",
      "2 | bld_drop       | Dropout    | 0     \n",
      "3 | source_project | Linear     | 3.1 K \n",
      "4 | target_project | Linear     | 3.1 K \n",
      "5 | dropout        | Dropout    | 0     \n",
      "6 | encoder        | ModuleList | 5.5 M \n",
      "7 | decoder        | ModuleList | 5.5 M \n",
      "8 | output_layer   | Linear     | 387   \n",
      "----------------------------------------------\n",
      "11.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 M    Total params\n",
      "22.043    Total estimated model params size (MB)\n"
     ]
    }
   ],
   "source": [
    "# ì‹¤ì¸¡ ì…ë ¥ ì°¨ì›\n",
    "actual_source_dims = train_source_arrays[0].shape[1]\n",
    "actual_target_dims = train_target_arrays[0].shape[1]\n",
    "print(f\"Source Dims: {actual_source_dims}, Target Dims: {actual_target_dims}\")\n",
    "\n",
    "RUN_STAGE1 = True  # ë‹¤ìŒì— ë‹¤ì‹œ ëŒë¦´ ë•Œ ì—¬ê¸°ë§Œ í† ê¸€\n",
    "\n",
    "study_s1 = load_study(S1_PATH)\n",
    "\n",
    "if (study_s1 is None) and RUN_STAGE1:\n",
    "    # Hyperband: ê¸¸ê³  ë„“ì€ íƒìƒ‰ì— ìœ ë¦¬ (Râ†’reduction_factorë¡œ ê°•ë„ ì¡°ì ˆ)\n",
    "    pruner = optuna.pruners.HyperbandPruner(min_resource=1, reduction_factor=3)\n",
    "    study_s1 = optuna.create_study(\n",
    "        sampler=optuna.samplers.TPESampler(seed=random_seed, multivariate=True, group=True),\n",
    "        pruner=pruner,\n",
    "        study_name=\"TimesNet_stage1_capacity\",\n",
    "        direction=\"minimize\",\n",
    "    )\n",
    "\n",
    "    N_TRIALS = 150   # â† ì¶©ë¶„íˆ ëŠ˜ë¦¼(ì˜ˆ: 150~300)\n",
    "    study_s1.optimize(\n",
    "        lambda tr: stage1_objective(tr, actual_source_dims, actual_target_dims),\n",
    "        n_trials=N_TRIALS,\n",
    "        show_progress_bar=True,\n",
    "        gc_after_trial=True,\n",
    "        n_jobs=1,  # Colab ë‹¨ì¼ GPU ê¸°ì¤€\n",
    "    )\n",
    "\n",
    "    save_study(study_s1, S1_PATH)\n",
    "\n",
    "elif study_s1 is None and not RUN_STAGE1:\n",
    "    raise RuntimeError(f\"RUN_STAGE1=False ì´ì§€ë§Œ ì €ì¥ëœ Stage-1 ìŠ¤í„°ë””ê°€ ì—†ìŠµë‹ˆë‹¤: {S1_PATH}\")\n",
    "\n",
    "# ìš”ì•½ ì¶œë ¥\n",
    "best_s1 = study_s1.best_trial\n",
    "print(\"S1 best val_loss:\", best_s1.value)\n",
    "print(\"S1 best params:\", best_s1.params)\n",
    "print(\"S1 attrs:\", getattr(best_s1, \"user_attrs\", {}))\n",
    "s1p = best_s1.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YLMPtxwaarEW",
   "metadata": {
    "id": "YLMPtxwaarEW"
   },
   "outputs": [],
   "source": [
    "# í¼ë¸”ë¦­ SMAPE í‰ê°€ì— í•„ìš”í•œ ì „ì—­ í™•ì¸\n",
    "assert 'val_pred_loader' in globals() and 'scaler' in globals() \\\n",
    "    and 'group_ids_val' in globals() and 'val_target_arrays' in globals(), \\\n",
    "    \"Public SMAPE í‰ê°€ì— í•„ìš”í•œ ì „ì—­ ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "RUN_STAGE2 = True  # â† íŠœë‹ì„ â€œê±´ë„ˆë›°ë ¤ë©´â€ False ë¡œë§Œ ë°”ê¾¸ë©´ ë¨\n",
    "\n",
    "study_s2 = load_study(S2_PATH)\n",
    "if (study_s2 is None) and RUN_STAGE2:\n",
    "    study_s2 = optuna.create_study(\n",
    "        sampler=optuna.samplers.TPESampler(seed=random_seed),\n",
    "        pruner=optuna.pruners.MedianPruner(n_startup_trials=10),\n",
    "        study_name=\"TimesNet_stage2_behavior\",\n",
    "        direction=\"minimize\",  # ëª©ì : Public SMAPE\n",
    "    )\n",
    "    study_s2.optimize(\n",
    "        lambda tr: stage2_objective(tr, actual_source_dims, actual_target_dims, s1p),\n",
    "        n_trials=80, show_progress_bar=True, gc_after_trial=True\n",
    "    )\n",
    "    with open(S2_PATH, \"wb\") as f:\n",
    "        pickle.dump(study_s2, f)\n",
    "elif study_s2 is None and not RUN_STAGE2:\n",
    "    raise RuntimeError(f\"RUN_STAGE2=False ì´ì§€ë§Œ ì €ì¥ëœ Stage-2 ìŠ¤í„°ë””ê°€ ì—†ìŠµë‹ˆë‹¤: {S2_PATH}\")\n",
    "\n",
    "best_s2 = study_s2.best_trial\n",
    "print(\"S2 best public SMAPE:\", best_s2.value)\n",
    "print(\"S2 best params:\", best_s2.params)\n",
    "print(\"S2 attrs:\", best_s2.user_attrs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "W1Y2hzK24K1g",
   "metadata": {
    "id": "W1Y2hzK24K1g"
   },
   "outputs": [],
   "source": [
    "# ============================== #\n",
    "# Final training (TimesNet, Determinism OFF)\n",
    "# ============================== #\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "import numpy as np, torch, os, json, shutil, pickle\n",
    "from datetime import datetime, timezone\n",
    "from lightning.pytorch import Trainer\n",
    "\n",
    "NONNEG_CLIP = True\n",
    "\n",
    "# --- Stage-1/2 ê²°ê³¼ ì‚¬ìš© ---\n",
    "p1 = best_s1.params\n",
    "p2 = best_s2.params\n",
    "\n",
    "# --- êµ¬ì¡° ë³µì› (S1; TimesNet ì „ìš©) ---\n",
    "# d_model\n",
    "d_model = p1.get(\"d_model\", 2 ** p1.get(\"d_model_exp\", 7))  # fallback=128\n",
    "# ê¹Šì´\n",
    "n_encoders   = p1.get(\"n_encoders\", 2)\n",
    "n_decoders   = p1.get(\"n_decoders\", max(1, n_encoders))\n",
    "# TimesNet ê³ ìœ \n",
    "top_k        = p1.get(\"top_k\", 3)\n",
    "num_kernels  = p1.get(\"num_kernels\", 6)\n",
    "d_ff_tn      = p1.get(\"d_ff_tn\", int(d_model * p1.get(\"d_ff_mult\", 3)))\n",
    "\n",
    "# í•™ìŠµ ê´€ë ¨ (S1)\n",
    "learning_rate = p1.get(\"learning_rate\", 1e-3)\n",
    "dropout_rate  = p1.get(\"dropout_rate\", 0.2)\n",
    "lr_decay      = p1.get(\"lr_decay\", 1.0)\n",
    "grad_clip     = float(p1.get(\"gradient_clip_val\", 1.0))\n",
    "accum         = p1.get(\"accumulate_grad_batches\", 1)\n",
    "# ì„ë² ë”©\n",
    "d_bld        = p1.get(\"d_bld\", 16)\n",
    "emb_dropout  = p1.get(\"emb_dropout\", 0.0)\n",
    "\n",
    "# --- ë™ì‘ í•˜ì´í¼ (S2) ---\n",
    "beta_week         = p2.get(\"beta_week\", 0.6)\n",
    "alpha             = p2.get(\"alpha\", 0.7)\n",
    "use_adaptive_beta = p2.get(\"use_adaptive_beta\", True)\n",
    "\n",
    "# ì‹¤ì œ ì…ë ¥ ì°¨ì›\n",
    "actual_source_dims = train_source_arrays[0].shape[1]\n",
    "actual_target_dims = train_target_arrays[0].shape[1]\n",
    "\n",
    "# --- ìµœì¢… í•˜ì´í¼ (TimesNet) ---\n",
    "final_hparams = {\n",
    "    \"source_length\": SOURCE_LENGTH, \"target_length\": TARGET_LENGTH,\n",
    "    \"source_dims\": actual_source_dims, \"target_dims\": actual_target_dims,\n",
    "    \"horizon_start\": 0, \"quantiles\": [0.025, 0.5, 0.975],\n",
    "\n",
    "    # êµ¬ì¡°/ìš©ëŸ‰\n",
    "    \"d_model\": d_model,\n",
    "    \"n_encoders\": n_encoders,\n",
    "    \"n_decoders\": n_decoders,\n",
    "\n",
    "    # í•™ìŠµ\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"dropout_rate\": dropout_rate,\n",
    "    \"lr_decay\": lr_decay,\n",
    "\n",
    "    # ì„ë² ë”©\n",
    "    \"num_buildings\": len(uniq_ids),\n",
    "    \"d_bld\": d_bld,\n",
    "    \"emb_dropout\": emb_dropout,\n",
    "\n",
    "    # TimesNet ì „ìš©\n",
    "    \"top_k\": top_k,\n",
    "    \"num_kernels\": num_kernels,\n",
    "    \"d_ff_tn\": d_ff_tn,\n",
    "\n",
    "    # ë™ì‘ í•˜ì´í¼\n",
    "    \"beta_week\": beta_week,\n",
    "    \"alpha\": alpha,\n",
    "    \"use_adaptive_beta\": use_adaptive_beta,\n",
    "}\n",
    "\n",
    "# ë°ì´í„°ë¡œë” (í•™ìŠµ ì „ìš© ë¡œë”)\n",
    "final_model = TimesNet(final_hparams)\n",
    "final_train_data = SequenceDatasetWithBld(\n",
    "    np.array(train_source_arrays), np.array(train_target_arrays), bld_ids=train_bld_ids_idx\n",
    ")\n",
    "final_train_loader = torch.utils.data.DataLoader(final_train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# ì½œë°±/ë¡œê±°\n",
    "os.makedirs(FINAL_DIR, exist_ok=True)\n",
    "ckpt_cb = ModelCheckpoint(\n",
    "    dirpath=FINAL_DIR, filename=\"final-{epoch:02d}-{val_loss:.4f}\",\n",
    "    monitor=\"val_loss\", mode=\"min\", save_top_k=1, save_last=True\n",
    ")\n",
    "es_cb  = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
    "lr_cb  = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "csv_logger = CSVLogger(save_dir=FINAL_DIR, name=\"logs\")\n",
    "\n",
    "# ì—í­ì€ S1 íƒìƒ‰ ê²°ê³¼ ì¬ì‚¬ìš©(ì—†ìœ¼ë©´ 30)\n",
    "optimal_epochs = 50\n",
    "print(f\"âœ… Using epochs: {optimal_epochs}\")\n",
    "\n",
    "# ***ê²°ì •ì„± OFF\n",
    "final_trainer = Trainer(\n",
    "    max_epochs=optimal_epochs,\n",
    "    accelerator=\"cpu\", devices=1,\n",
    "    logger=csv_logger, enable_progress_bar=True,\n",
    "    precision=32,\n",
    "    gradient_clip_val=grad_clip, accumulate_grad_batches=accum,\n",
    "    callbacks=[ckpt_cb, es_cb, lr_cb],\n",
    "    deterministic=False,\n",
    "    benchmark=False,\n",
    ")\n",
    "\n",
    "assert 'val_loader' in globals(), \"val_loaderê°€ í•„ìš”í•©ë‹ˆë‹¤.\"\n",
    "final_trainer.fit(final_model, final_train_loader, val_loader)\n",
    "\n",
    "best_ckpt_path = ckpt_cb.best_model_path\n",
    "print(f\"âœ… Best checkpoint: {best_ckpt_path}\")\n",
    "\n",
    "# ë¡œë“œ & ê²€ì¦\n",
    "loaded_final_model = TimesNet.load_from_checkpoint(\n",
    "    best_ckpt_path, hyperparams_dict=final_hparams,\n",
    "    map_location=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "loaded_final_model.eval()\n",
    "val_metrics = final_trainer.validate(loaded_final_model, dataloaders=val_loader, verbose=True)\n",
    "print(\"Final val metrics:\", val_metrics)\n",
    "\n",
    "# í¼ë¸”ë¦­ ì°½ ì¬í‰ê°€\n",
    "with torch.inference_mode():\n",
    "    raw = final_trainer.predict(loaded_final_model, dataloaders=val_pred_loader)\n",
    "preds_raw_list, fut_ex_list = zip(*raw)\n",
    "residual_q = torch.cat(preds_raw_list, dim=0).cpu().numpy().astype(np.float32)  # (N,H,Q)\n",
    "fut_ex     = torch.cat(fut_ex_list,   dim=0).cpu().numpy().astype(np.float32)  # (N,H)\n",
    "\n",
    "# ì¤‘ì•™ ë¶„ìœ„ìˆ˜ ì±„ë„ ì¸ë±ìŠ¤\n",
    "mid = getattr(loaded_final_model, \"median_idx\", 1)\n",
    "yhat_scaled = residual_q[:, :, mid] + fut_ex\n",
    "N = residual_q.shape[0]\n",
    "group_ids_used = list(group_ids_val[:N])\n",
    "y_scaled = np.stack([arr[:, -1] for arr in val_target_arrays], axis=0).astype(np.float32)[:N]\n",
    "yhat_real = scaler.backtransform_preds(yhat_scaled, group_ids=group_ids_used)\n",
    "y_real    = scaler.backtransform_preds(y_scaled,    group_ids=group_ids_used)\n",
    "\n",
    "if NONNEG_CLIP:\n",
    "    yhat_real = np.clip(yhat_real, 0.0, None)\n",
    "    y_real    = np.clip(y_real,    0.0, None)\n",
    "\n",
    "Hpub = min(int(PUBLIC_H), y_real.shape[1])\n",
    "yhat_pub = yhat_real[:, -Hpub:]\n",
    "y_pub    = y_real[:, -Hpub:]\n",
    "\n",
    "smape_public = _smape_np(y_pub, yhat_pub, eps=EPS_PUBLIC)\n",
    "bias_public  = float(np.nanmean(yhat_pub - y_pub))\n",
    "print(f\"ğŸ¯ Public-window SMAPE({Hpub}): {smape_public:.6f} | bias: {bias_public:.6f}\")\n",
    "\n",
    "# ë©”íƒ€ ì €ì¥\n",
    "final_ckpt_copy = os.path.join(FINAL_DIR, \"final_best.ckpt\")\n",
    "if best_ckpt_path and os.path.exists(best_ckpt_path):\n",
    "    shutil.copy2(best_ckpt_path, final_ckpt_copy)\n",
    "\n",
    "meta = {\n",
    "    \"timestamp\": datetime.now(timezone.utc).isoformat(),\n",
    "    \"final_hyperparams\": final_hparams,\n",
    "    \"stage1_best\": {\"value\": best_s1.value, \"params\": p1, \"attrs\": best_s1.user_attrs},\n",
    "    \"stage2_best\": {\"value\": best_s2.value, \"params\": p2, \"attrs\": best_s2.user_attrs},\n",
    "    \"val_metrics\": val_metrics,\n",
    "    \"public_window\": {\n",
    "        \"H\": Hpub, \"smape\": smape_public, \"bias\": bias_public,\n",
    "        \"eps\": EPS_PUBLIC, \"nonneg_clip\": NONNEG_CLIP\n",
    "    },\n",
    "    \"paths\": {\"best_ckpt\": best_ckpt_path, \"copied_ckpt\": final_ckpt_copy, \"save_dir\": FINAL_DIR}\n",
    "}\n",
    "with open(os.path.join(FINAL_DIR, \"final_meta.json\"), \"w\") as f:\n",
    "    json.dump(meta, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"ğŸ§¾ ë©”íƒ€ ì €ì¥ ì™„ë£Œ: {os.path.join(FINAL_DIR, 'final_meta.json')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d425b0d3-852e-4f68-9c2f-eba6f18d3043",
   "metadata": {
    "id": "d425b0d3-852e-4f68-9c2f-eba6f18d3043"
   },
   "source": [
    "## Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tVqXZ0aSV8l_",
   "metadata": {
    "id": "tVqXZ0aSV8l_"
   },
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# 1. Validation Set ì˜ˆì¸¡ + í›„ì²˜ë¦¬ + ì‹œê°í™”/ì§€í‘œ (êµì²´ë³¸)\n",
    "# ===================================================================\n",
    "import torch, numpy as np, pandas as pd, matplotlib.pyplot as plt, os, json\n",
    "\n",
    "# ---- í† ê¸€/ìƒìˆ˜ ----\n",
    "APPLY_PI_SHRINK = True\n",
    "FINAL_PI_TAU    = 0.6\n",
    "EPS_PUBLIC      = 1.0\n",
    "\n",
    "print(\"Validation ë°ì´í„°ì— ëŒ€í•œ ì„±ëŠ¥ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "\n",
    "# 1) ì˜ˆì¸¡\n",
    "with torch.inference_mode():\n",
    "    raw_outputs = final_trainer.predict(loaded_final_model, dataloaders=val_pred_loader)\n",
    "\n",
    "preds_raw_list, fut_ex_list = zip(*raw_outputs)\n",
    "residual_q = torch.cat(preds_raw_list, dim=0).cpu().numpy().astype(np.float32)  # (N,H,3) ê°€ì •\n",
    "fut_ex     = torch.cat(fut_ex_list,   dim=0).cpu().numpy().astype(np.float32)   # (N,H)\n",
    "assert residual_q.shape[:2] == fut_ex.shape[:2]\n",
    "N, H, Q = residual_q.shape\n",
    "assert Q == 3, f\"ì˜ˆì¸¡ Qì¶•ì´ 3ì´ ì•„ë‹™ë‹ˆë‹¤: {Q}\"\n",
    "\n",
    "# 2) ì”ì°¨ -> ìŠ¤ì¼€ì¼ëœ ì‹¤ì œê°’ (ë°”ì´ì–´ìŠ¤ ë³´ì • ì—†ìŒ)\n",
    "preds_raw_val = residual_q + fut_ex[:, :, None]   # (N,H,3) : [low, median, high] ê°€ì •\n",
    "\n",
    "# 3) ì—­ë³€í™˜(ì›ë‹¨ìœ„) & ë¬¼ë¦¬ ì œì•½\n",
    "#    - ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼: val_targetì—ì„œ ê±´ë¬¼ë²ˆí˜¸ ì¶”ì¶œ\n",
    "if 'group_ids_val' not in globals() or group_ids_val is None or len(group_ids_val) != preds_raw_val.shape[0]:\n",
    "    try:\n",
    "        group_ids_val = [vt.iloc[0][BUILDING_COL] for vt in val_target]\n",
    "    except Exception:\n",
    "        raise RuntimeError(\"group_ids_valì„ ë§Œë“¤ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. val_target ì‹œí€€ìŠ¤ì— BUILDING_COLì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "preds_val_no = scaler.backtransform_preds(preds_raw_val, group_ids=group_ids_val)  # (N,H,3)\n",
    "preds_val_no = np.clip(preds_val_no, 0.0, None)\n",
    "\n",
    "# 4) (ì„ íƒ) PI ìˆ˜ì¶• - ì›ë‹¨ìœ„ì—ì„œ ì ìš©í•´ ë¹„êµ í›„, ì¢‹ì•„ì§€ë©´ ë°˜ì˜\n",
    "def _smape_np(y_true, y_pred, eps=1.0):\n",
    "    y_true = np.asarray(y_true, np.float32)\n",
    "    y_pred = np.asarray(y_pred, np.float32)\n",
    "    m = np.isfinite(y_true) & np.isfinite(y_pred)\n",
    "    if not np.any(m): return 1e9\n",
    "    y_true = y_true[m]; y_pred = y_pred[m]\n",
    "    return float(np.mean(2.0*np.abs(y_pred - y_true) /\n",
    "                         (np.abs(y_true) + np.abs(y_pred) + eps)))\n",
    "\n",
    "# ì‹¤ì œê°’(ì›ë‹¨ìœ„) ë°°ì—´ ë§Œë“¤ê¸°: val_target ê·¸ëŒ€ë¡œ ì‚¬ìš© (ìˆœì„œ ê°€ì • ë™ì¼)\n",
    "y_real_val = np.stack([df[TARGET_COL].to_numpy() for df in val_target], axis=0).astype(np.float32)\n",
    "H_use = min(H, y_real_val.shape[1])\n",
    "y_real_val = y_real_val[:, :H_use]\n",
    "preds_val_no = preds_val_no[:, :H_use, :]\n",
    "\n",
    "# (ìˆ˜ì¶•í›„ í›„ë³´)\n",
    "preds_val_sh = preds_val_no.copy()\n",
    "if APPLY_PI_SHRINK:\n",
    "    med = preds_val_sh[:, :, 1]\n",
    "    preds_val_sh[:, :, 0] = med - FINAL_PI_TAU * (med - preds_val_sh[:, :, 0])\n",
    "    preds_val_sh[:, :, 2] = med + FINAL_PI_TAU * (preds_val_sh[:, :, 2] - med)\n",
    "\n",
    "# ì„±ëŠ¥ ë¹„êµ(ì¤‘ì•™ì„ )\n",
    "sm_no = _smape_np(y_real_val, preds_val_no[:, :, 1], eps=EPS_PUBLIC)\n",
    "sm_sh = _smape_np(y_real_val, preds_val_sh[:, :, 1], eps=EPS_PUBLIC)\n",
    "use_shrink = APPLY_PI_SHRINK and (sm_sh <= sm_no)\n",
    "\n",
    "preds_val = preds_val_sh if use_shrink else preds_val_no\n",
    "\n",
    "# ì •ì±… ì €ì¥(ì„ íƒ)\n",
    "if 'FINAL_DIR' not in globals():\n",
    "    FINAL_DIR = \"C:/Users/Daniel/DeepLearningEnergyForecasting/TimesNet_final_run\"\n",
    "os.makedirs(FINAL_DIR, exist_ok=True)\n",
    "policy = {\"pi_shrink\": bool(use_shrink), \"pi_tau\": float(FINAL_PI_TAU if use_shrink else 0.0)}\n",
    "with open(os.path.join(FINAL_DIR, \"postproc_policy.json\"), \"w\") as f:\n",
    "    json.dump(policy, f, ensure_ascii=False, indent=2)\n",
    "print(\"[POLICY] Saved:\", policy, f\"(SMAPE no={sm_no:.6f}, sh={sm_sh:.6f})\")\n",
    "\n",
    "# 5) DF ìƒì„±(ë„¤ ê¸°ì¡´ ë°©ì‹ ìœ ì§€)\n",
    "val_source_with_ids = list(enumerate(val_source))\n",
    "val_target_with_ids = list(enumerate(val_target))\n",
    "df_preds_val   = predictions_to_dataframe(preds_val, val_target_with_ids)\n",
    "df_actuals_val = test_sequences_to_dataframe(val_source_with_ids, val_target_with_ids)\n",
    "\n",
    "# 6) ì‹œê°í™”\n",
    "print(\"\\n--- ì „ì²´ ê²€ì¦ ê¸°ê°„ ì˜ˆì¸¡ ê²°ê³¼ ---\")\n",
    "_ = plot_actual_predicted(df_actuals_val, df_preds_val, \"TimesNet (Validation)\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n--- ìƒ˜í”Œ êµ¬ê°„ ì˜ˆì¸¡ ìƒì„¸ ë¶„ì„ ---\")\n",
    "num_val_samples = len(val_target_with_ids)\n",
    "indices_to_plot = [0, max(0, num_val_samples // 3 - 1), num_val_samples // 2, num_val_samples - 1] if num_val_samples >= 4 else list(range(num_val_samples))\n",
    "for idx in indices_to_plot:\n",
    "    _ = plot_sequence_preds(\n",
    "        preds_val,\n",
    "        val_source_with_ids, val_target_with_ids,\n",
    "        \"TimesNet (Validation)\",\n",
    "        target_col=TARGET_COL,\n",
    "        sequence_index=idx\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "# 7) ì§€í‘œ\n",
    "df_val_output_only = df_actuals_val[df_actuals_val[\"sequence\"] == \"output\"].copy()\n",
    "final_metrics = calculate_metrics(df_val_output_only, df_preds_val, model=\"TimesNet\", target_col=TARGET_COL)\n",
    "print(\"\\n--- TimesNet Validation Set ì„±ëŠ¥ ---\")\n",
    "display(final_metrics)\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "# sanity\n",
    "print(f\"[CHK] mean(y_real_val): {float(np.nanmean(y_real_val)):.3f}\")\n",
    "print(f\"[CHK] mean(pred_val_mid): {float(np.nanmean(preds_val[:, :, 1])):.3f}\")\n",
    "print(f\"[CHK] mean(pred - true): {float(np.nanmean(preds_val[:, :, 1] - y_real_val)):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DqTunvcRLtb5",
   "metadata": {
    "id": "DqTunvcRLtb5"
   },
   "outputs": [],
   "source": [
    "assert residual_q.ndim == 3 and fut_ex.ndim == 2, \"shape mismatch\"\n",
    "assert residual_q.shape[:2] == fut_ex.shape[:2],  \"N,H mismatch\"\n",
    "\n",
    "# --- Public 72h SMAPE ëª¨ë‹ˆí„°ë§ (ê²€ì¦ ì…€ ë§ë¯¸ì— ì¶”ê°€) ---\n",
    "mid = loaded_final_model.median_idx  # âœ… ì¤‘ì•™ ë¶„ìœ„ìˆ˜ ì¸ë±ìŠ¤\n",
    "y_scaled    = np.stack([arr[:, -1] for arr in val_target_arrays], axis=0).astype(np.float32)\n",
    "yhat_scaled = residual_q[:, :, mid] + fut_ex   # âœ… 1 â†’ mid\n",
    "y_real    = scaler.backtransform_preds(y_scaled,    group_ids=group_ids_val)\n",
    "yhat_real = scaler.backtransform_preds(yhat_scaled, group_ids=group_ids_val)\n",
    "if NONNEG_CLIP:\n",
    "    y_real = np.clip(y_real, 0, None); yhat_real = np.clip(yhat_real, 0, None)\n",
    "\n",
    "H_pub = min(int(PUBLIC_H), y_real.shape[1])\n",
    "smape_public = _smape_np(y_real[:, -H_pub:], yhat_real[:, -H_pub:], eps=EPS_PUBLIC)\n",
    "bias_public  = float(np.nanmean(yhat_real[:, -H_pub:] - y_real[:, -H_pub:]))\n",
    "print(f\"\\n--- Public {H_pub}h proxy ---  SMAPE: {smape_public:.6f} | Bias: {bias_public:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MGITvVRopX4U",
   "metadata": {
    "id": "MGITvVRopX4U"
   },
   "outputs": [],
   "source": [
    "# Validationì—ì„œë„(ì„ íƒ)\n",
    "assert (preds_val >= 0.0).all(), \"Validation ì—­ë³€í™˜ ì˜ˆì¸¡ì— ìŒìˆ˜ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.\"\n",
    "\n",
    "# ===== ê±´ë¬¼ë³„ ì„±ëŠ¥ ìš”ì•½: ë³‘í•© ì—†ì´ í™•ì‹¤íˆ ë§ì¶”ëŠ” ì•ˆì „ ë²„ì „ =====\n",
    "def _smape(a, f, eps=1.0):\n",
    "    a = np.asarray(a, dtype=np.float32)\n",
    "    f = np.asarray(f, dtype=np.float32)\n",
    "    return 2.0 * np.abs(f - a) / (np.abs(f) + np.abs(a) + eps)\n",
    "\n",
    "rows = []\n",
    "for i, (_, df_tgt) in enumerate(val_target_with_ids):\n",
    "    # ê° ì‹œí€€ìŠ¤ì˜ íƒ€ì„ìŠ¤íƒ¬í”„/ê±´ë¬¼/ì‹¤ì œê°’\n",
    "    # (create_transformer_sequences_for_prediction ì—ì„œ set_index('ì¼ì‹œ') í–ˆë˜ êµ¬ì¡° ê°€ì •)\n",
    "    times = df_tgt.index.to_numpy()\n",
    "    bld   = df_tgt[BUILDING_COL].iloc[0]\n",
    "    y_true = df_tgt[TARGET_COL].to_numpy()\n",
    "\n",
    "    # ì˜ˆì¸¡ (median)\n",
    "    y_pred = preds_val[i, :, mid]\n",
    "\n",
    "    # í˜¹ì‹œ ê¸¸ì´ê°€ ë‹¤ë¥´ë©´ ì•ˆì „í•˜ê²Œ ë§ì¶°ì¤Œ\n",
    "    H = min(len(times), len(y_true), len(y_pred))\n",
    "    if H == 0:\n",
    "        continue\n",
    "\n",
    "    rows.append(pd.DataFrame({\n",
    "        \"ê±´ë¬¼ë²ˆí˜¸\": bld,\n",
    "        \"time\": times[:H],\n",
    "        \"actual\": y_true[:H],\n",
    "        \"pred_point\": y_pred[:H],\n",
    "    }))\n",
    "\n",
    "tmp = pd.concat(rows, ignore_index=True)\n",
    "\n",
    "by_bld = tmp.groupby(\"ê±´ë¬¼ë²ˆí˜¸\").apply(\n",
    "    lambda g: pd.Series({\n",
    "        \"SMAPE\": float(_smape(g[\"actual\"].values, g[\"pred_point\"].values).mean()),\n",
    "        \"MAE\": float(np.mean(np.abs(g[\"actual\"].values - g[\"pred_point\"].values))),\n",
    "        \"N\": int(len(g))\n",
    "    })\n",
    ").sort_values(\"SMAPE\")\n",
    "\n",
    "by_bld[\"flag_smallN\"] = (by_bld[\"N\"] < 50)\n",
    "\n",
    "print(\"\\n--- ê±´ë¬¼ë³„ ì„±ëŠ¥ ìš”ì•½ (ìƒìœ„/í•˜ìœ„ 10) ---\")\n",
    "display(by_bld.head(10))\n",
    "display(by_bld.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1iN2zNLtx0eO",
   "metadata": {
    "id": "1iN2zNLtx0eO"
   },
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# âœ… (Validationìš©) baseline(fut_base) ì•ˆì „ í™•ë³´ + a/b ê²€ì‚¬\n",
    "# =========================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "mid = loaded_final_model.median_idx  # âœ…\n",
    "fut_base = preds_raw_val[:, :, mid] - residual_q[:, :, mid]\n",
    "# (= fut_ex ì™€ ë™ì¼í•´ì•¼ í•©ë‹ˆë‹¤. í•„ìš”í•˜ë©´ np.allclose(fut_base, fut_ex)ë¡œ í™•ì¸ ê°€ëŠ¥)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# (a) í›ˆë ¨ ê¸°ì¤€: ê±´ë¬¼ë³„ íƒ€ê¹ƒ ìŠ¤ì¼€ì¼ ë²”ìœ„(minâ‰ˆ0, maxâ‰ˆ1) ìƒ˜í”Œë§ í™•ì¸\n",
    "#   - train_target_scaled: [(id, arr), ...] í˜•íƒœ\n",
    "#   - arr: (T, D_with_building), col0=ê±´ë¬¼ë²ˆí˜¸, last=ìŠ¤ì¼€ì¼ëœ íƒ€ê¹ƒ\n",
    "# ---------------------------------------------------------\n",
    "samples = []\n",
    "for _, arr in train_target_scaled:\n",
    "    bld = int(arr[0, 0])   # 0ë²ˆ ì»¬ëŸ¼: ê±´ë¬¼ë²ˆí˜¸\n",
    "    y   = arr[:, -1]       # ë§ˆì§€ë§‰ ì»¬ëŸ¼: ìŠ¤ì¼€ì¼ëœ íƒ€ê¹ƒ\n",
    "    samples.append((bld, float(y.min()), float(y.max())))\n",
    "\n",
    "chk_a = (\n",
    "    pd.DataFrame(samples, columns=[\"ê±´ë¬¼ë²ˆí˜¸\", \"y_min\", \"y_max\"])\n",
    "      .groupby(\"ê±´ë¬¼ë²ˆí˜¸\")\n",
    "      .agg({\"y_min\": \"min\", \"y_max\": \"max\"})\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "print(\"í›ˆë ¨ ê¸°ì¤€ ê±´ë¬¼ë³„ íƒ€ê¹ƒ ìŠ¤ì¼€ì¼ ë²”ìœ„(ìµœì†Ÿê°’/ìµœëŒ“ê°’):\")\n",
    "display(chk_a.sample(min(10, len(chk_a))))   # ì„ì˜ 10ê°œ ìƒ˜í”Œ\n",
    "print(\"ìš”ì•½ í†µê³„:\")\n",
    "display(chk_a[[\"y_min\", \"y_max\"]].describe())\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# (b) Validationì—ì„œ 'ì§„ì§œ ì”ì°¨' í‘œì¤€í¸ì°¨(í•™ìŠµì´ ì£½ì§€ ì•ŠëŠ”ì§€) í™•ì¸\n",
    "#   - val_target_arrays: ëª¨ë¸ ì…ë ¥(ê±´ë¬¼ë²ˆí˜¸ ì œê±°), last=ìŠ¤ì¼€ì¼ëœ íƒ€ê¹ƒ\n",
    "#   - fut_base: weekly-blend baseline (ìŠ¤ì¼€ì¼ ê³µê°„)\n",
    "# ---------------------------------------------------------\n",
    "residuals = []\n",
    "for i in range(len(val_target_arrays)):\n",
    "    y_true_scaled = val_target_arrays[i][:, -1]  # (H,)\n",
    "    base_scaled   = fut_base[i]                  # (H,)\n",
    "    H = min(len(y_true_scaled), len(base_scaled))\n",
    "    if H > 0:\n",
    "        residuals.append(y_true_scaled[:H] - base_scaled[:H])\n",
    "\n",
    "r = np.concatenate(residuals) if residuals else np.array([], dtype=np.float32)\n",
    "if r.size == 0:\n",
    "    print(\"[Validation] ì”ì°¨ë¥¼ ê³„ì‚°í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(f\"[Validation] true residual std: {r.std():.6f}  (mean={r.mean():.6f})\")\n",
    "    print(\"ë¶„ìœ„ìˆ˜:\", np.percentile(r, [0, 1, 5, 25, 50, 75, 95, 99, 100]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ZZupQ2acAqX",
   "metadata": {
    "id": "2ZZupQ2acAqX"
   },
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# 2) Test Set ìµœì¢… ì˜ˆì¸¡ + ì œì¶œíŒŒì¼ ìƒì„± (ì¼ê´€ì„±/íŒŒì¼ ì•ˆì „ ì ìš©ë³¸)\n",
    "# ===================================================================\n",
    "import torch, numpy as np, pandas as pd, os, json, time\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"--- [3/3] ìµœì¢… ì œì¶œ íŒŒì¼ ìƒì„± ì‹œì‘ ---\")\n",
    "\n",
    "# ---------- 0) RUN ì‹ë³„ì/ì¶œë ¥ ë””ë ‰í† ë¦¬ ----------\n",
    "# FINAL_DIR ì€ í•™ìŠµ/ê²€ì¦ ì…€ì—ì„œ ë§Œë“  ë””ë ‰í† ë¦¬.\n",
    "# ì—¬ê¸°ì— run_id í•˜ìœ„ í´ë”ë¥¼ ë§Œë“¤ì–´ ëª¨ë“  ì‚°ì¶œë¬¼ì„ ë¶„ë¦¬ ì €ì¥\n",
    "if 'FINAL_DIR' not in globals() or not FINAL_DIR:\n",
    "    FINAL_DIR = \"C:/Users/Daniel/DeepLearningEnergyForecasting/TimesNet_final_run\"\n",
    "os.makedirs(FINAL_DIR, exist_ok=True)\n",
    "\n",
    "# ê°€ëŠ¥í•˜ë©´ metaì—ì„œ ë™ì¼ runì„ ì¬ì‚¬ìš©, ì—†ìœ¼ë©´ ìƒˆ RUN_ID\n",
    "meta_path = os.path.join(FINAL_DIR, \"final_meta.json\")\n",
    "if os.path.exists(meta_path):\n",
    "    try:\n",
    "        with open(meta_path, \"r\") as f:\n",
    "            _meta = json.load(f)\n",
    "        RUN_ID = _meta.get(\"timestamp\", datetime.utcnow().isoformat()).replace(\":\", \"\").replace(\"-\", \"\")[:15]\n",
    "        print(f\"[INFO] Using RUN_ID from meta: {RUN_ID}\")\n",
    "    except Exception:\n",
    "        RUN_ID = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        print(f\"[WARN] meta ì½ê¸° ì‹¤íŒ¨ â†’ new RUN_ID: {RUN_ID}\")\n",
    "else:\n",
    "    RUN_ID = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    print(f\"[INFO] meta ì—†ìŒ â†’ new RUN_ID: {RUN_ID}\")\n",
    "\n",
    "RUN_DIR = os.path.join(FINAL_DIR, f\"run_{RUN_ID}\")\n",
    "os.makedirs(RUN_DIR, exist_ok=True)\n",
    "SUBMIT_DIR = os.path.join(RUN_DIR, \"submit\")\n",
    "os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
    "\n",
    "# ---------- 1) ìŠ¤ì¼€ì¼ ë³€í™˜ (SequenceScaler ìœ ì§€) ----------\n",
    "infer_source_with_ids = list(enumerate(infer_src))\n",
    "infer_target_with_ids = list(enumerate(infer_tgt))\n",
    "\n",
    "source_scaled_final = scaler.transform(infer_source_with_ids)\n",
    "target_scaled_final = scaler.transform(infer_target_with_ids)\n",
    "\n",
    "# ë°°ì—´í™” + (íƒ€ê¹ƒ ì œì™¸: covariates-only) â€” ê±´ë¬¼ë²ˆí˜¸(ì²« ì—´) ì œê±°\n",
    "source_arrays_final = [arr[:, 1:]   for _, arr in source_scaled_final]\n",
    "target_arrays_final = [arr[:, 1:-1] for _, arr in target_scaled_final]\n",
    "\n",
    "print(\"Test source D:\", source_arrays_final[0].shape[1])\n",
    "print(\"Test target-cov D:\", target_arrays_final[0].shape[1])\n",
    "\n",
    "# ---------- 2) bld_ids (í•™ìŠµ ë•Œ ë§Œë“  infer_bld_ids_idx ì‚¬ìš©) ----------\n",
    "final_test_data = SequenceDatasetWithBld(\n",
    "    np.array(source_arrays_final),\n",
    "    np.array(target_arrays_final),\n",
    "    bld_ids=infer_bld_ids_idx\n",
    ")\n",
    "final_test_loader = torch.utils.data.DataLoader(final_test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# ---------- 3) ì˜ˆì¸¡ ì‹¤í–‰ ----------\n",
    "loaded_final_model.eval()\n",
    "with torch.inference_mode():\n",
    "    raw_outputs_test = final_trainer.predict(loaded_final_model, dataloaders=final_test_loader)\n",
    "\n",
    "preds_raw_list_test, fut_ex_list_test = zip(*raw_outputs_test)\n",
    "residual_q_test = torch.cat(preds_raw_list_test, dim=0).cpu().numpy().astype(np.float32)   # (N,H,3)\n",
    "fut_ex_test     = torch.cat(fut_ex_list_test,   dim=0).cpu().numpy().astype(np.float32)    # (N,H)\n",
    "assert residual_q_test.shape[:2] == fut_ex_test.shape[:2], \"N,H mismatch\"\n",
    "N, H, Q = residual_q_test.shape\n",
    "assert Q == 3, f\"ì˜ˆì¸¡ Qì¶•ì´ 3ì´ ì•„ë‹™ë‹ˆë‹¤: {Q}\"\n",
    "\n",
    "# ---------- 4) ì”ì°¨ -> ìŠ¤ì¼€ì¼ëœ ì‹¤ì œê°’ ----------\n",
    "preds_raw_test = residual_q_test + fut_ex_test[:, :, None]   # (N,H,3)\n",
    "\n",
    "# ---------- 5) ì—­ë³€í™˜(ì›ë‹¨ìœ„) & ë¬¼ë¦¬ ì œì•½ ----------\n",
    "group_ids_test = [vt.iloc[0][BUILDING_COL] for vt in infer_tgt]\n",
    "if len(group_ids_test) != preds_raw_test.shape[0]:\n",
    "    print(f\"[ê²½ê³ ] group_ids_test ê¸¸ì´ ë¶ˆì¼ì¹˜: {len(group_ids_test)} vs {preds_raw_test.shape[0]}\")\n",
    "preds_test = scaler.backtransform_preds(preds_raw_test, group_ids=group_ids_test)  # (N,H,3)\n",
    "preds_test = np.clip(preds_test, 0.0, None)\n",
    "\n",
    "# ---------- 6) Validationì—ì„œ ì €ì¥í•œ postproc policy ì ìš© (ì›ë‹¨ìœ„ì—ì„œë§Œ PI ìˆ˜ì¶•) ----------\n",
    "policy_path = os.path.join(FINAL_DIR, \"postproc_policy.json\")\n",
    "policy_used = {\"found\": False}\n",
    "if os.path.exists(policy_path):\n",
    "    with open(policy_path, \"r\") as f:\n",
    "        pol = json.load(f)\n",
    "    policy_used = {\"found\": True, **pol}\n",
    "    _pi_shrink = bool(pol.get(\"pi_shrink\", False))\n",
    "    _pi_tau    = float(pol.get(\"pi_tau\", 0.0))\n",
    "    print(\"[POLICY] Loaded:\", pol)\n",
    "    if _pi_shrink and _pi_tau > 0.0:\n",
    "        med = preds_test[:, :, 1]\n",
    "        preds_test[:, :, 0] = med - _pi_tau * (med - preds_test[:, :, 0])\n",
    "        preds_test[:, :, 2] = med + _pi_tau * (preds_test[:, :, 2] - med)\n",
    "else:\n",
    "    print(\"[POLICY] Not found, proceed without PI shrink change.\")\n",
    "\n",
    "# ---------- 7) ì œì¶œ íŒŒì¼ ìƒì„± (median ì‚¬ìš©) ----------\n",
    "sub = pd.read_csv(SAMPLE_SUB_PATH)\n",
    "expected_len = N * H\n",
    "if len(sub) != expected_len:\n",
    "    raise ValueError(f\"ì œì¶œ ê¸¸ì´ ë¶ˆì¼ì¹˜: {len(sub)} vs ì˜ˆìƒ {expected_len}\")\n",
    "\n",
    "out_col = \"answer\" if \"answer\" in sub.columns else (\"prediction\" if \"prediction\" in sub.columns else \"answer\")\n",
    "sub[out_col] = preds_test[:, :, 1].reshape(-1).astype(np.float32)\n",
    "\n",
    "# íŒŒì¼ëª…ì— RUN_ID ë¶€ì—¬ + RUN ë””ë ‰í† ë¦¬ì— ë³´ê´€(ì¬í˜„ì„±)\n",
    "submission_filename = f\"submission_TimesNet_{RUN_ID}.csv\"\n",
    "submission_path = os.path.join(SUBMIT_DIR, submission_filename)\n",
    "sub.to_csv(submission_path, index=False)\n",
    "\n",
    "# í¸ì˜ìƒ ì‘ì—… ë””ë ‰í† ë¦¬ì—ë„ ë™ì¼ íŒŒì¼ ë³µì‚¬\n",
    "cwd_submission_path = os.path.join(os.getcwd(), submission_filename)\n",
    "sub.to_csv(cwd_submission_path, index=False)\n",
    "\n",
    "print(f\"âœ… ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ: {submission_path}\")\n",
    "print(f\"âœ… ì‘ì—… ë””ë ‰í† ë¦¬ ë³µì‚¬ë³¸: {cwd_submission_path}\")\n",
    "print(f\"[SUBMIT] shape: N={N}, H={H}, Q={Q}, out_col={out_col}, mean(median)={float(np.nanmean(preds_test[:,:,1])):.3f}\")\n",
    "\n",
    "# ---------- 8) ì œì¶œ ì‚°ì¶œë¬¼ provenance ì €ì¥ ----------\n",
    "provenance = {\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"final_dir\": FINAL_DIR,\n",
    "    \"run_dir\": RUN_DIR,\n",
    "    \"submission_path\": submission_path,\n",
    "    \"submission_filename\": submission_filename,\n",
    "    \"timestamp\": time.ctime(),\n",
    "    \"policy_used\": policy_used,\n",
    "    \"N\": int(N), \"H\": int(H), \"Q\": int(Q),\n",
    "    \"median_mean\": float(np.nanmean(preds_test[:,:,1])),\n",
    "}\n",
    "with open(os.path.join(SUBMIT_DIR, \"provenance.json\"), \"w\") as f:\n",
    "    json.dump(provenance, f, ensure_ascii=False, indent=2)\n",
    "print(\"[PROVENANCE] Saved:\", os.path.join(SUBMIT_DIR, \"provenance.json\"))\n",
    "\n",
    "# ë¯¸ë¦¬ë³´ê¸°\n",
    "display(sub.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Of-IsoqKjfex",
   "metadata": {
    "id": "Of-IsoqKjfex"
   },
   "outputs": [],
   "source": [
    "# 7) 4ê°œ ê±´ë¬¼ë§Œ í™•ëŒ€ ì‹œê°í™” (ê°„ë‹¨ êµì²´ë³¸)\n",
    "print(\"\\n--- 4ê°œ ê±´ë¬¼ ì˜ˆì¸¡ ìƒì„¸ ë¶„ì„ ---\")\n",
    "\n",
    "# (ì„ íƒ) íŠ¹ì • 4ê°œ ê±´ë¬¼ë²ˆí˜¸ ì§€ì • â€” ì§€ì • ì•ˆ í•˜ë©´ ê²€ì¦ ì„¸íŠ¸ì—ì„œ ì•ì˜ 4ê°œ ì„œë¡œ ë‹¤ë¥¸ ê±´ë¬¼ ìë™ ì„ íƒ\n",
    "MANUAL_BUILDINGS = []  # ì˜ˆ: [101, 205, 309, 412]\n",
    "\n",
    "# ê±´ë¬¼ë²ˆí˜¸ â†’ ì‹œí€€ìŠ¤ ì¸ë±ìŠ¤ ë§¤í•‘\n",
    "bld_to_idx = { df[BUILDING_COL].iloc[0]: i for i, (_, df) in enumerate(val_target_with_ids) }\n",
    "\n",
    "if MANUAL_BUILDINGS:\n",
    "    indices_to_plot = [bld_to_idx[b] for b in MANUAL_BUILDINGS if b in bld_to_idx][:4]\n",
    "else:\n",
    "    # ê²€ì¦ ì„¸íŠ¸ì—ì„œ ì„œë¡œ ë‹¤ë¥¸ ê±´ë¬¼ 4ê°œ ìë™ ì„ íƒ\n",
    "    seen = set()\n",
    "    indices_to_plot = []\n",
    "    for i, (_, df) in enumerate(val_target_with_ids):\n",
    "        b = df[BUILDING_COL].iloc[0]\n",
    "        if b not in seen:\n",
    "            seen.add(b)\n",
    "            indices_to_plot.append(i)\n",
    "            if len(indices_to_plot) == 4:\n",
    "                break\n",
    "\n",
    "for idx in indices_to_plot:\n",
    "    _ = plot_sequence_preds(\n",
    "        preds_val,\n",
    "        val_source_with_ids, val_target_with_ids,\n",
    "        \"TimesNet (Validation)\",\n",
    "        target_col=TARGET_COL,\n",
    "        sequence_index=idx\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d58f5e-0e4e-4ead-bc40-23152ccf4885",
   "metadata": {
    "id": "92d58f5e-0e4e-4ead-bc40-23152ccf4885"
   },
   "source": [
    "Keep in mind that for the median quantile, pinball loss equals MAE / 2."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "aiot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
